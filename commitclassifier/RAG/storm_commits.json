{
    "diff_files": [
        {
            "diff": "@@ -17,7 +17,7 @@ import java.sql.Time;\n import java.sql.Timestamp;\n import java.util.ArrayList;\n import java.util.List;\n-import org.apache.commons.lang.Validate;\n+import org.apache.commons.lang3.Validate;\n import org.apache.storm.jdbc.common.Column;\n import org.apache.storm.jdbc.common.ConnectionProvider;\n import org.apache.storm.jdbc.common.JdbcClient;\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -52,25 +52,28 @@ public class DRPCSimpleACLAuthorizer extends DRPCAuthorizerBase {\n             Map<String, AclFunctionEntry> acl = new HashMap<>();\n             Map<String, Object> conf = Utils.findAndReadConfigFile(aclFileName);\n             if (conf.containsKey(Config.DRPC_AUTHORIZER_ACL)) {\n-                Map<String, Map<String, ?>> confAcl =\n-                    (Map<String, Map<String, ?>>)\n-                        conf.get(Config.DRPC_AUTHORIZER_ACL);\n-\n-                for (Map.Entry<String, Map<String, ?>> entry : confAcl.entrySet()) {\n-                    Map<String, ?> val = entry.getValue();\n-                    Collection<String> clientUsers = val.containsKey(CLIENT_USERS_KEY)\n-                            ? (Collection<String>) val.get(CLIENT_USERS_KEY)\n-                            : null;\n-                    String invocationUser = val.containsKey(INVOCATION_USER_KEY)\n-                            ? (String) val.get(INVOCATION_USER_KEY)\n-                            : null;\n-                    acl.put(entry.getKey(),\n-                            new AclFunctionEntry(clientUsers, invocationUser));\n+                Map<String, Map<String, ?>> confAcl = (Map<String, Map<String, ?>>) conf.get(Config.DRPC_AUTHORIZER_ACL);\n+\n+                if (confAcl != null) {\n+                    for (Map.Entry<String, Map<String, ?>> entry : confAcl.entrySet()) {\n+                        Map<String, ?> val = entry.getValue();\n+                        Collection<String> clientUsers = val.containsKey(CLIENT_USERS_KEY)\n+                                ? (Collection<String>) val.get(CLIENT_USERS_KEY)\n+                                : null;\n+                        String invocationUser = val.containsKey(INVOCATION_USER_KEY)\n+                                ? (String) val.get(INVOCATION_USER_KEY)\n+                                : null;\n+                        acl.put(entry.getKey(),\n+                                new AclFunctionEntry(clientUsers, invocationUser));\n+                    }\n                 }\n-            } else if (!permitWhenMissingFunctionEntry) {\n-                LOG.warn(\"Requiring explicit ACL entries, but none given. Therefore, all operations will be denied.\");\n             }\n+\n             this.acl = acl;\n+            if (this.acl.isEmpty() && !permitWhenMissingFunctionEntry) {\n+                LOG.warn(\"Requiring explicit ACL entries, but none given. Therefore, all operations will be denied.\");\n+            }\n+\n             lastUpdate = System.currentTimeMillis();\n         }\n         return acl;\n",
            "security_relevancy": "security_relevant"
        },
        {
            "diff": "@@ -16,7 +16,6 @@ import java.util.Iterator;\n import java.util.List;\n import java.util.Map;\n import org.apache.storm.generated.KillOptions;\n-import org.apache.storm.generated.Nimbus;\n import org.apache.storm.utils.NimbusClient;\n import org.apache.storm.utils.Utils;\n import org.slf4j.Logger;\n@@ -67,29 +66,24 @@ public class KillTopology {\n             opts.set_wait_secs(wait);\n         }\n \n-        NimbusClient.withConfiguredClient(new NimbusClient.WithNimbus() {\n-            @Override\n-            public void run(Nimbus.Iface nimbus) throws Exception {\n-                for (String name : names) {\n-                    try {\n-                        nimbus.killTopologyWithOpts(name, opts);\n-                        LOG.info(\"Killed topology: {}\", name);\n-                    } catch (Exception e) {\n-                        errorCount += 1;\n-                        if (!continueOnError) {\n-                            throw e;\n-                        } else {\n-                            LOG.error(\n-                                    \"Caught error killing topology '{}'; continuing as -i was passed.\", name, e\n-                            );\n-                        }\n+        NimbusClient.withConfiguredClient(nimbus -> {\n+            for (String name : names) {\n+                try {\n+                    nimbus.killTopologyWithOpts(name, opts);\n+                    LOG.info(\"Killed topology: {}\", name);\n+                } catch (Exception e) {\n+                    errorCount += 1;\n+                    if (continueOnError) {\n+                        LOG.error(\"Caught error killing topology '{}'; continuing as -i was passed.\", name, e);\n+                    } else {\n+                        throw e;\n                     }\n                 }\n+            }\n \n-                // If we failed to kill any topology, still exit with failure status\n-                if (errorCount > 0) {\n-                    throw new RuntimeException(\"Failed to successfully kill \" + errorCount + \" topologies.\");\n-                }\n+            // If we failed to kill any topology, still exit with failure status\n+            if (errorCount > 0) {\n+                throw new RuntimeException(\"Failed to successfully kill \" + errorCount + \" topologies.\");\n             }\n         });\n     }\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -19,15 +19,19 @@ import java.util.HashSet;\n import java.util.Set;\n import javax.security.auth.Subject;\n import org.apache.storm.shade.com.google.common.collect.ImmutableSet;\n-import org.junit.Assert;\n-import org.junit.Before;\n-import org.junit.Test;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.junit.jupiter.api.Assertions.assertNull;\n \n public class ReqContextTest {\n \n     private ReqContext rc;\n \n-    @Before\n+    @BeforeEach\n     public void setup() {\n         rc = ReqContext.context();\n     }\n@@ -35,20 +39,20 @@ public class ReqContextTest {\n     @Test\n     public void testSubject() {\n         Subject expected = new Subject();\n-        Assert.assertFalse(expected.isReadOnly());\n+        assertFalse(expected.isReadOnly());\n         rc.setSubject(expected);\n-        Assert.assertEquals(expected, rc.subject());\n+        assertEquals(expected, rc.subject());\n \n         expected.setReadOnly();\n         rc.setSubject(expected);\n-        Assert.assertEquals(expected, rc.subject());\n+        assertEquals(expected, rc.subject());\n     }\n \n     @Test\n     public void testRemoteAddress() throws UnknownHostException {\n         InetAddress expected = InetAddress.getByAddress(\"ABCD\".getBytes());\n         rc.setRemoteAddress(expected);\n-        Assert.assertEquals(expected, rc.remoteAddress());\n+        assertEquals(expected, rc.remoteAddress());\n     }\n \n     /**\n@@ -57,23 +61,18 @@ public class ReqContextTest {\n     @Test\n     public void testPrincipalReturnsNullWhenNoSubject() {\n         rc.setSubject(new Subject());\n-        Assert.assertNull(rc.principal());\n+        assertNull(rc.principal());\n     }\n \n     @Test\n     public void testPrincipal() {\n         final String principalName = \"Test Principal\";\n-        Principal testPrincipal = new Principal() {\n-            @Override\n-            public String getName() {\n-                return principalName;\n-            }\n-        };\n+        Principal testPrincipal = () -> principalName;\n         Set<Principal> principals = ImmutableSet.of(testPrincipal);\n         Subject subject = new Subject(false, principals, new HashSet<>(), new HashSet<>());\n         rc.setSubject(subject);\n-        Assert.assertNotNull(rc.principal());\n-        Assert.assertEquals(principalName, rc.principal().getName());\n+        assertNotNull(rc.principal());\n+        assertEquals(principalName, rc.principal().getName());\n         rc.setSubject(null);\n     }\n }\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -1,196 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version\n- * 2.0 (the \"License\"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the License for the specific language governing permissions\n- * and limitations under the License.\n- */\n-\n-package org.apache.storm.cassandra.bolt;\n-\n-import com.datastax.driver.core.Statement;\n-import java.util.ArrayList;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.concurrent.LinkedBlockingQueue;\n-import java.util.concurrent.TimeUnit;\n-import org.apache.storm.Config;\n-import org.apache.storm.cassandra.executor.AsyncResultHandler;\n-import org.apache.storm.cassandra.executor.impl.BatchAsyncResultHandler;\n-import org.apache.storm.cassandra.query.CQLStatementTupleMapper;\n-import org.apache.storm.task.OutputCollector;\n-import org.apache.storm.task.TopologyContext;\n-import org.apache.storm.tuple.Tuple;\n-import org.apache.storm.utils.Time;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-public class BatchCassandraWriterBolt extends BaseCassandraBolt<List<Tuple>> {\n-\n-    public static final int DEFAULT_EMIT_FREQUENCY = 2;\n-    private static final Logger LOG = LoggerFactory.getLogger(BatchCassandraWriterBolt.class);\n-    private LinkedBlockingQueue<Tuple> queue;\n-\n-    private int tickFrequencyInSeconds;\n-\n-    private long lastModifiedTimesMillis;\n-\n-    private int batchMaxSize = 1000;\n-\n-    private String componentId;\n-\n-    private AsyncResultHandler<List<Tuple>> asyncResultHandler;\n-\n-    /**\n-     * Creates a new {@link CassandraWriterBolt} instance.\n-     */\n-    public BatchCassandraWriterBolt(CQLStatementTupleMapper tupleMapper) {\n-        this(tupleMapper, DEFAULT_EMIT_FREQUENCY);\n-    }\n-\n-    /**\n-     * Creates a new {@link CassandraWriterBolt} instance.\n-     */\n-    public BatchCassandraWriterBolt(CQLStatementTupleMapper tupleMapper, int tickFrequencyInSeconds) {\n-        super(tupleMapper);\n-        this.tickFrequencyInSeconds = tickFrequencyInSeconds;\n-    }\n-\n-    /**\n-     * {@inheritDoc}\n-     */\n-    @Override\n-    public void prepare(Map<String, Object> topoConfig, TopologyContext topologyContext, OutputCollector outputCollector) {\n-        super.prepare(topoConfig, topologyContext, outputCollector);\n-        this.componentId = topologyContext.getThisComponentId();\n-        this.queue = new LinkedBlockingQueue<>(batchMaxSize);\n-        this.lastModifiedTimesMillis = now();\n-    }\n-\n-    @Override\n-    protected AsyncResultHandler<List<Tuple>> getAsyncHandler() {\n-        if (asyncResultHandler == null) {\n-            asyncResultHandler = new BatchAsyncResultHandler(getResultHandler());\n-        }\n-        return asyncResultHandler;\n-    }\n-\n-    /**\n-     * {@inheritDoc}\n-     */\n-    @Override\n-    protected void process(Tuple input) {\n-        if (!queue.offer(input)) {\n-            LOG.info(logPrefix() + \"The message queue is full, preparing batch statement...\");\n-            prepareAndExecuteStatement();\n-            queue.add(input);\n-        }\n-    }\n-\n-    /**\n-     * {@inheritDoc}\n-     */\n-    @Override\n-    protected void onTickTuple(Tuple tuple) {\n-        prepareAndExecuteStatement();\n-    }\n-\n-    public void prepareAndExecuteStatement() {\n-        int size = queue.size();\n-        if (size > 0) {\n-            List<Tuple> inputs = new ArrayList<>(size);\n-            queue.drainTo(inputs);\n-            try {\n-                List<PairStatementTuple> psl = buildStatement(inputs);\n-\n-                int sinceLastModified = updateAndGetSecondsSinceLastModified();\n-                LOG.debug(logPrefix() + \"Execute cql batches with {} statements after {} seconds\", size, sinceLastModified);\n-\n-                checkTimeElapsedSinceLastExec(sinceLastModified);\n-\n-                GroupingBatchBuilder batchBuilder = new GroupingBatchBuilder(cassandraConf.getBatchSizeRows(), psl);\n-\n-                int batchSize = 0;\n-                for (PairBatchStatementTuples batch : batchBuilder) {\n-                    LOG.debug(logPrefix() + \"Writing data to {} in batches of {} rows.\", cassandraConf.getKeyspace(),\n-                              batch.getInputs().size());\n-                    getAsyncExecutor().execAsync(batch.getStatement(), batch.getInputs());\n-                    batchSize++;\n-                }\n-\n-                int pending = getAsyncExecutor().getPendingTasksSize();\n-                if (pending > batchSize) {\n-                    LOG.warn(logPrefix() + \"Currently pending tasks is superior to the number of submit batches({}) : {}\", batchSize,\n-                             pending);\n-                }\n-\n-            } catch (Throwable r) {\n-                LOG.error(logPrefix() + \"Error(s) occurred while preparing batch statements\");\n-                getAsyncHandler().failure(r, inputs);\n-            }\n-        }\n-    }\n-\n-    private List<PairStatementTuple> buildStatement(List<Tuple> inputs) {\n-        List<PairStatementTuple> stmts = new ArrayList<>(inputs.size());\n-\n-        for (Tuple t : inputs) {\n-            List<Statement> sl = getMapper().map(topoConfig, session, t);\n-            for (Statement s : sl) {\n-                stmts.add(new PairStatementTuple(t, s));\n-            }\n-        }\n-        return stmts;\n-    }\n-\n-    private void checkTimeElapsedSinceLastExec(int sinceLastModified) {\n-        if (sinceLastModified > tickFrequencyInSeconds) {\n-            LOG.warn(logPrefix() + \"The time elapsed since last execution exceeded tick tuple frequency - {} > {} seconds\",\n-                     sinceLastModified, tickFrequencyInSeconds);\n-        }\n-    }\n-\n-    private String logPrefix() {\n-        return componentId + \" - \";\n-    }\n-\n-    public BatchCassandraWriterBolt withTickFrequency(long time, TimeUnit unit) {\n-        this.tickFrequencyInSeconds = (int) unit.toSeconds(time);\n-        return this;\n-    }\n-\n-    /**\n-     * Maximum number of tuple kept in memory before inserting batches to cassandra.\n-     * @param size the max queue size.\n-     * @return <code>this</code>\n-     */\n-    public BatchCassandraWriterBolt withQueueSize(int size) {\n-        this.batchMaxSize = size;\n-        return this;\n-    }\n-\n-    /**\n-     * {@inheritDoc}\n-     */\n-    @Override\n-    public Map<String, Object> getComponentConfiguration() {\n-        Config conf = new Config();\n-        conf.put(Config.TOPOLOGY_TICK_TUPLE_FREQ_SECS, tickFrequencyInSeconds);\n-        return conf;\n-    }\n-\n-    private int updateAndGetSecondsSinceLastModified() {\n-        long now = now();\n-        int seconds = (int) (now - lastModifiedTimesMillis) / 1000;\n-        lastModifiedTimesMillis = now;\n-        return seconds;\n-    }\n-\n-    private long now() {\n-        return Time.currentTimeMillis();\n-    }\n-}\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -1,85 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version\n- * 2.0 (the \"License\"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions\n- * and limitations under the License.\n- */\n-\n-package org.apache.storm.hbase.bolt.mapper;\n-\n-import static org.apache.storm.hbase.common.Utils.toBytes;\n-import static org.apache.storm.hbase.common.Utils.toLong;\n-\n-import org.apache.storm.hbase.common.ColumnList;\n-import org.apache.storm.tuple.Fields;\n-import org.apache.storm.tuple.Tuple;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-public class SimpleHBaseMapper implements HBaseMapper {\n-    private static final Logger LOG = LoggerFactory.getLogger(SimpleHBaseMapper.class);\n-\n-    private String rowKeyField;\n-    //    private String timestampField;\n-    private byte[] columnFamily;\n-    private Fields columnFields;\n-    private Fields counterFields;\n-\n-    public SimpleHBaseMapper() {\n-    }\n-\n-\n-    public SimpleHBaseMapper withRowKeyField(String rowKeyField) {\n-        this.rowKeyField = rowKeyField;\n-        return this;\n-    }\n-\n-    public SimpleHBaseMapper withColumnFields(Fields columnFields) {\n-        this.columnFields = columnFields;\n-        return this;\n-    }\n-\n-    public SimpleHBaseMapper withCounterFields(Fields counterFields) {\n-        this.counterFields = counterFields;\n-        return this;\n-    }\n-\n-    public SimpleHBaseMapper withColumnFamily(String columnFamily) {\n-        this.columnFamily = columnFamily.getBytes();\n-        return this;\n-    }\n-\n-    //    public SimpleTridentHBaseMapper withTimestampField(String timestampField){\n-    //        this.timestampField = timestampField;\n-    //        return this;\n-    //    }\n-\n-    @Override\n-    public byte[] rowKey(Tuple tuple) {\n-        Object objVal = tuple.getValueByField(this.rowKeyField);\n-        return toBytes(objVal);\n-    }\n-\n-    @Override\n-    public ColumnList columns(Tuple tuple) {\n-        ColumnList cols = new ColumnList();\n-        if (this.columnFields != null) {\n-            // TODO timestamps\n-            for (String field : this.columnFields) {\n-                cols.addColumn(this.columnFamily, field.getBytes(), toBytes(tuple.getValueByField(field)));\n-            }\n-        }\n-        if (this.counterFields != null) {\n-            for (String field : this.counterFields) {\n-                cols.addCounter(this.columnFamily, field.getBytes(), toLong(tuple.getValueByField(field)));\n-            }\n-        }\n-        return cols;\n-    }\n-}\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -1,216 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.storm.rocketmq.bolt;\n-\n-import java.util.LinkedList;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Properties;\n-import org.apache.commons.lang.Validate;\n-import org.apache.rocketmq.client.exception.MQClientException;\n-import org.apache.rocketmq.client.producer.DefaultMQProducer;\n-import org.apache.rocketmq.client.producer.SendCallback;\n-import org.apache.rocketmq.client.producer.SendResult;\n-import org.apache.rocketmq.common.message.Message;\n-import org.apache.storm.Config;\n-import org.apache.storm.rocketmq.RocketMqConfig;\n-import org.apache.storm.rocketmq.common.mapper.TupleToMessageMapper;\n-import org.apache.storm.rocketmq.common.selector.TopicSelector;\n-import org.apache.storm.task.OutputCollector;\n-import org.apache.storm.task.TopologyContext;\n-import org.apache.storm.topology.IRichBolt;\n-import org.apache.storm.topology.OutputFieldsDeclarer;\n-import org.apache.storm.tuple.Tuple;\n-import org.apache.storm.utils.BatchHelper;\n-import org.apache.storm.utils.TupleUtils;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-public class RocketMqBolt implements IRichBolt {\n-    private static final long serialVersionUID = 1L;\n-    private static final Logger LOG = LoggerFactory.getLogger(RocketMqBolt.class);\n-\n-    private static final int DEFAULT_FLUSH_INTERVAL_SECS = 5;\n-    private static final int DEFAULT_BATCH_SIZE = 20;\n-\n-    private DefaultMQProducer producer;\n-    private OutputCollector collector;\n-    private TopicSelector selector;\n-    private TupleToMessageMapper mapper;\n-    private Properties properties;\n-\n-    private boolean async = true;\n-    private boolean batch = false;\n-    private int batchSize = DEFAULT_BATCH_SIZE;\n-    private int flushIntervalSecs = DEFAULT_FLUSH_INTERVAL_SECS;\n-    private BatchHelper batchHelper;\n-    private List<Message> messages;\n-\n-    @Override\n-    public void prepare(Map<String, Object> topoConf, TopologyContext context, OutputCollector collector) {\n-        Validate.notEmpty(properties, \"Producer properties can not be empty\");\n-        Validate.notNull(selector, \"TopicSelector can not be null\");\n-        Validate.notNull(mapper, \"TupleToMessageMapper can not be null\");\n-\n-        producer = new DefaultMQProducer();\n-        producer.setInstanceName(String.valueOf(context.getThisTaskId()));\n-        RocketMqConfig.buildProducerConfigs(properties, producer);\n-\n-        try {\n-            producer.start();\n-        } catch (MQClientException e) {\n-            throw new RuntimeException(e);\n-        }\n-\n-        this.collector = collector;\n-        this.batchHelper = new BatchHelper(batchSize, collector);\n-        this.messages = new LinkedList<>();\n-    }\n-\n-    public RocketMqBolt withSelector(TopicSelector selector) {\n-        this.selector = selector;\n-        return this;\n-    }\n-\n-    public RocketMqBolt withMapper(TupleToMessageMapper mapper) {\n-        this.mapper = mapper;\n-        return this;\n-    }\n-\n-    public RocketMqBolt withAsync(boolean async) {\n-        this.async = async;\n-        return this;\n-    }\n-\n-    public RocketMqBolt withBatch(boolean batch) {\n-        this.batch = batch;\n-        return this;\n-    }\n-\n-    public RocketMqBolt withBatchSize(int batchSize) {\n-        this.batchSize = batchSize;\n-        return this;\n-    }\n-\n-    public RocketMqBolt withFlushIntervalSecs(int flushIntervalSecs) {\n-        this.flushIntervalSecs = flushIntervalSecs;\n-        return this;\n-    }\n-\n-    public RocketMqBolt withProperties(Properties properties) {\n-        this.properties = properties;\n-        return this;\n-    }\n-\n-    @Override\n-    public void execute(Tuple input) {\n-        if (!batch && TupleUtils.isTick(input)) {\n-            return;\n-        }\n-\n-        String topic = selector.getTopic(input);\n-        if (topic == null) {\n-            LOG.warn(\"skipping Message due to topic selector returned null.\");\n-            collector.ack(input);\n-            return;\n-        }\n-\n-        if (batch) {\n-            // batch sync sending\n-            try {\n-                if (batchHelper.shouldHandle(input)) {\n-                    batchHelper.addBatch(input);\n-                    messages.add(prepareMessage(input));\n-                }\n-\n-                if (batchHelper.shouldFlush()) {\n-                    producer.send(messages);\n-                    batchHelper.ack();\n-                    messages.clear();\n-                }\n-            } catch (Exception e) {\n-                LOG.error(\"Batch send messages failure!\", e);\n-                batchHelper.fail(e);\n-                messages.clear();\n-            }\n-        } else {\n-            if (async) {\n-                // async sending\n-                try {\n-                    producer.send(prepareMessage(input), new SendCallback() {\n-                        @Override\n-                        public void onSuccess(SendResult sendResult) {\n-                            collector.ack(input);\n-                        }\n-\n-                        @Override\n-                        public void onException(Throwable throwable) {\n-                            if (throwable != null) {\n-                                LOG.error(\"Async send messages failure!\", throwable);\n-                                collector.reportError(throwable);\n-                                collector.fail(input);\n-                            }\n-                        }\n-                    });\n-                } catch (Exception e) {\n-                    LOG.error(\"Async send messages failure!\", e);\n-                    collector.reportError(e);\n-                    collector.fail(input);\n-                }\n-            } else {\n-                // sync sending, will return a SendResult\n-                try {\n-                    producer.send(prepareMessage(input));\n-                    collector.ack(input);\n-                } catch (Exception e) {\n-                    LOG.error(\"Sync send messages failure!\", e);\n-                    collector.reportError(e);\n-                    collector.fail(input);\n-                }\n-            }\n-        }\n-    }\n-\n-    // Mapping: from storm tuple -> rocketmq Message\n-    private Message prepareMessage(Tuple input) {\n-        String topic = selector.getTopic(input);\n-        String tag = selector.getTag(input);\n-        String key = mapper.getKeyFromTuple(input);\n-        byte[] value = mapper.getValueFromTuple(input);\n-\n-        return new Message(topic, tag, key, value);\n-    }\n-\n-    @Override\n-    public void declareOutputFields(OutputFieldsDeclarer declarer) {\n-\n-    }\n-\n-    @Override\n-    public Map<String, Object> getComponentConfiguration() {\n-        return TupleUtils.putTickFrequencyIntoComponentConfig(new Config(), flushIntervalSecs);\n-    }\n-\n-    @Override\n-    public void cleanup() {\n-        if (producer != null) {\n-            producer.shutdown();\n-        }\n-    }\n-}\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -1,97 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version\n- * 2.0 (the \"License\"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions\n- * and limitations under the License.\n- */\n-\n-package org.apache.storm.mqtt.bolt;\n-\n-import java.util.Map;\n-import org.apache.storm.Config;\n-import org.apache.storm.mqtt.MqttMessage;\n-import org.apache.storm.mqtt.MqttTupleMapper;\n-import org.apache.storm.mqtt.common.MqttOptions;\n-import org.apache.storm.mqtt.common.MqttPublisher;\n-import org.apache.storm.mqtt.common.SslUtils;\n-import org.apache.storm.mqtt.ssl.KeyStoreLoader;\n-import org.apache.storm.task.OutputCollector;\n-import org.apache.storm.task.TopologyContext;\n-import org.apache.storm.topology.OutputFieldsDeclarer;\n-import org.apache.storm.topology.base.BaseTickTupleAwareRichBolt;\n-import org.apache.storm.tuple.Tuple;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-\n-public class MqttBolt extends BaseTickTupleAwareRichBolt {\n-    private static final Logger LOG = LoggerFactory.getLogger(MqttBolt.class);\n-    private MqttTupleMapper mapper;\n-    private transient MqttPublisher publisher;\n-    private boolean retain = false;\n-    private transient OutputCollector collector;\n-    private MqttOptions options;\n-    private KeyStoreLoader keyStoreLoader;\n-    private transient String topologyName;\n-\n-\n-    public MqttBolt(MqttOptions options, MqttTupleMapper mapper) {\n-        this(options, mapper, null, false);\n-    }\n-\n-    public MqttBolt(MqttOptions options, MqttTupleMapper mapper, boolean retain) {\n-        this(options, mapper, null, retain);\n-    }\n-\n-    public MqttBolt(MqttOptions options, MqttTupleMapper mapper, KeyStoreLoader keyStoreLoader) {\n-        this(options, mapper, keyStoreLoader, false);\n-    }\n-\n-    public MqttBolt(MqttOptions options, MqttTupleMapper mapper, KeyStoreLoader keyStoreLoader, boolean retain) {\n-        this.options = options;\n-        this.mapper = mapper;\n-        this.retain = retain;\n-        this.keyStoreLoader = keyStoreLoader;\n-        // the following code is duplicated in the constructor of MqttPublisher\n-        // we reproduce it here so we fail on the client side if SSL is misconfigured, rather than when the topology\n-        // is deployed to the cluster\n-        SslUtils.checkSslConfig(this.options.getUrl(), keyStoreLoader);\n-    }\n-\n-    @Override\n-    public void prepare(Map<String, Object> conf, TopologyContext context, OutputCollector collector) {\n-        this.collector = collector;\n-        this.topologyName = (String) conf.get(Config.TOPOLOGY_NAME);\n-        this.publisher = new MqttPublisher(this.options, this.keyStoreLoader, this.retain);\n-        try {\n-            this.publisher.connectMqtt(this.topologyName + \"-\" + context.getThisComponentId() + \"-\" + context.getThisTaskId());\n-        } catch (Exception e) {\n-            LOG.error(\"Unable to connect to MQTT Broker.\", e);\n-            throw new RuntimeException(\"Unable to connect to MQTT Broker.\", e);\n-        }\n-    }\n-\n-    @Override\n-    protected void process(Tuple input) {\n-        MqttMessage message = this.mapper.toMessage(input);\n-        try {\n-            this.publisher.publish(message);\n-            this.collector.ack(input);\n-        } catch (Exception e) {\n-            LOG.warn(\"Error publishing MQTT message. Failing tuple.\", e);\n-            // should we fail the tuple or kill the worker?\n-            collector.reportError(e);\n-            collector.fail(input);\n-        }\n-    }\n-\n-    @Override\n-    public void declareOutputFields(OutputFieldsDeclarer declarer) {\n-        // this bolt does not emit tuples\n-    }\n-}\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -1,4 +1,4 @@\n-/**\n+/*\n  * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with\n  * this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version\n  * 2.0 (the \"License\"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at\n@@ -36,7 +36,7 @@ import org.apache.storm.hdfs.bolt.rotation.FileRotationPolicy;\n import org.apache.storm.hdfs.bolt.rotation.FileSizeRotationPolicy;\n import org.apache.storm.hdfs.bolt.sync.CountSyncPolicy;\n import org.apache.storm.hdfs.bolt.sync.SyncPolicy;\n-import org.apache.storm.hdfs.testing.MiniDFSClusterRule;\n+import org.apache.storm.hdfs.testing.MiniDFSClusterExtension;\n import org.apache.storm.task.GeneralTopologyContext;\n import org.apache.storm.task.OutputCollector;\n import org.apache.storm.task.TopologyContext;\n@@ -45,17 +45,18 @@ import org.apache.storm.tuple.Fields;\n import org.apache.storm.tuple.Tuple;\n import org.apache.storm.tuple.TupleImpl;\n import org.apache.storm.tuple.Values;\n-import org.junit.After;\n-import org.junit.Assert;\n-import org.junit.Before;\n-import org.junit.BeforeClass;\n-import org.junit.Rule;\n-import org.junit.Test;\n-import org.junit.runner.RunWith;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.extension.RegisterExtension;\n import org.mockito.Mock;\n-import org.mockito.runners.MockitoJUnitRunner;\n+import org.mockito.junit.jupiter.MockitoExtension;\n \n-@RunWith(MockitoJUnitRunner.class)\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+\n+@ExtendWith(MockitoExtension.class)\n public class AvroGenericRecordBoltTest {\n \n     private static final String testRoot = \"/unittest\";\n@@ -72,8 +73,9 @@ public class AvroGenericRecordBoltTest {\n     private static Schema schema2;\n     private static Tuple tuple1;\n     private static Tuple tuple2;\n-    @Rule\n-    public MiniDFSClusterRule dfsClusterRule = new MiniDFSClusterRule(() -> {\n+\n+    @RegisterExtension\n+    public static final MiniDFSClusterExtension DFS_CLUSTER_EXTENSION = new MiniDFSClusterExtension(() -> {\n         Configuration conf = new Configuration();\n         conf.set(\"fs.trash.interval\", \"10\");\n         conf.setBoolean(\"dfs.permissions\", true);\n@@ -89,7 +91,7 @@ public class AvroGenericRecordBoltTest {\n     private DistributedFileSystem fs;\n     private String hdfsURI;\n \n-    @BeforeClass\n+    @BeforeAll\n     public static void setupClass() {\n         Schema.Parser parser = new Schema.Parser();\n         schema1 = parser.parse(schemaV1);\n@@ -110,8 +112,9 @@ public class AvroGenericRecordBoltTest {\n \n     private static Tuple generateTestTuple(GenericRecord record) {\n         TopologyBuilder builder = new TopologyBuilder();\n-        GeneralTopologyContext topologyContext = new GeneralTopologyContext(builder.createTopology(),\n-                                                                            new Config(), new HashMap(), new HashMap(), new HashMap(), \"\") {\n+        GeneralTopologyContext topologyContext =\n+            new GeneralTopologyContext(builder.createTopology(), new Config(), new HashMap(), new HashMap<>(),\n+                new HashMap<>(), \"\") {\n             @Override\n             public Fields getComponentOutputFields(String componentId, String streamId) {\n                 return new Fields(\"record\");\n@@ -120,13 +123,13 @@ public class AvroGenericRecordBoltTest {\n         return new TupleImpl(topologyContext, new Values(record), topologyContext.getComponentId(1), 1, \"\");\n     }\n \n-    @Before\n+    @BeforeEach\n     public void setup() throws Exception {\n-        fs = dfsClusterRule.getDfscluster().getFileSystem();\n+        fs = DFS_CLUSTER_EXTENSION.getDfscluster().getFileSystem();\n         hdfsURI = fs.getUri() + \"/\";\n     }\n \n-    @After\n+    @AfterEach\n     public void shutDown() throws IOException {\n         fs.close();\n     }\n@@ -141,12 +144,12 @@ public class AvroGenericRecordBoltTest {\n         bolt.execute(tuple1);\n         bolt.execute(tuple1);\n \n-        Assert.assertEquals(1, countNonZeroLengthFiles(testRoot));\n+        assertEquals(1, countNonZeroLengthFiles(testRoot));\n         verifyAllAvroFiles(testRoot);\n     }\n \n     @Test\n-    public void multipleTuplesMutliplesFiles() throws IOException {\n+    public void multipleTuplesMultiplesFiles() throws IOException {\n         AvroGenericRecordBolt bolt = makeAvroBolt(hdfsURI, 1, .0001f, schemaV1);\n \n         bolt.prepare(new Config(), topologyContext, collector);\n@@ -155,7 +158,7 @@ public class AvroGenericRecordBoltTest {\n         bolt.execute(tuple1);\n         bolt.execute(tuple1);\n \n-        Assert.assertEquals(4, countNonZeroLengthFiles(testRoot));\n+        assertEquals(4, countNonZeroLengthFiles(testRoot));\n         verifyAllAvroFiles(testRoot);\n     }\n \n@@ -168,7 +171,7 @@ public class AvroGenericRecordBoltTest {\n         bolt.execute(tuple2);\n \n         //Schema change should have forced a rotation\n-        Assert.assertEquals(2, countNonZeroLengthFiles(testRoot));\n+        assertEquals(2, countNonZeroLengthFiles(testRoot));\n \n         verifyAllAvroFiles(testRoot);\n     }\n@@ -182,7 +185,7 @@ public class AvroGenericRecordBoltTest {\n         bolt.execute(tuple2);\n \n         //Schema changes should have forced file rotations\n-        Assert.assertEquals(2, countNonZeroLengthFiles(testRoot));\n+        assertEquals(2, countNonZeroLengthFiles(testRoot));\n         verifyAllAvroFiles(testRoot);\n     }\n \n@@ -201,7 +204,7 @@ public class AvroGenericRecordBoltTest {\n         bolt.execute(tuple2);\n \n         //Two distinct schema should result in only two files\n-        Assert.assertEquals(2, countNonZeroLengthFiles(testRoot));\n+        assertEquals(2, countNonZeroLengthFiles(testRoot));\n         verifyAllAvroFiles(testRoot);\n     }\n \n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -1,145 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.storm.mongodb.trident.state;\n-\n-import com.google.common.collect.Lists;\n-\n-import java.io.Serializable;\n-import java.util.List;\n-import java.util.Map;\n-\n-import org.apache.commons.lang.Validate;\n-import org.apache.storm.mongodb.common.MongoDbClient;\n-import org.apache.storm.mongodb.common.QueryFilterCreator;\n-import org.apache.storm.mongodb.common.mapper.MongoLookupMapper;\n-import org.apache.storm.mongodb.common.mapper.MongoMapper;\n-import org.apache.storm.topology.FailedException;\n-import org.apache.storm.trident.operation.TridentCollector;\n-import org.apache.storm.trident.state.State;\n-import org.apache.storm.trident.tuple.TridentTuple;\n-import org.apache.storm.tuple.Values;\n-import org.bson.Document;\n-import org.bson.conversions.Bson;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-public class MongoState implements State {\n-\n-    private static final Logger LOG = LoggerFactory.getLogger(MongoState.class);\n-\n-    private Options options;\n-    private MongoDbClient mongoClient;\n-    private Map<String, Object> map;\n-\n-    protected MongoState(Map<String, Object> map, Options options) {\n-        this.options = options;\n-        this.map = map;\n-    }\n-\n-    public static class Options implements Serializable {\n-        private String url;\n-        private String collectionName;\n-        private MongoMapper mapper;\n-        private MongoLookupMapper lookupMapper;\n-        private QueryFilterCreator queryCreator;\n-\n-        public Options withUrl(String url) {\n-            this.url = url;\n-            return this;\n-        }\n-\n-        public Options withCollectionName(String collectionName) {\n-            this.collectionName = collectionName;\n-            return this;\n-        }\n-\n-        public Options withMapper(MongoMapper mapper) {\n-            this.mapper = mapper;\n-            return this;\n-        }\n-\n-        public Options withMongoLookupMapper(MongoLookupMapper lookupMapper) {\n-            this.lookupMapper = lookupMapper;\n-            return this;\n-        }\n-\n-        public Options withQueryFilterCreator(QueryFilterCreator queryCreator) {\n-            this.queryCreator = queryCreator;\n-            return this;\n-        }\n-    }\n-\n-    protected void prepare() {\n-        Validate.notEmpty(options.url, \"url can not be blank or null\");\n-        Validate.notEmpty(options.collectionName, \"collectionName can not be blank or null\");\n-\n-        this.mongoClient = new MongoDbClient(options.url, options.collectionName);\n-    }\n-\n-    @Override\n-    public void beginCommit(Long txid) {\n-        LOG.debug(\"beginCommit is noop.\");\n-    }\n-\n-    @Override\n-    public void commit(Long txid) {\n-        LOG.debug(\"commit is noop.\");\n-    }\n-\n-    /**\n-     * Update Mongo state.\n-     * @param tuples trident tuples\n-     * @param collector trident collector\n-     */\n-    public void updateState(List<TridentTuple> tuples, TridentCollector collector) {\n-        List<Document> documents = Lists.newArrayList();\n-        for (TridentTuple tuple : tuples) {\n-            Document document = options.mapper.toDocument(tuple);\n-            documents.add(document);\n-        }\n-\n-        try {\n-            this.mongoClient.insert(documents, true);\n-        } catch (Exception e) {\n-            LOG.warn(\"Batch write failed but some requests might have succeeded. Triggering replay.\", e);\n-            throw new FailedException(e);\n-        }\n-    }\n-\n-    /**\n-     * Batch retrieve values.\n-     * @param tridentTuples trident tuples\n-     * @return values\n-     */\n-    public List<List<Values>> batchRetrieve(List<TridentTuple> tridentTuples) {\n-        List<List<Values>> batchRetrieveResult = Lists.newArrayList();\n-        try {\n-            for (TridentTuple tuple : tridentTuples) {\n-                Bson filter = options.queryCreator.createFilter(tuple);\n-                Document doc = mongoClient.find(filter);\n-                List<Values> values = options.lookupMapper.toTuple(tuple, doc);\n-                batchRetrieveResult.add(values);\n-            }\n-        } catch (Exception e) {\n-            LOG.warn(\"Batch get operation failed. Triggering replay.\", e);\n-            throw new FailedException(e);\n-        }\n-        return batchRetrieveResult;\n-    }\n-}\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -1,4 +1,4 @@\n-/**\n+/*\n  * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with\n  * this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version\n  * 2.0 (the \"License\"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at\n@@ -13,11 +13,11 @@\n package org.apache.storm.security.auth;\n \n import org.apache.storm.security.auth.sasl.SaslTransportPlugin;\n-import org.junit.Test;\n+import org.junit.jupiter.api.Test;\n \n-import static org.junit.Assert.assertEquals;\n-import static org.junit.Assert.assertFalse;\n-import static org.junit.Assert.assertTrue;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n \n public class SaslTransportPluginTest {\n \n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -16,10 +16,10 @@ import java.sql.Date;\n import java.sql.Time;\n import java.sql.Timestamp;\n import java.sql.Types;\n-import org.junit.Test;\n+import org.junit.jupiter.api.Test;\n \n-import static org.junit.Assert.assertEquals;\n-import static org.junit.Assert.fail;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n \n public class UtilTest {\n \n@@ -46,20 +46,9 @@ public class UtilTest {\n \n     @Test\n     public void testError() {\n-        //This test is rather ugly, but it is the only way to see if the error messages are working correctly.\n-        try {\n-            Util.getJavaType(Types.REF);\n-            fail(\"didn't throw like expected\");\n-        } catch (Exception e) {\n-            assertEquals(\"We do not support tables with SqlType: REF\", e.getMessage());\n-        }\n-\n-        try {\n-            Util.getJavaType(-1000);\n-            fail(\"didn't throw like expected\");\n-        } catch (Exception e) {\n-            assertEquals(\"Unknown sqlType -1000\", e.getMessage());\n-        }\n-\n+        Exception e = assertThrows(Exception.class, () -> Util.getJavaType(Types.REF));\n+        assertEquals(\"We do not support tables with SqlType: REF\", e.getMessage());\n+        e = assertThrows(Exception.class, () -> Util.getJavaType(-1000));\n+        assertEquals(\"Unknown sqlType -1000\", e.getMessage());\n     }\n }\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -1,26 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version\n- * 2.0 (the \"License\"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the License for the specific language governing permissions\n- * and limitations under the License.\n- */\n-\n-package org.apache.storm.cassandra.trident.state;\n-\n-import java.util.List;\n-import org.apache.storm.trident.operation.TridentCollector;\n-import org.apache.storm.trident.state.BaseStateUpdater;\n-import org.apache.storm.trident.tuple.TridentTuple;\n-\n-public class CassandraStateUpdater extends BaseStateUpdater<CassandraState> {\n-\n-    @Override\n-    public void updateState(CassandraState state, List<TridentTuple> list, TridentCollector collector) {\n-        state.updateState(list, collector);\n-    }\n-}\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -1,123 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version\n- * 2.0 (the \"License\"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions\n- * and limitations under the License.\n- */\n-\n-package org.apache.storm.hbase.common;\n-\n-import java.io.IOException;\n-import java.math.BigDecimal;\n-import java.security.PrivilegedExceptionAction;\n-import org.apache.hadoop.conf.Configuration;\n-import org.apache.hadoop.hbase.TableName;\n-import org.apache.hadoop.hbase.client.ConnectionFactory;\n-import org.apache.hadoop.hbase.client.Table;\n-import org.apache.hadoop.hbase.security.UserProvider;\n-import org.apache.hadoop.hbase.util.Bytes;\n-import org.apache.hadoop.security.UserGroupInformation;\n-import org.apache.hadoop.security.token.Token;\n-import org.apache.hadoop.security.token.TokenIdentifier;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-public class Utils {\n-    public static final String TOKEN_KIND_HBASE_AUTH_TOKEN = \"HBASE_AUTH_TOKEN\";\n-    private static final Logger LOG = LoggerFactory.getLogger(Utils.class);\n-\n-    private Utils() {}\n-\n-    public static Table getTable(UserProvider provider, Configuration config, String tableName)\n-        throws IOException, InterruptedException {\n-        UserGroupInformation ugi;\n-        if (provider != null) {\n-            ugi = provider.getCurrent().getUGI();\n-            LOG.debug(\"Current USER for provider: {}\", ugi.getUserName());\n-        } else {\n-            // autocreds puts delegation token into current user UGI\n-            ugi = UserGroupInformation.getCurrentUser();\n-\n-            LOG.debug(\"UGI for current USER : {}\", ugi.getUserName());\n-            if (ugi.hasKerberosCredentials()) {\n-                LOG.debug(\"UGI has Kerberos credentials\");\n-            } else {\n-                boolean foundHBaseAuthToken = false;\n-                for (Token<? extends TokenIdentifier> token : ugi.getTokens()) {\n-                    LOG.debug(\"Token in UGI (delegation token): {} / {}\", token.toString(),\n-                            token.decodeIdentifier().getUser());\n-\n-                    // token.getKind() = Text, Text is annotated by @Stringable\n-                    // which ensures toString() implementation\n-                    if (token.getKind().toString().equals(TOKEN_KIND_HBASE_AUTH_TOKEN)) {\n-                        // use UGI from token\n-                        if (!foundHBaseAuthToken) {\n-                            LOG.debug(\"Found HBASE_AUTH_TOKEN - using the token to replace current user.\");\n-\n-                            ugi = token.decodeIdentifier().getUser();\n-                            ugi.addToken(token);\n-\n-                            foundHBaseAuthToken = true;\n-                        } else {\n-                            LOG.warn(\"Found multiple HBASE_AUTH_TOKEN - will use already found token. \"\n-                                    + \"Please enable DEBUG log level to track delegation tokens.\");\n-                        }\n-                    }\n-                }\n-\n-                if (!foundHBaseAuthToken) {\n-                    LOG.warn(\"Can't find HBase auth token in delegation tokens.\");\n-                }\n-            }\n-        }\n-\n-        return ugi.doAs(new PrivilegedExceptionAction<Table>() {\n-            @Override\n-            public Table run() throws IOException {\n-                return ConnectionFactory.createConnection(config).getTable(TableName.valueOf(tableName));\n-            }\n-        });\n-    }\n-\n-    public static long toLong(Object obj) {\n-        long l = 0;\n-        if (obj != null) {\n-            if (obj instanceof Number) {\n-                l = ((Number) obj).longValue();\n-            } else {\n-                LOG.warn(\"Could not coerce {} to Long\", obj.getClass().getName());\n-            }\n-        }\n-        return l;\n-    }\n-\n-    public static byte[] toBytes(Object obj) {\n-        if (obj == null) {\n-            return null;\n-        } else if (obj instanceof String) {\n-            return ((String) obj).getBytes();\n-        } else if (obj instanceof Integer) {\n-            return Bytes.toBytes((Integer) obj);\n-        } else if (obj instanceof Long) {\n-            return Bytes.toBytes((Long) obj);\n-        } else if (obj instanceof Short) {\n-            return Bytes.toBytes((Short) obj);\n-        } else if (obj instanceof Float) {\n-            return Bytes.toBytes((Float) obj);\n-        } else if (obj instanceof Double) {\n-            return Bytes.toBytes((Double) obj);\n-        } else if (obj instanceof Boolean) {\n-            return Bytes.toBytes((Boolean) obj);\n-        } else if (obj instanceof BigDecimal) {\n-            return Bytes.toBytes((BigDecimal) obj);\n-        } else {\n-            LOG.error(\"Can't convert class to byte array: \" + obj.getClass().getName());\n-            return new byte[0];\n-        }\n-    }\n-}\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -1,4 +1,4 @@\n-/**\n+/*\n  * Licensed to the Apache Software Foundation (ASF) under one\n  * or more contributor license agreements.  See the NOTICE file\n  * distributed with this work for additional information\n@@ -26,9 +26,8 @@ import java.util.UUID;\n \n import org.apache.storm.Config;\n import org.apache.storm.StormSubmitter;\n+import org.apache.storm.elasticsearch.common.DefaultEsTupleMapper;\n import org.apache.storm.elasticsearch.common.EsConfig;\n-import org.apache.storm.elasticsearch.common.EsConstants;\n-import org.apache.storm.elasticsearch.common.EsTestUtil;\n import org.apache.storm.elasticsearch.common.EsTupleMapper;\n import org.apache.storm.generated.AlreadyAliveException;\n import org.apache.storm.generated.AuthorizationException;\n@@ -68,16 +67,13 @@ public final class TridentEsTopology {\n         Stream stream = topology.newStream(\"spout\", spout);\n         EsConfig esConfig = new EsConfig(\"http://localhost:9300\");\n         Fields esFields = new Fields(\"index\", \"type\", \"source\");\n-        EsTupleMapper tupleMapper = EsTestUtil.generateDefaultTupleMapper();\n+        EsTupleMapper tupleMapper = new DefaultEsTupleMapper();\n         StateFactory factory = new EsStateFactory(esConfig, tupleMapper);\n         TridentState state = stream.partitionPersist(factory,\n                 esFields,\n                 new EsUpdater(),\n                 new Fields());\n \n-        EsTestUtil.startEsNode();\n-        EsTestUtil.waitForSeconds(EsConstants.WAIT_DEFAULT_SECS);\n-\n         StormSubmitter.submitTopology(TOPOLOGY_NAME,\n                 new Config(),\n                 topology.build());\n@@ -147,7 +143,7 @@ public final class TridentEsTopology {\n          */\n         @Override\n         public void open(final Map<String, Object> conf,\n-                final TopologyContext context) {\n+                         final TopologyContext context) {\n             index = 0;\n         }\n \n@@ -158,7 +154,7 @@ public final class TridentEsTopology {\n          */\n         @Override\n         public void emitBatch(final long batchId,\n-                final TridentCollector collector) {\n+                              final TridentCollector collector) {\n             List<List<Object>> batch = this.batches.get(batchId);\n             if (batch == null) {\n                 batch = new ArrayList<List<Object>>();\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -19,14 +19,12 @@\n package org.apache.storm.drpc;\n \n import java.util.ArrayList;\n+import java.util.Collections;\n import java.util.HashMap;\n-import java.util.Iterator;\n-import java.util.LinkedList;\n import java.util.List;\n import java.util.Map;\n-import java.util.concurrent.Callable;\n+import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Future;\n import java.util.concurrent.SynchronousQueue;\n import java.util.concurrent.TimeUnit;\n import org.apache.storm.Config;\n@@ -34,7 +32,7 @@ import org.apache.storm.ILocalDRPC;\n import org.apache.storm.generated.AuthorizationException;\n import org.apache.storm.generated.DRPCRequest;\n import org.apache.storm.generated.DistributedRPCInvocations;\n-import org.apache.storm.shade.org.json.simple.JSONValue;\n+import org.apache.storm.shade.net.minidev.json.JSONValue;\n import org.apache.storm.spout.SpoutOutputCollector;\n import org.apache.storm.task.TopologyContext;\n import org.apache.storm.thrift.TException;\n@@ -54,12 +52,13 @@ public class DRPCSpout extends BaseRichSpout {\n     public static final Logger LOG = LoggerFactory.getLogger(DRPCSpout.class);\n     //ANY CHANGE TO THIS CODE MUST BE SERIALIZABLE COMPATIBLE OR THERE WILL BE PROBLEMS\n     private static final long serialVersionUID = 2387848310969237877L;\n+    private static final int clientConstructionRetryIntervalSec = 120;\n     private final String function;\n     private final String localDrpcId;\n     private SpoutOutputCollector collector;\n-    private List<DRPCInvocationsClient> clients = new ArrayList<>();\n-    private transient LinkedList<Future<Void>> futures = null;\n+    private List<DRPCInvocationsClient> clients = Collections.synchronizedList(new ArrayList<>());\n     private transient ExecutorService background = null;\n+    private transient Map<String, CompletableFuture<Void>> futuresMap = null;  // server : future\n \n     public DRPCSpout(String function) {\n         this.function = function;\n@@ -81,13 +80,25 @@ public class DRPCSpout extends BaseRichSpout {\n     }\n \n     private void reconnectAsync(final DRPCInvocationsClient client) {\n-        futures.add(background.submit(new Callable<Void>() {\n-            @Override\n-            public Void call() throws Exception {\n-                client.reconnectClient();\n-                return null;\n-            }\n-        }));\n+        String remote = client.getHost();\n+        CompletableFuture<Void> future = futuresMap.get(remote);\n+        if (future.isDone()) {\n+            LOG.warn(\"DRPCInvocationsClient [{}:{}] connection failed, no pending reconnection. Try reconnecting...\",\n+                client.getHost(), client.getPort());\n+            CompletableFuture<Void> newFuture =\n+                CompletableFuture.runAsync(() -> {\n+                    try {\n+                        client.reconnectClient();\n+                        LOG.info(\"Reconnected to remote {}:{}. \",\n+                            client.getHost(), client.getPort());\n+                    } catch (Exception e) {\n+                        collector.reportError(e);\n+                        LOG.warn(\"Failed to reconnect to remote {}:{}. \",\n+                            client.getHost(), client.getPort(), e);\n+                    }\n+                }, background);\n+            futuresMap.put(remote, newFuture);\n+        }\n     }\n \n     private void reconnectSync(DRPCInvocationsClient client) {\n@@ -99,21 +110,6 @@ public class DRPCSpout extends BaseRichSpout {\n         }\n     }\n \n-    private void checkFutures() {\n-        Iterator<Future<Void>> i = futures.iterator();\n-        while (i.hasNext()) {\n-            Future<Void> f = i.next();\n-            if (f.isDone()) {\n-                i.remove();\n-            }\n-            try {\n-                f.get();\n-            } catch (Exception e) {\n-                throw new RuntimeException(e);\n-            }\n-        }\n-    }\n-\n     @Override\n     public void open(Map<String, Object> conf, TopologyContext context, SpoutOutputCollector collector) {\n         this.collector = collector;\n@@ -121,8 +117,7 @@ public class DRPCSpout extends BaseRichSpout {\n             background = new ExtendedThreadPoolExecutor(0, Integer.MAX_VALUE,\n                                                         60L, TimeUnit.SECONDS,\n                                                         new SynchronousQueue<Runnable>());\n-            futures = new LinkedList<>();\n-\n+            futuresMap = new HashMap<>();\n             int numTasks = context.getComponentTasks(context.getThisComponentId()).size();\n             int index = context.getThisTaskIndex();\n \n@@ -132,16 +127,28 @@ public class DRPCSpout extends BaseRichSpout {\n                 throw new RuntimeException(\"No DRPC servers configured for topology\");\n             }\n \n+            List<DRPCClientBuilder> clientBuilders = new ArrayList<>();\n             if (numTasks < servers.size()) {\n                 for (String s : servers) {\n-                    futures.add(background.submit(new Adder(s, port, conf)));\n+                    clientBuilders.add(new DRPCClientBuilder(s, port, conf));\n                 }\n             } else {\n                 int i = index % servers.size();\n-                futures.add(background.submit(new Adder(servers.get(i), port, conf)));\n+                clientBuilders.add(new DRPCClientBuilder(servers.get(i), port, conf));\n             }\n+            establishConnections(clientBuilders);\n         }\n+    }\n \n+    protected void establishConnections(List<DRPCClientBuilder> clientBuilders) {\n+        int numOfClients = clientBuilders.size();\n+\n+        for (int i = 0; i < numOfClients; i++) {\n+            DRPCClientBuilder builder = clientBuilders.get(i);\n+            String server = builder.getServer();\n+            CompletableFuture<Void> future = CompletableFuture.runAsync(builder, background);\n+            futuresMap.put(server, future);\n+        }\n     }\n \n     @Override\n@@ -149,22 +156,18 @@ public class DRPCSpout extends BaseRichSpout {\n         for (DRPCInvocationsClient client : clients) {\n             client.close();\n         }\n+        if (background != null) {\n+            background.shutdownNow();\n+        }\n     }\n \n     @Override\n     public void nextTuple() {\n         if (localDrpcId == null) {\n-            int size = 0;\n-            synchronized (clients) {\n-                size = clients.size(); //This will only ever grow, so no need to worry about falling off the end\n-            }\n-            for (int i = 0; i < size; i++) {\n-                DRPCInvocationsClient client;\n-                synchronized (clients) {\n-                    client = clients.get(i);\n-                }\n+            //This will only ever grow and at least one client has been up\n+            for (int i = 0; i < clients.size(); i++) {\n+                DRPCInvocationsClient client = clients.get(i);\n                 if (!client.isConnected()) {\n-                    LOG.warn(\"DRPCInvocationsClient [{}:{}] is not connected.\", client.getHost(), client.getPort());\n                     reconnectAsync(client);\n                     continue;\n                 }\n@@ -180,16 +183,15 @@ public class DRPCSpout extends BaseRichSpout {\n                         break;\n                     }\n                 } catch (AuthorizationException aze) {\n+                    LOG.error(\"Not authorized to fetch DRPC request from DRPC server [{}:{}]\",\n+                        client.getHost(), client.getPort(), aze);\n                     reconnectAsync(client);\n-                    LOG.error(\"Not authorized to fetch DRPC request from DRPC server\", aze);\n-                } catch (TException e) {\n-                    reconnectAsync(client);\n-                    LOG.error(\"Failed to fetch DRPC request from DRPC server\", e);\n                 } catch (Exception e) {\n-                    LOG.error(\"Failed to fetch DRPC request from DRPC server\", e);\n+                    LOG.error(\"Failed to fetch DRPC request from DRPC server [{}:{}]\",\n+                        client.getHost(), client.getPort(), e);\n+                    reconnectAsync(client);\n                 }\n             }\n-            checkFutures();\n         } else {\n             DistributedRPCInvocations.Iface drpc = (DistributedRPCInvocations.Iface) ServiceRegistry.getService(localDrpcId);\n             if (drpc != null) { // can happen during shutdown of drpc while topology is still up\n@@ -264,24 +266,47 @@ public class DRPCSpout extends BaseRichSpout {\n         }\n     }\n \n-    private class Adder implements Callable<Void> {\n+    private class DRPCClientBuilder implements Runnable {\n         private String server;\n         private int port;\n         private Map<String, Object> conf;\n \n-        Adder(String server, int port, Map<String, Object> conf) {\n+        DRPCClientBuilder(String server, int port, Map<String, Object> conf) {\n             this.server = server;\n             this.port = port;\n             this.conf = conf;\n         }\n \n         @Override\n-        public Void call() throws Exception {\n-            DRPCInvocationsClient c = new DRPCInvocationsClient(conf, server, port);\n-            synchronized (clients) {\n+        public void run() {\n+            DRPCInvocationsClient c = null;\n+            while (c == null) {\n+                try {\n+                    // DRPCInvocationsClient has backoff retry logic\n+                    c = new DRPCInvocationsClient(conf, server, port);\n+                } catch (Exception e) {\n+                    collector.reportError(e);\n+                    LOG.error(\"Failed to create DRPCInvocationsClient for remote {}:{}. Retrying after {} secs.\",\n+                        server, port, clientConstructionRetryIntervalSec, e);\n+                    try {\n+                        Thread.sleep(clientConstructionRetryIntervalSec * 1000);\n+                    } catch (InterruptedException ex) {\n+                        LOG.warn(\"DRPCInvocationsClient creation retry sleep interrupted.\");\n+                        break;\n+                    }\n+                }\n+            }\n+            if (c != null) {\n+                LOG.info(\"Successfully created DRPCInvocationsClient for remote {}:{}.\", server, port);\n                 clients.add(c);\n+            } else {\n+                LOG.warn(\"DRPCInvocationsClient creation retry for remote {}:{} interrupted.\",\n+                    server, port);\n             }\n-            return null;\n+        }\n+\n+        public String getServer() {\n+            return server;\n         }\n     }\n }\n",
            "security_relevancy": "potentially_security_relevant"
        },
        {
            "diff": "@@ -1,301 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version\n- * 2.0 (the \"License\"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions\n- * and limitations under the License.\n- */\n-\n-package org.apache.storm.mqtt.common;\n-\n-import java.io.Serializable;\n-import java.util.List;\n-\n-/**\n- * MQTT Configuration Options.\n- */\n-public class MqttOptions implements Serializable {\n-    private String url = \"tcp://localhost:1883\";\n-    private List<String> topics = null;\n-    private boolean cleanConnection = false;\n-\n-    private String willTopic;\n-    private String willPayload;\n-    private int willQos = 1;\n-    private boolean willRetain = false;\n-\n-    private long reconnectDelay = 10;\n-    private long reconnectDelayMax = 30 * 1000;\n-    private double reconnectBackOffMultiplier = 2.0f;\n-    private long reconnectAttemptsMax = -1;\n-    private long connectAttemptsMax = -1;\n-\n-    private String userName = \"\";\n-    private String password = \"\";\n-\n-    private int qos = 1;\n-\n-    public String getUrl() {\n-        return url;\n-    }\n-\n-    /**\n-     * Sets the url for connecting to the MQTT broker, e.g. {@code tcp://localhost:1883}.\n-     */\n-    public void setUrl(String url) {\n-        this.url = url;\n-    }\n-\n-    public List<String> getTopics() {\n-        return topics;\n-    }\n-\n-    /**\n-     * A list of MQTT topics to subscribe to.\n-     */\n-    public void setTopics(List<String> topics) {\n-        this.topics = topics;\n-    }\n-\n-    public boolean isCleanConnection() {\n-        return cleanConnection;\n-    }\n-\n-    /**\n-     * Set to false if you want the MQTT server to persist topic subscriptions and ack positions across client sessions.\n-     * Defaults to false.\n-     */\n-    public void setCleanConnection(boolean cleanConnection) {\n-        this.cleanConnection = cleanConnection;\n-    }\n-\n-    public String getWillTopic() {\n-        return willTopic;\n-    }\n-\n-    /**\n-     * If set the server will publish the client's Will message to the specified topics if the client has an unexpected\n-     * disconnection.\n-     */\n-    public void setWillTopic(String willTopic) {\n-        this.willTopic = willTopic;\n-    }\n-\n-    public String getWillPayload() {\n-        return willPayload;\n-    }\n-\n-    /**\n-     * The Will message to send. Defaults to a zero length message.\n-     */\n-    public void setWillPayload(String willPayload) {\n-        this.willPayload = willPayload;\n-    }\n-\n-    public long getReconnectDelay() {\n-        return reconnectDelay;\n-    }\n-\n-    /**\n-     * How long to wait in ms before the first reconnect attempt. Defaults to 10.\n-     */\n-    public void setReconnectDelay(long reconnectDelay) {\n-        this.reconnectDelay = reconnectDelay;\n-    }\n-\n-    public long getReconnectDelayMax() {\n-        return reconnectDelayMax;\n-    }\n-\n-    /**\n-     * The maximum amount of time in ms to wait between reconnect attempts. Defaults to 30,000.\n-     */\n-    public void setReconnectDelayMax(long reconnectDelayMax) {\n-        this.reconnectDelayMax = reconnectDelayMax;\n-    }\n-\n-    public double getReconnectBackOffMultiplier() {\n-        return reconnectBackOffMultiplier;\n-    }\n-\n-    /**\n-     * The Exponential backoff be used between reconnect attempts. Set to 1 to disable exponential backoff. Defaults to\n-     * 2.\n-     */\n-    public void setReconnectBackOffMultiplier(double reconnectBackOffMultiplier) {\n-        this.reconnectBackOffMultiplier = reconnectBackOffMultiplier;\n-    }\n-\n-    public long getReconnectAttemptsMax() {\n-        return reconnectAttemptsMax;\n-    }\n-\n-    /**\n-     * The maximum number of reconnect attempts before an error is reported back to the client after a server\n-     * connection had previously been established. Set to -1 to use unlimited attempts. Defaults to -1.\n-     */\n-    public void setReconnectAttemptsMax(long reconnectAttemptsMax) {\n-        this.reconnectAttemptsMax = reconnectAttemptsMax;\n-    }\n-\n-    public long getConnectAttemptsMax() {\n-        return connectAttemptsMax;\n-    }\n-\n-    /**\n-     * The maximum number of reconnect attempts before an error is reported back to the client on the first attempt by\n-     * the client to connect to a server. Set to -1 to use unlimited attempts. Defaults to -1.\n-     */\n-    public void setConnectAttemptsMax(long connectAttemptsMax) {\n-        this.connectAttemptsMax = connectAttemptsMax;\n-    }\n-\n-    public String getUserName() {\n-        return userName;\n-    }\n-\n-    /**\n-     * The username for authenticated sessions.\n-     */\n-    public void setUserName(String userName) {\n-        this.userName = userName;\n-    }\n-\n-    public String getPassword() {\n-        return password;\n-    }\n-\n-    /**\n-     * The password for authenticated sessions.\n-     */\n-    public void setPassword(String password) {\n-        this.password = password;\n-    }\n-\n-    public int getQos() {\n-        return this.qos;\n-    }\n-\n-    /**\n-     * Sets the quality of service to use for MQTT messages. Defaults to 1 (at least once).\n-     */\n-    public void setQos(int qos) {\n-        if (qos < 0 || qos > 2) {\n-            throw new IllegalArgumentException(\"MQTT QoS must be >= 0 and <= 2\");\n-        }\n-        this.qos = qos;\n-    }\n-\n-    public int getWillQos() {\n-        return this.willQos;\n-    }\n-\n-    /**\n-     * Sets the quality of service to use for the MQTT Will message. Defaults to 1 (at least once).\n-     */\n-    public void setWillQos(int qos) {\n-        if (qos < 0 || qos > 2) {\n-            throw new IllegalArgumentException(\"MQTT Will QoS must be >= 0 and <= 2\");\n-        }\n-        this.willQos = qos;\n-    }\n-\n-    public boolean getWillRetain() {\n-        return this.willRetain;\n-    }\n-\n-    /**\n-     * Set to true if you want the Will message to be published with the retain option.\n-     */\n-    public void setWillRetain(boolean retain) {\n-        this.willRetain = retain;\n-    }\n-\n-    public static class Builder {\n-        private MqttOptions options = new MqttOptions();\n-\n-        public Builder url(String url) {\n-            this.options.url = url;\n-            return this;\n-        }\n-\n-\n-        public Builder topics(List<String> topics) {\n-            this.options.topics = topics;\n-            return this;\n-        }\n-\n-        public Builder cleanConnection(boolean cleanConnection) {\n-            this.options.cleanConnection = cleanConnection;\n-            return this;\n-        }\n-\n-        public Builder willTopic(String willTopic) {\n-            this.options.willTopic = willTopic;\n-            return this;\n-        }\n-\n-        public Builder willPayload(String willPayload) {\n-            this.options.willPayload = willPayload;\n-            return this;\n-        }\n-\n-        public Builder willRetain(boolean retain) {\n-            this.options.willRetain = retain;\n-            return this;\n-        }\n-\n-        public Builder willQos(int qos) {\n-            this.options.setWillQos(qos);\n-            return this;\n-        }\n-\n-        public Builder reconnectDelay(long reconnectDelay) {\n-            this.options.reconnectDelay = reconnectDelay;\n-            return this;\n-        }\n-\n-        public Builder reconnectDelayMax(long reconnectDelayMax) {\n-            this.options.reconnectDelayMax = reconnectDelayMax;\n-            return this;\n-        }\n-\n-        public Builder reconnectBackOffMultiplier(double reconnectBackOffMultiplier) {\n-            this.options.reconnectBackOffMultiplier = reconnectBackOffMultiplier;\n-            return this;\n-        }\n-\n-        public Builder reconnectAttemptsMax(long reconnectAttemptsMax) {\n-            this.options.reconnectAttemptsMax = reconnectAttemptsMax;\n-            return this;\n-        }\n-\n-        public Builder connectAttemptsMax(long connectAttemptsMax) {\n-            this.options.connectAttemptsMax = connectAttemptsMax;\n-            return this;\n-        }\n-\n-        public Builder userName(String userName) {\n-            this.options.userName = userName;\n-            return this;\n-        }\n-\n-        public Builder password(String password) {\n-            this.options.password = password;\n-            return this;\n-        }\n-\n-        public Builder qos(int qos) {\n-            this.options.setQos(qos);\n-            return this;\n-        }\n-\n-        public MqttOptions build() {\n-            return this.options;\n-        }\n-    }\n-}\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -15,9 +15,9 @@ package org.apache.storm.hdfs.spout;\n import java.util.HashMap;\n import java.util.Map;\n import org.apache.storm.validation.ConfigValidation;\n-import org.junit.Test;\n+import org.junit.jupiter.api.Test;\n \n-import static org.junit.Assert.fail;\n+import static org.junit.jupiter.api.Assertions.fail;\n \n public class ConfigsTest {\n \n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -1,43 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.storm.mongodb.trident.state;\n-\n-import java.util.Map;\n-\n-import org.apache.storm.task.IMetricsContext;\n-import org.apache.storm.trident.state.State;\n-import org.apache.storm.trident.state.StateFactory;\n-\n-public class MongoStateFactory implements StateFactory {\n-\n-    private MongoState.Options options;\n-\n-    public MongoStateFactory(MongoState.Options options) {\n-        this.options = options;\n-    }\n-\n-    @Override\n-    public State makeState(Map<String, Object> conf, IMetricsContext metrics,\n-            int partitionIndex, int numPartitions) {\n-        MongoState state = new MongoState(conf, options);\n-        state.prepare();\n-        return state;\n-    }\n-\n-}\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -29,13 +29,14 @@ import org.apache.storm.sql.runtime.FieldInfo;\n import org.apache.storm.sql.runtime.ISqlStreamsDataSource;\n import org.apache.storm.streams.Pair;\n import org.apache.storm.tuple.Values;\n-import org.junit.Assert;\n import org.junit.jupiter.api.AfterAll;\n-import org.junit.jupiter.api.Assertions;\n import org.junit.jupiter.api.BeforeAll;\n import org.junit.jupiter.api.Test;\n import org.junit.jupiter.api.extension.ExtendWith;\n \n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n+\n @ExtendWith(TestUtils.MockBoltExtension.class)\n @ExtendWith(TestUtils.MockInsertBoltExtension.class)\n public class TestStormSql {\n@@ -82,9 +83,9 @@ public class TestStormSql {\n         List<Pair<Object, Values>> values = TestUtils.MockInsertBolt.getCollectedValues();\n         impl.runLocal(cluster, stmt, (__) -> values.size() >= 2, WAIT_TIMEOUT_MS);\n \n-        Assert.assertEquals(2, values.size());\n-        Assert.assertEquals(4, values.get(0).getFirst());\n-        Assert.assertEquals(5, values.get(1).getFirst());\n+        assertEquals(2, values.size());\n+        assertEquals(4, values.get(0).getFirst());\n+        assertEquals(5, values.get(1).getFirst());\n     }\n \n     @Test\n@@ -102,8 +103,8 @@ public class TestStormSql {\n \n         Map<String, Integer> map = ImmutableMap.of(\"b\", 2, \"c\", 4);\n         Map<String, Map<String, Integer>> nestedMap = ImmutableMap.of(\"a\", map);\n-        Assert.assertEquals(2, values.get(0).getFirst());\n-        Assert.assertEquals(new Values(2, 4, nestedMap, Arrays.asList(100, 200, 300)), values.get(0).getSecond());\n+        assertEquals(2, values.get(0).getFirst());\n+        assertEquals(new Values(2, 4, nestedMap, Arrays.asList(100, 200, 300)), values.get(0).getSecond());\n     }\n \n     @Test\n@@ -120,7 +121,7 @@ public class TestStormSql {\n         List<Pair<Object, Values>> values = TestUtils.MockInsertBolt.getCollectedValues();\n         impl.runLocal(cluster, stmt, (__) -> true, WAIT_TIMEOUT_MS_NO_RECORDS_EXPECTED);\n \n-        Assert.assertEquals(0, values.size());\n+        assertEquals(0, values.size());\n     }\n \n     @Test\n@@ -137,7 +138,7 @@ public class TestStormSql {\n         List<Pair<Object, Values>> values = TestUtils.MockInsertBolt.getCollectedValues();\n         impl.runLocal(cluster, stmt, (__) -> true, WAIT_TIMEOUT_MS_NO_RECORDS_EXPECTED);\n \n-        Assert.assertEquals(0, values.size());\n+        assertEquals(0, values.size());\n     }\n \n     @Test\n@@ -153,7 +154,7 @@ public class TestStormSql {\n         List<Pair<Object, Values>> values = TestUtils.MockInsertBolt.getCollectedValues();\n         impl.runLocal(cluster, stmt, (__) -> true, WAIT_TIMEOUT_MS_NO_RECORDS_EXPECTED);\n \n-        Assert.assertEquals(0, values.size());\n+        assertEquals(0, values.size());\n     }\n \n     @Test\n@@ -169,7 +170,7 @@ public class TestStormSql {\n         List<Pair<Object, Values>> values = TestUtils.MockInsertBolt.getCollectedValues();\n         impl.runLocal(cluster, stmt, (__) -> true, WAIT_TIMEOUT_MS_NO_RECORDS_EXPECTED);\n \n-        Assert.assertEquals(0, values.size());\n+        assertEquals(0, values.size());\n     }\n \n     @Test\n@@ -181,7 +182,7 @@ public class TestStormSql {\n         stmt.add(\"INSERT INTO BAR SELECT STREAM MYPLUS(NAME, 1) FROM FOO WHERE ID = 0\");\n         StormSqlLocalClusterImpl impl = new StormSqlLocalClusterImpl();\n \n-        Assertions.assertThrows(ValidationException.class,\n+        assertThrows(ValidationException.class,\n             () -> impl.runLocal(cluster, stmt, (__) -> true, WAIT_TIMEOUT_MS_ERROR_EXPECTED));\n     }\n \n@@ -195,7 +196,7 @@ public class TestStormSql {\n         stmt.add(\"INSERT INTO BAR SELECT STREAM ID FROM FOO WHERE MYPLUS(ID, 1) = 'x'\");\n         StormSqlLocalClusterImpl impl = new StormSqlLocalClusterImpl();\n \n-        Assertions.assertThrows(CompilingClassLoader.CompilerException.class,\n+        assertThrows(CompilingClassLoader.CompilerException.class,\n             () -> impl.runLocal(cluster, stmt, (__) -> true, WAIT_TIMEOUT_MS_ERROR_EXPECTED));\n     }\n \n@@ -211,9 +212,9 @@ public class TestStormSql {\n         List<Pair<Object, Values>> values = TestUtils.MockInsertBolt.getCollectedValues();\n         impl.runLocal(cluster, stmt, (__) -> values.size() >= 2, WAIT_TIMEOUT_MS);\n \n-        Assert.assertEquals(2, values.size());\n-        Assert.assertEquals(4, values.get(0).getFirst());\n-        Assert.assertEquals(5, values.get(1).getFirst());\n+        assertEquals(2, values.size());\n+        assertEquals(4, values.get(0).getFirst());\n+        assertEquals(5, values.get(1).getFirst());\n     }\n \n     @Test\n@@ -225,7 +226,7 @@ public class TestStormSql {\n         stmt.add(\"INSERT INTO BAR SELECT STREAM MYPLUS(ID, 1) FROM FOO WHERE ID > 2\");\n         StormSqlLocalClusterImpl impl = new StormSqlLocalClusterImpl();\n \n-        Assertions.assertThrows(UnsupportedOperationException.class,\n+        assertThrows(UnsupportedOperationException.class,\n             () -> impl.runLocal(cluster, stmt, (__) -> true, WAIT_TIMEOUT_MS_ERROR_EXPECTED));\n     }\n \n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -1,320 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version\n- * 2.0 (the \"License\"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the License for the specific language governing permissions\n- * and limitations under the License.\n- */\n-\n-package org.apache.storm.cassandra.client;\n-\n-import com.datastax.driver.core.ConsistencyLevel;\n-import com.datastax.driver.core.SocketOptions;\n-import com.datastax.driver.core.policies.DCAwareRoundRobinPolicy;\n-import com.datastax.driver.core.policies.DCAwareRoundRobinPolicy.Builder;\n-import com.datastax.driver.core.policies.DefaultRetryPolicy;\n-import com.datastax.driver.core.policies.DowngradingConsistencyRetryPolicy;\n-import com.datastax.driver.core.policies.FallthroughRetryPolicy;\n-import com.datastax.driver.core.policies.LoadBalancingPolicy;\n-import com.datastax.driver.core.policies.LoggingRetryPolicy;\n-import com.datastax.driver.core.policies.RetryPolicy;\n-import com.datastax.driver.core.policies.RoundRobinPolicy;\n-import com.datastax.driver.core.policies.TokenAwarePolicy;\n-import com.google.common.base.Objects;\n-import java.io.Serializable;\n-import java.util.Map;\n-import java.util.concurrent.TimeUnit;\n-import org.apache.commons.lang3.StringUtils;\n-import org.apache.storm.utils.ObjectReader;\n-import org.apache.storm.utils.Utils;\n-\n-/**\n- * Configuration used by cassandra storm components.\n- */\n-public class CassandraConf implements Serializable {\n-\n-    public static final String CASSANDRA_USERNAME = \"cassandra.username\";\n-    public static final String CASSANDRA_PASSWORD = \"cassandra.password\";\n-    public static final String CASSANDRA_KEYSPACE = \"cassandra.keyspace\";\n-    public static final String CASSANDRA_CONSISTENCY_LEVEL = \"cassandra.output.consistencyLevel\";\n-    public static final String CASSANDRA_NODES = \"cassandra.nodes\";\n-    public static final String CASSANDRA_PORT = \"cassandra.port\";\n-    public static final String CASSANDRA_BATCH_SIZE_ROWS = \"cassandra.batch.size.rows\";\n-    public static final String CASSANDRA_RETRY_POLICY = \"cassandra.retryPolicy\";\n-    public static final String CASSANDRA_RECONNECT_POLICY_BASE_MS = \"cassandra.reconnectionPolicy.baseDelayMs\";\n-    public static final String CASSANDRA_RECONNECT_POLICY_MAX_MS = \"cassandra.reconnectionPolicy.maxDelayMs\";\n-    public static final String CASSANDRA_POOL_MAX_SIZE = \"cassandra.pool.max.size\";\n-    public static final String CASSANDRA_LOAD_BALANCING_POLICY = \"cassandra.loadBalancingPolicy\";\n-    public static final String CASSANDRA_DATACENTER_NAME = \"cassandra.datacenter.name\";\n-    public static final String CASSANDRA_MAX_REQUESTS_PER_CON_LOCAL = \"cassandra.max.requests.per.con.local\";\n-    public static final String CASSANDRA_MAX_REQUESTS_PER_CON_REMOTE = \"cassandra.max.requests.per.con.remote\";\n-    public static final String CASSANDRA_HEARTBEAT_INTERVAL_SEC = \"cassandra.heartbeat.interval.sec\";\n-    public static final String CASSANDRA_IDLE_TIMEOUT_SEC = \"cassandra.idle.timeout.sec\";\n-    public static final String CASSANDRA_SOCKET_READ_TIMEOUT_MS = \"cassandra.socket.read.timeout.millis\";\n-    public static final String CASSANDRA_SOCKET_CONNECT_TIMEOUT_MS = \"cassandra.socket.connect.timeout.millis\";\n-\n-    /**\n-     * The authorized cassandra username.\n-     */\n-    private String username;\n-    /**\n-     * The authorized cassandra password.\n-     */\n-    private String password;\n-    /**\n-     * The cassandra keyspace.\n-     */\n-    private String keyspace;\n-    /**\n-     * List of contacts nodes.\n-     */\n-    private String[] nodes = { \"localhost\" };\n-\n-    /**\n-     * The port used to connect to nodes.\n-     */\n-    private int port = 9092;\n-\n-    /**\n-     * Consistency level used to write statements.\n-     */\n-    private ConsistencyLevel consistencyLevel = ConsistencyLevel.ONE;\n-    /**\n-     * The maximal numbers of rows per batch.\n-     */\n-    private int batchSizeRows = 100;\n-\n-    /**\n-     * The retry policy to use for the new cluster.\n-     */\n-    private String retryPolicyName;\n-\n-    /**\n-     * The base delay in milliseconds to use for the reconnection policy.\n-     */\n-    private long reconnectionPolicyBaseMs;\n-\n-    /**\n-     * The maximum delay to wait between two attempts.\n-     */\n-    private long reconnectionPolicyMaxMs;\n-\n-    /**\n-     * The maximum queue for connection pool.\n-     */\n-    private int poolMaxQueueSize;\n-\n-    private String loadBalancingPolicyName;\n-\n-    private String datacenterName;\n-\n-    private int maxRequestPerConnectionLocal;\n-\n-    private int maxRequestPerConnectionRemote;\n-\n-    private int heartbeatIntervalSeconds;\n-\n-    private int idleTimeoutSeconds;\n-\n-    /**\n-     * The timeout for read for socket options.\n-     */\n-    private long socketReadTimeoutMillis;\n-\n-    /**\n-     * The timeout for connect for socket options.\n-     */\n-    private long socketConnectTimeoutMillis;\n-\n-    /**\n-     * Creates a new {@link CassandraConf} instance.\n-     */\n-    public CassandraConf() {\n-        super();\n-    }\n-\n-    /**\n-     * Creates a new {@link CassandraConf} instance.\n-     *\n-     * @param conf The storm configuration.\n-     */\n-    public CassandraConf(Map<String, Object> conf) {\n-\n-        this.username = (String) Utils.get(conf, CASSANDRA_USERNAME, null);\n-        this.password = (String) Utils.get(conf, CASSANDRA_PASSWORD, null);\n-        this.keyspace = get(conf, CASSANDRA_KEYSPACE);\n-        this.consistencyLevel =\n-            ConsistencyLevel.valueOf((String) Utils.get(conf, CASSANDRA_CONSISTENCY_LEVEL, ConsistencyLevel.ONE.name()));\n-        this.nodes = ((String) Utils.get(conf, CASSANDRA_NODES, \"localhost\")).split(\",\");\n-        this.batchSizeRows = ObjectReader.getInt(conf.get(CASSANDRA_BATCH_SIZE_ROWS), 100);\n-        this.port = ObjectReader.getInt(conf.get(CASSANDRA_PORT), 9042);\n-        this.retryPolicyName = (String) Utils.get(conf, CASSANDRA_RETRY_POLICY, DefaultRetryPolicy.class.getSimpleName());\n-        this.reconnectionPolicyBaseMs = getLong(conf.get(CASSANDRA_RECONNECT_POLICY_BASE_MS), 100L);\n-        this.reconnectionPolicyMaxMs = getLong(conf.get(CASSANDRA_RECONNECT_POLICY_MAX_MS), TimeUnit.MINUTES.toMillis(1));\n-        this.poolMaxQueueSize = getInt(conf.get(CASSANDRA_POOL_MAX_SIZE), 256);\n-        this.loadBalancingPolicyName = (String) Utils.get(conf, CASSANDRA_LOAD_BALANCING_POLICY, TokenAwarePolicy.class.getSimpleName());\n-        this.datacenterName = (String) Utils.get(conf, CASSANDRA_DATACENTER_NAME, null);\n-        this.maxRequestPerConnectionLocal = getInt(conf.get(CASSANDRA_MAX_REQUESTS_PER_CON_LOCAL), 1024);\n-        this.maxRequestPerConnectionRemote = getInt(conf.get(CASSANDRA_MAX_REQUESTS_PER_CON_REMOTE), 256);\n-        this.heartbeatIntervalSeconds = getInt(conf.get(CASSANDRA_HEARTBEAT_INTERVAL_SEC), 30);\n-        this.idleTimeoutSeconds = getInt(conf.get(CASSANDRA_IDLE_TIMEOUT_SEC), 60);\n-        this.socketReadTimeoutMillis =\n-            getLong(conf.get(CASSANDRA_SOCKET_READ_TIMEOUT_MS), (long) SocketOptions.DEFAULT_READ_TIMEOUT_MILLIS);\n-        this.socketConnectTimeoutMillis =\n-            getLong(conf.get(CASSANDRA_SOCKET_CONNECT_TIMEOUT_MS), (long) SocketOptions.DEFAULT_CONNECT_TIMEOUT_MILLIS);\n-    }\n-\n-    public static Integer getInt(Object o, Integer defaultValue) {\n-        if (null == o) {\n-            return defaultValue;\n-        }\n-        if (o instanceof Number) {\n-            return ((Number) o).intValue();\n-        } else if (o instanceof String) {\n-            return Integer.parseInt((String) o);\n-        }\n-        throw new IllegalArgumentException(\"Don't know how to convert \" + o + \" to int\");\n-    }\n-\n-    public static Long getLong(Object o, Long defaultValue) {\n-        if (null == o) {\n-            return defaultValue;\n-        }\n-        if (o instanceof Number) {\n-            return ((Number) o).longValue();\n-        } else if (o instanceof String) {\n-            return Long.parseLong((String) o);\n-        }\n-        throw new IllegalArgumentException(\"Don't know how to convert \" + o + \" to long\");\n-    }\n-\n-    public String getUsername() {\n-        return username;\n-    }\n-\n-    public String getPassword() {\n-        return password;\n-    }\n-\n-    public String getKeyspace() {\n-        return keyspace;\n-    }\n-\n-    public String[] getNodes() {\n-        return nodes;\n-    }\n-\n-    public ConsistencyLevel getConsistencyLevel() {\n-        return consistencyLevel;\n-    }\n-\n-    public int getBatchSizeRows() {\n-        return batchSizeRows;\n-    }\n-\n-    public int getPort() {\n-        return this.port;\n-    }\n-\n-    public long getReconnectionPolicyBaseMs() {\n-        return reconnectionPolicyBaseMs;\n-    }\n-\n-    public long getReconnectionPolicyMaxMs() {\n-        return reconnectionPolicyMaxMs;\n-    }\n-\n-    public RetryPolicy getRetryPolicy() {\n-        if (this.retryPolicyName.equals(DowngradingConsistencyRetryPolicy.class.getSimpleName())) {\n-            return new LoggingRetryPolicy(DowngradingConsistencyRetryPolicy.INSTANCE);\n-        }\n-        if (this.retryPolicyName.equals(FallthroughRetryPolicy.class.getSimpleName())) {\n-            return FallthroughRetryPolicy.INSTANCE;\n-        }\n-        if (this.retryPolicyName.equals(DefaultRetryPolicy.class.getSimpleName())) {\n-            return DefaultRetryPolicy.INSTANCE;\n-        }\n-        throw new IllegalArgumentException(\"Unknown cassandra retry policy \" + this.retryPolicyName);\n-    }\n-\n-    public LoadBalancingPolicy getLoadBalancingPolicy() {\n-        if (this.loadBalancingPolicyName.equals(TokenAwarePolicy.class.getSimpleName())) {\n-            return new TokenAwarePolicy(new RoundRobinPolicy());\n-        }\n-        if (this.loadBalancingPolicyName.equals(DCAwareRoundRobinPolicy.class.getSimpleName())) {\n-            Builder builder = DCAwareRoundRobinPolicy.builder();\n-            if (StringUtils.isNotBlank(datacenterName)) {\n-                builder = builder.withLocalDc(this.datacenterName);\n-            }\n-            return new TokenAwarePolicy(builder.build());\n-        }\n-        throw new IllegalArgumentException(\"Unknown cassandra load balancing policy \" + this.loadBalancingPolicyName);\n-    }\n-\n-    public int getPoolMaxQueueSize() {\n-        return poolMaxQueueSize;\n-    }\n-\n-    public String getDatacenterName() {\n-        return datacenterName;\n-    }\n-\n-    public int getMaxRequestPerConnectionLocal() {\n-        return maxRequestPerConnectionLocal;\n-    }\n-\n-    public int getMaxRequestPerConnectionRemote() {\n-        return maxRequestPerConnectionRemote;\n-    }\n-\n-    public int getHeartbeatIntervalSeconds() {\n-        return heartbeatIntervalSeconds;\n-    }\n-\n-    public int getIdleTimeoutSeconds() {\n-        return idleTimeoutSeconds;\n-    }\n-\n-    public long getSocketReadTimeoutMillis() {\n-        return socketReadTimeoutMillis;\n-    }\n-\n-    public long getSocketConnectTimeoutMillis() {\n-        return socketConnectTimeoutMillis;\n-    }\n-\n-    private <T> T get(Map<String, Object> conf, String key) {\n-        Object o = conf.get(key);\n-        if (o == null) {\n-            throw new IllegalArgumentException(\"No '\" + key + \"' value found in configuration!\");\n-        }\n-        return (T) o;\n-    }\n-\n-    @Override\n-    public String toString() {\n-        return Objects.toStringHelper(this)\n-                      .add(\"username\", username)\n-                      .add(\"password\", password)\n-                      .add(\"keyspace\", keyspace)\n-                      .add(\"nodes\", nodes)\n-                      .add(\"port\", port)\n-                      .add(\"consistencyLevel\", consistencyLevel)\n-                      .add(\"batchSizeRows\", batchSizeRows)\n-                      .add(\"retryPolicyName\", retryPolicyName)\n-                      .add(\"reconnectionPolicyBaseMs\", reconnectionPolicyBaseMs)\n-                      .add(\"reconnectionPolicyMaxMs\", reconnectionPolicyMaxMs)\n-                      .add(\"poolMaxQueueSize\", poolMaxQueueSize)\n-                      .add(\"datacenterName\", datacenterName)\n-                      .add(\"maxRequestPerConnectionLocal\", maxRequestPerConnectionLocal)\n-                      .add(\"maxRequestPerConnectionRemote\", maxRequestPerConnectionRemote)\n-                      .add(\"heartbeatIntervalSeconds\", heartbeatIntervalSeconds)\n-                      .add(\"idleTimeoutSeconds\", idleTimeoutSeconds)\n-                      .add(\"socketReadTimeoutMillis\", socketReadTimeoutMillis)\n-                      .toString();\n-    }\n-}\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -36,6 +36,9 @@ import static org.apache.storm.validation.ConfigValidationAnnotations.Password;\n import java.util.ArrayList;\n import java.util.Map;\n import org.apache.storm.container.ResourceIsolationInterface;\n+import org.apache.storm.container.oci.OciImageTagToManifestPluginInterface;\n+import org.apache.storm.container.oci.OciManifestToResourcesPluginInterface;\n+import org.apache.storm.container.oci.OciResourcesLocalizerInterface;\n import org.apache.storm.nimbus.ITopologyActionNotifierPlugin;\n import org.apache.storm.scheduler.blacklist.reporters.IReporter;\n import org.apache.storm.scheduler.blacklist.strategies.IBlacklistStrategy;\n@@ -75,6 +78,12 @@ public class DaemonConfig implements Validated {\n     @IsString\n     public static final String STORM_DAEMON_METRICS_REPORTER_PLUGIN_DOMAIN = \"storm.daemon.metrics.reporter.plugin.domain\";\n \n+    /**\n+     * We report the metrics with this interval period.\n+     */\n+    @IsInteger\n+    public static final String STORM_DAEMON_METRICS_REPORTER_INTERVAL_SECS = \"storm.daemon.metrics.reporter.interval.secs\";\n+\n     /**\n      * Specify the csv reporter directory for CvsPreparableReporter daemon metrics reporter.\n      */\n@@ -337,6 +346,12 @@ public class DaemonConfig implements Validated {\n     @IsPositiveNumber\n     public static final String UI_PORT = \"ui.port\";\n \n+    /**\n+     * Storm UI's title.\n+     */\n+    @IsString\n+    public static final String UI_TITLE = \"ui.title\";\n+\n     /**\n      * This controls wheather Storm UI should bind to http port even if ui.port is > 0.\n      */\n@@ -762,6 +777,13 @@ public class DaemonConfig implements Validated {\n     @IsInteger\n     public static final String SUPERVISOR_LOCALIZER_CACHE_CLEANUP_INTERVAL_MS = \"supervisor.localizer.cleanup.interval.ms\";\n \n+    /**\n+     * The distributed cache interval for checking for blobs to update.\n+     */\n+    @IsPositiveNumber\n+    @IsInteger\n+    public static final String SUPERVISOR_LOCALIZER_UPDATE_BLOB_INTERVAL_SECS = \"supervisor.localizer.update.blob.interval.secs\";\n+\n     /**\n      * What blobstore download parallelism the supervisor should use.\n      */\n@@ -1278,11 +1300,47 @@ public class DaemonConfig implements Validated {\n     public static String STORM_OCI_ALLOWED_IMAGES = \"storm.oci.allowed.images\";\n \n     /**\n-     * White listed syscalls seccomp Json file to be used as a seccomp filter.\n+     * Specify the seccomp Json file to be used as a seccomp filter.\n      */\n     @IsString\n     public static String STORM_OCI_SECCOMP_PROFILE = \"storm.oci.seccomp.profile\";\n \n+    /**\n+     * The HDFS location under which the oci image manifests, layers,\n+     * and configs directories exist.\n+     */\n+    public static String STORM_OCI_IMAGE_HDFS_TOPLEVEL_DIR = \"storm.oci.image.hdfs.toplevel.dir\";\n+\n+    /**\n+     * The plugin to be used to get the image-tag to manifest mappings.\n+     */\n+    @IsImplementationOfClass(implementsClass = OciImageTagToManifestPluginInterface.class)\n+    public static final String STORM_OCI_IMAGE_TAG_TO_MANIFEST_PLUGIN = \"storm.oci.image.tag.to.manifest.plugin\";\n+\n+    /**\n+     * The plugin to be used to get oci resource according to the manifest.\n+     */\n+    @IsImplementationOfClass(implementsClass = OciManifestToResourcesPluginInterface.class)\n+    public static final String STORM_OCI_MANIFEST_TO_RESOURCES_PLUGIN = \"storm.oci.manifest.to.resources.plugin\";\n+\n+    /**\n+     * The plugin to use for oci resources localization.\n+     */\n+    @IsImplementationOfClass(implementsClass = OciResourcesLocalizerInterface.class)\n+    public static final String STORM_OCI_RESOURCES_LOCALIZER = \"storm.oci.resources.localizer\";\n+\n+    /**\n+     * The local directory for localized oci resources.\n+     */\n+    @IsString\n+    public static final String STORM_OCI_RESOURCES_LOCAL_DIR = \"storm.oci.resources.local.dir\";\n+\n+    /**\n+     * Target count of OCI layer mounts that we should keep on disk at one time.\n+     */\n+    @IsInteger\n+    public static final String STORM_OCI_LAYER_MOUNTS_TO_KEEP = \"storm.oci.layer.mounts.to.keep\";\n+\n     public static String getCgroupRootDir(Map<String, Object> conf) {\n         return (String) conf.get(STORM_SUPERVISOR_CGROUP_ROOTDIR);\n     }\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -1,4 +1,4 @@\n-/**\n+/*\n  * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with\n  * this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version\n  * 2.0 (the \"License\"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at\n@@ -12,30 +12,32 @@\n \n package org.apache.storm.security.auth.authorizer;\n \n-import java.io.IOException;\n+import org.apache.storm.Config;\n+import org.apache.storm.security.auth.IAuthorizer;\n+import org.apache.storm.security.auth.IGroupMappingServiceProvider;\n+import org.apache.storm.security.auth.ReqContext;\n+import org.apache.storm.utils.ConfigUtils;\n+import org.junit.jupiter.api.Test;\n+\n+import javax.security.auth.Subject;\n import java.security.Principal;\n-import java.util.Arrays;\n import java.util.Collection;\n+import java.util.Collections;\n import java.util.HashMap;\n import java.util.HashSet;\n import java.util.Map;\n import java.util.Set;\n-import javax.security.auth.Subject;\n-import org.apache.storm.Config;\n-import org.apache.storm.security.auth.IAuthorizer;\n-import org.apache.storm.security.auth.IGroupMappingServiceProvider;\n-import org.apache.storm.security.auth.ReqContext;\n-import org.apache.storm.utils.ConfigUtils;\n-import org.junit.Assert;\n-import org.junit.Test;\n+\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n \n public class SimpleACLAuthorizerTest {\n \n     @Test\n     public void SimpleACLUserAuthTest() {\n         Map<String, Object> clusterConf = ConfigUtils.readStormConfig();\n-        Collection<String> adminUserSet = new HashSet<>(Arrays.asList(\"admin\"));\n-        Collection<String> supervisorUserSet = new HashSet<>(Arrays.asList(\"supervisor\"));\n+        Collection<String> adminUserSet = new HashSet<>(Collections.singletonList(\"admin\"));\n+        Collection<String> supervisorUserSet = new HashSet<>(Collections.singletonList(\"supervisor\"));\n         clusterConf.put(Config.NIMBUS_ADMINS, adminUserSet);\n         clusterConf.put(Config.NIMBUS_SUPERVISOR_USERS, supervisorUserSet);\n \n@@ -48,157 +50,157 @@ public class SimpleACLAuthorizerTest {\n \n         authorizer.prepare(clusterConf);\n \n-        Assert.assertTrue(authorizer.permit(new ReqContext(adminUser), \"submitTopology\", new HashMap<>()));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"submitTopology\", new HashMap<>()));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"submitTopology\", new HashMap<>()));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userB), \"submitTopology\", new HashMap<>()));\n+        assertTrue(authorizer.permit(new ReqContext(adminUser), \"submitTopology\", new HashMap<>()));\n+        assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"submitTopology\", new HashMap<>()));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"submitTopology\", new HashMap<>()));\n+        assertTrue(authorizer.permit(new ReqContext(userB), \"submitTopology\", new HashMap<>()));\n \n-        Assert.assertTrue(authorizer.permit(new ReqContext(adminUser), \"fileUpload\", new HashMap<>()));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"fileUpload\", new HashMap<>()));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"fileUpload\", new HashMap<>()));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userB), \"fileUpload\", new HashMap<>()));\n+        assertTrue(authorizer.permit(new ReqContext(adminUser), \"fileUpload\", new HashMap<>()));\n+        assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"fileUpload\", new HashMap<>()));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"fileUpload\", new HashMap<>()));\n+        assertTrue(authorizer.permit(new ReqContext(userB), \"fileUpload\", new HashMap<>()));\n \n-        Assert.assertTrue(authorizer.permit(new ReqContext(adminUser), \"getNimbusConf\", new HashMap<>()));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"getNimbusConf\", new HashMap<>()));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"getNimbusConf\", new HashMap<>()));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userB), \"getNimbusConf\", new HashMap<>()));\n+        assertTrue(authorizer.permit(new ReqContext(adminUser), \"getNimbusConf\", new HashMap<>()));\n+        assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"getNimbusConf\", new HashMap<>()));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"getNimbusConf\", new HashMap<>()));\n+        assertTrue(authorizer.permit(new ReqContext(userB), \"getNimbusConf\", new HashMap<>()));\n \n-        Assert.assertTrue(authorizer.permit(new ReqContext(adminUser), \"getClusterInfo\", new HashMap<>()));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"getClusterInfo\", new HashMap<>()));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"getClusterInfo\", new HashMap<>()));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userB), \"getClusterInfo\", new HashMap<>()));\n+        assertTrue(authorizer.permit(new ReqContext(adminUser), \"getClusterInfo\", new HashMap<>()));\n+        assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"getClusterInfo\", new HashMap<>()));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"getClusterInfo\", new HashMap<>()));\n+        assertTrue(authorizer.permit(new ReqContext(userB), \"getClusterInfo\", new HashMap<>()));\n \n-        Assert.assertTrue(authorizer.permit(new ReqContext(adminUser), \"getSupervisorPageInfo\", new HashMap<>()));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"getSupervisorPageInfo\", new HashMap<>()));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"getSupervisorPageInfo\", new HashMap<>()));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userB), \"getSupervisorPageInfo\", new HashMap<>()));\n+        assertTrue(authorizer.permit(new ReqContext(adminUser), \"getSupervisorPageInfo\", new HashMap<>()));\n+        assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"getSupervisorPageInfo\", new HashMap<>()));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"getSupervisorPageInfo\", new HashMap<>()));\n+        assertTrue(authorizer.permit(new ReqContext(userB), \"getSupervisorPageInfo\", new HashMap<>()));\n \n-        Assert.assertTrue(authorizer.permit(new ReqContext(adminUser), \"fileDownload\", new HashMap<>()));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(supervisorUser), \"fileDownload\", new HashMap<>()));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userA), \"fileDownload\", new HashMap<>()));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"fileDownload\", new HashMap<>()));\n+        assertTrue(authorizer.permit(new ReqContext(adminUser), \"fileDownload\", new HashMap<>()));\n+        assertTrue(authorizer.permit(new ReqContext(supervisorUser), \"fileDownload\", new HashMap<>()));\n+        assertFalse(authorizer.permit(new ReqContext(userA), \"fileDownload\", new HashMap<>()));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"fileDownload\", new HashMap<>()));\n \n         Map<String, Object> topoConf = new HashMap<>();\n-        Collection<String> topologyUserSet = new HashSet<>(Arrays.asList(\"user-a\"));\n+        Collection<String> topologyUserSet = new HashSet<>(Collections.singletonList(\"user-a\"));\n         topoConf.put(Config.TOPOLOGY_USERS, topologyUserSet);\n \n-        Assert.assertTrue(authorizer.permit(new ReqContext(adminUser), \"killTopology\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"killTopology\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"killTopology\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"killTopology\", topoConf));\n-\n-        Assert.assertTrue(authorizer.permit(new ReqContext(adminUser), \"rebalance\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"rebalance\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"rebalance\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"rebalance\", topoConf));\n-\n-        Assert.assertTrue(authorizer.permit(new ReqContext(adminUser), \"activate\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"activate\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"activate\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"activate\", topoConf));\n-\n-        Assert.assertTrue(authorizer.permit(new ReqContext(adminUser), \"deactivate\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"deactivate\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"deactivate\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"deactivate\", topoConf));\n-\n-        Assert.assertTrue(authorizer.permit(new ReqContext(adminUser), \"getTopologyConf\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"getTopologyConf\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"getTopologyConf\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"getTopologyConf\", topoConf));\n-\n-        Assert.assertTrue(authorizer.permit(new ReqContext(adminUser), \"getTopology\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"getTopology\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"getTopology\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"getTopology\", topoConf));\n-\n-        Assert.assertTrue(authorizer.permit(new ReqContext(adminUser), \"getUserTopology\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"getUserTopology\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"getUserTopology\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"getUserTopology\", topoConf));\n-\n-        Assert.assertTrue(authorizer.permit(new ReqContext(adminUser), \"getTopologyInfo\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"getTopologyInfo\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"getTopologyInfo\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"getTopologyInfo\", topoConf));\n-\n-        Assert.assertTrue(authorizer.permit(new ReqContext(adminUser), \"getTopologyPageInfo\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"getTopologyPageInfo\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"getTopologyPageInfo\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"getTopologyPageInfo\", topoConf));\n-\n-        Assert.assertTrue(authorizer.permit(new ReqContext(adminUser), \"getComponentPageInfo\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"getComponentPageInfo\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"getComponentPageInfo\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"getComponentPageInfo\", topoConf));\n-\n-        Assert.assertTrue(authorizer.permit(new ReqContext(adminUser), \"uploadNewCredentials\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"uploadNewCredentials\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"uploadNewCredentials\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"uploadNewCredentials\", topoConf));\n-\n-        Assert.assertTrue(authorizer.permit(new ReqContext(adminUser), \"setLogConfig\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"setLogConfig\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"setLogConfig\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"setLogConfig\", topoConf));\n-\n-        Assert.assertTrue(authorizer.permit(new ReqContext(adminUser), \"setWorkerProfiler\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"setWorkerProfiler\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"setWorkerProfiler\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"setWorkerProfiler\", topoConf));\n-\n-        Assert.assertTrue(authorizer.permit(new ReqContext(adminUser), \"getWorkerProfileActionExpiry\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"getWorkerProfileActionExpiry\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"getWorkerProfileActionExpiry\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"getWorkerProfileActionExpiry\", topoConf));\n-\n-        Assert.assertTrue(authorizer.permit(new ReqContext(adminUser), \"getComponentPendingProfileActions\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"getComponentPendingProfileActions\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"getComponentPendingProfileActions\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"getComponentPendingProfileActions\", topoConf));\n-\n-        Assert.assertTrue(authorizer.permit(new ReqContext(adminUser), \"startProfiling\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"startProfiling\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"startProfiling\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"startProfiling\", topoConf));\n-\n-        Assert.assertTrue(authorizer.permit(new ReqContext(adminUser), \"stopProfiling\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"stopProfiling\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"stopProfiling\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"stopProfiling\", topoConf));\n-\n-        Assert.assertTrue(authorizer.permit(new ReqContext(adminUser), \"dumpProfile\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"dumpProfile\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"dumpProfile\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"dumpProfile\", topoConf));\n-\n-        Assert.assertTrue(authorizer.permit(new ReqContext(adminUser), \"dumpJstack\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"dumpJstack\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"dumpJstack\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"dumpJstack\", topoConf));\n-\n-        Assert.assertTrue(authorizer.permit(new ReqContext(adminUser), \"dumpHeap\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"dumpHeap\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"dumpHeap\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"dumpHeap\", topoConf));\n-\n-        Assert.assertTrue(authorizer.permit(new ReqContext(adminUser), \"debug\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"debug\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"debug\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"debug\", topoConf));\n-\n-        Assert.assertTrue(authorizer.permit(new ReqContext(adminUser), \"getLogConfig\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"getLogConfig\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"getLogConfig\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"getLogConfig\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(adminUser), \"killTopology\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"killTopology\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"killTopology\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"killTopology\", topoConf));\n+\n+        assertTrue(authorizer.permit(new ReqContext(adminUser), \"rebalance\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"rebalance\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"rebalance\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"rebalance\", topoConf));\n+\n+        assertTrue(authorizer.permit(new ReqContext(adminUser), \"activate\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"activate\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"activate\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"activate\", topoConf));\n+\n+        assertTrue(authorizer.permit(new ReqContext(adminUser), \"deactivate\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"deactivate\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"deactivate\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"deactivate\", topoConf));\n+\n+        assertTrue(authorizer.permit(new ReqContext(adminUser), \"getTopologyConf\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"getTopologyConf\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"getTopologyConf\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"getTopologyConf\", topoConf));\n+\n+        assertTrue(authorizer.permit(new ReqContext(adminUser), \"getTopology\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"getTopology\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"getTopology\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"getTopology\", topoConf));\n+\n+        assertTrue(authorizer.permit(new ReqContext(adminUser), \"getUserTopology\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"getUserTopology\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"getUserTopology\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"getUserTopology\", topoConf));\n+\n+        assertTrue(authorizer.permit(new ReqContext(adminUser), \"getTopologyInfo\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"getTopologyInfo\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"getTopologyInfo\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"getTopologyInfo\", topoConf));\n+\n+        assertTrue(authorizer.permit(new ReqContext(adminUser), \"getTopologyPageInfo\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"getTopologyPageInfo\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"getTopologyPageInfo\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"getTopologyPageInfo\", topoConf));\n+\n+        assertTrue(authorizer.permit(new ReqContext(adminUser), \"getComponentPageInfo\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"getComponentPageInfo\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"getComponentPageInfo\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"getComponentPageInfo\", topoConf));\n+\n+        assertTrue(authorizer.permit(new ReqContext(adminUser), \"uploadNewCredentials\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"uploadNewCredentials\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"uploadNewCredentials\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"uploadNewCredentials\", topoConf));\n+\n+        assertTrue(authorizer.permit(new ReqContext(adminUser), \"setLogConfig\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"setLogConfig\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"setLogConfig\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"setLogConfig\", topoConf));\n+\n+        assertTrue(authorizer.permit(new ReqContext(adminUser), \"setWorkerProfiler\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"setWorkerProfiler\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"setWorkerProfiler\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"setWorkerProfiler\", topoConf));\n+\n+        assertTrue(authorizer.permit(new ReqContext(adminUser), \"getWorkerProfileActionExpiry\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"getWorkerProfileActionExpiry\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"getWorkerProfileActionExpiry\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"getWorkerProfileActionExpiry\", topoConf));\n+\n+        assertTrue(authorizer.permit(new ReqContext(adminUser), \"getComponentPendingProfileActions\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"getComponentPendingProfileActions\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"getComponentPendingProfileActions\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"getComponentPendingProfileActions\", topoConf));\n+\n+        assertTrue(authorizer.permit(new ReqContext(adminUser), \"startProfiling\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"startProfiling\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"startProfiling\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"startProfiling\", topoConf));\n+\n+        assertTrue(authorizer.permit(new ReqContext(adminUser), \"stopProfiling\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"stopProfiling\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"stopProfiling\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"stopProfiling\", topoConf));\n+\n+        assertTrue(authorizer.permit(new ReqContext(adminUser), \"dumpProfile\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"dumpProfile\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"dumpProfile\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"dumpProfile\", topoConf));\n+\n+        assertTrue(authorizer.permit(new ReqContext(adminUser), \"dumpJstack\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"dumpJstack\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"dumpJstack\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"dumpJstack\", topoConf));\n+\n+        assertTrue(authorizer.permit(new ReqContext(adminUser), \"dumpHeap\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"dumpHeap\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"dumpHeap\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"dumpHeap\", topoConf));\n+\n+        assertTrue(authorizer.permit(new ReqContext(adminUser), \"debug\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"debug\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"debug\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"debug\", topoConf));\n+\n+        assertTrue(authorizer.permit(new ReqContext(adminUser), \"getLogConfig\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(supervisorUser), \"getLogConfig\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"getLogConfig\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"getLogConfig\", topoConf));\n     }\n \n     @Test\n     public void SimpleACLNimbusUserAuthTest() {\n         Map<String, Object> clusterConf = ConfigUtils.readStormConfig();\n-        Collection<String> adminUserSet = new HashSet<>(Arrays.asList(\"admin\"));\n-        Collection<String> supervisorUserSet = new HashSet<>(Arrays.asList(\"supervisor\"));\n-        Collection<String> nimbusUserSet = new HashSet<>(Arrays.asList(\"user-a\"));\n+        Collection<String> adminUserSet = new HashSet<>(Collections.singletonList(\"admin\"));\n+        Collection<String> supervisorUserSet = new HashSet<>(Collections.singletonList(\"supervisor\"));\n+        Collection<String> nimbusUserSet = new HashSet<>(Collections.singletonList(\"user-a\"));\n \n         clusterConf.put(Config.NIMBUS_ADMINS, adminUserSet);\n         clusterConf.put(Config.NIMBUS_SUPERVISOR_USERS, supervisorUserSet);\n@@ -213,10 +215,10 @@ public class SimpleACLAuthorizerTest {\n \n         authorizer.prepare(clusterConf);\n \n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"submitTopology\", new HashMap<>()));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"submitTopology\", new HashMap<>()));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(adminUser), \"fileUpload\", new HashMap<>()));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(supervisorUser), \"fileDownload\", new HashMap<>()));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"submitTopology\", new HashMap<>()));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"submitTopology\", new HashMap<>()));\n+        assertTrue(authorizer.permit(new ReqContext(adminUser), \"fileUpload\", new HashMap<>()));\n+        assertTrue(authorizer.permit(new ReqContext(supervisorUser), \"fileDownload\", new HashMap<>()));\n     }\n \n     @Test\n@@ -224,10 +226,10 @@ public class SimpleACLAuthorizerTest {\n         Map<String, Object> clusterConf = ConfigUtils.readStormConfig();\n \n         Map<String, Object> topoConf = new HashMap<>();\n-        Collection<String> topologyUserSet = new HashSet<>(Arrays.asList(\"user-a\"));\n+        Collection<String> topologyUserSet = new HashSet<>(Collections.singletonList(\"user-a\"));\n         topoConf.put(Config.TOPOLOGY_USERS, topologyUserSet);\n \n-        Collection<String> topologyReadOnlyUserSet = new HashSet<>(Arrays.asList(\"user-readonly\"));\n+        Collection<String> topologyReadOnlyUserSet = new HashSet<>(Collections.singletonList(\"user-readonly\"));\n         topoConf.put(Config.TOPOLOGY_READONLY_USERS, topologyReadOnlyUserSet);\n \n         Subject userA = createSubject(\"user-a\");\n@@ -237,93 +239,93 @@ public class SimpleACLAuthorizerTest {\n         IAuthorizer authorizer = new SimpleACLAuthorizer();\n         authorizer.prepare(clusterConf);\n \n-        Assert.assertFalse(authorizer.permit(new ReqContext(readOnlyUser), \"killTopology\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"killTopology\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"killTopology\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(readOnlyUser), \"killTopology\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"killTopology\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"killTopology\", topoConf));\n \n-        Assert.assertFalse(authorizer.permit(new ReqContext(readOnlyUser), \"rebalance\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"rebalance\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"rebalance\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(readOnlyUser), \"rebalance\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"rebalance\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"rebalance\", topoConf));\n \n-        Assert.assertFalse(authorizer.permit(new ReqContext(readOnlyUser), \"activate\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"activate\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"activate\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(readOnlyUser), \"activate\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"activate\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"activate\", topoConf));\n \n-        Assert.assertFalse(authorizer.permit(new ReqContext(readOnlyUser), \"deactivate\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"deactivate\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"deactivate\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(readOnlyUser), \"deactivate\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"deactivate\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"deactivate\", topoConf));\n \n-        Assert.assertTrue(authorizer.permit(new ReqContext(readOnlyUser), \"getTopologyConf\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"getTopologyConf\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"getTopologyConf\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(readOnlyUser), \"getTopologyConf\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"getTopologyConf\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"getTopologyConf\", topoConf));\n \n-        Assert.assertTrue(authorizer.permit(new ReqContext(readOnlyUser), \"getTopology\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"getTopology\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"getTopology\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(readOnlyUser), \"getTopology\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"getTopology\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"getTopology\", topoConf));\n \n-        Assert.assertTrue(authorizer.permit(new ReqContext(readOnlyUser), \"getUserTopology\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"getUserTopology\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"getUserTopology\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(readOnlyUser), \"getUserTopology\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"getUserTopology\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"getUserTopology\", topoConf));\n \n-        Assert.assertTrue(authorizer.permit(new ReqContext(readOnlyUser), \"getTopologyInfo\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"getTopologyInfo\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"getTopologyInfo\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(readOnlyUser), \"getTopologyInfo\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"getTopologyInfo\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"getTopologyInfo\", topoConf));\n \n-        Assert.assertTrue(authorizer.permit(new ReqContext(readOnlyUser), \"getTopologyPageInfo\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"getTopologyPageInfo\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"getTopologyPageInfo\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(readOnlyUser), \"getTopologyPageInfo\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"getTopologyPageInfo\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"getTopologyPageInfo\", topoConf));\n \n-        Assert.assertTrue(authorizer.permit(new ReqContext(readOnlyUser), \"getComponentPageInfo\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"getComponentPageInfo\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"getComponentPageInfo\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(readOnlyUser), \"getComponentPageInfo\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"getComponentPageInfo\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"getComponentPageInfo\", topoConf));\n \n-        Assert.assertFalse(authorizer.permit(new ReqContext(readOnlyUser), \"uploadNewCredentials\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"uploadNewCredentials\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"uploadNewCredentials\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(readOnlyUser), \"uploadNewCredentials\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"uploadNewCredentials\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"uploadNewCredentials\", topoConf));\n \n-        Assert.assertFalse(authorizer.permit(new ReqContext(readOnlyUser), \"setLogConfig\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"setLogConfig\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"setLogConfig\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(readOnlyUser), \"setLogConfig\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"setLogConfig\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"setLogConfig\", topoConf));\n \n-        Assert.assertFalse(authorizer.permit(new ReqContext(readOnlyUser), \"setWorkerProfiler\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"setWorkerProfiler\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"setWorkerProfiler\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(readOnlyUser), \"setWorkerProfiler\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"setWorkerProfiler\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"setWorkerProfiler\", topoConf));\n \n-        Assert.assertTrue(authorizer.permit(new ReqContext(readOnlyUser), \"getWorkerProfileActionExpiry\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"getWorkerProfileActionExpiry\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"getWorkerProfileActionExpiry\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(readOnlyUser), \"getWorkerProfileActionExpiry\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"getWorkerProfileActionExpiry\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"getWorkerProfileActionExpiry\", topoConf));\n \n-        Assert.assertTrue(authorizer.permit(new ReqContext(readOnlyUser), \"getComponentPendingProfileActions\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"getComponentPendingProfileActions\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"getComponentPendingProfileActions\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(readOnlyUser), \"getComponentPendingProfileActions\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"getComponentPendingProfileActions\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"getComponentPendingProfileActions\", topoConf));\n \n-        Assert.assertFalse(authorizer.permit(new ReqContext(readOnlyUser), \"startProfiling\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"startProfiling\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"startProfiling\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(readOnlyUser), \"startProfiling\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"startProfiling\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"startProfiling\", topoConf));\n \n-        Assert.assertFalse(authorizer.permit(new ReqContext(readOnlyUser), \"stopProfiling\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"stopProfiling\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"stopProfiling\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(readOnlyUser), \"stopProfiling\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"stopProfiling\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"stopProfiling\", topoConf));\n \n-        Assert.assertFalse(authorizer.permit(new ReqContext(readOnlyUser), \"dumpProfile\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"dumpProfile\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"dumpProfile\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(readOnlyUser), \"dumpProfile\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"dumpProfile\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"dumpProfile\", topoConf));\n \n-        Assert.assertFalse(authorizer.permit(new ReqContext(readOnlyUser), \"dumpJstack\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"dumpJstack\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"dumpJstack\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(readOnlyUser), \"dumpJstack\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"dumpJstack\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"dumpJstack\", topoConf));\n \n-        Assert.assertFalse(authorizer.permit(new ReqContext(readOnlyUser), \"dumpHeap\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"dumpHeap\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"dumpHeap\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(readOnlyUser), \"dumpHeap\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"dumpHeap\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"dumpHeap\", topoConf));\n \n-        Assert.assertFalse(authorizer.permit(new ReqContext(readOnlyUser), \"debug\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"debug\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"debug\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(readOnlyUser), \"debug\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"debug\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"debug\", topoConf));\n \n-        Assert.assertTrue(authorizer.permit(new ReqContext(readOnlyUser), \"getLogConfig\", topoConf));\n-        Assert.assertTrue(authorizer.permit(new ReqContext(userA), \"getLogConfig\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"getLogConfig\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(readOnlyUser), \"getLogConfig\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userA), \"getLogConfig\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"getLogConfig\", topoConf));\n     }\n \n     @Test\n@@ -333,7 +335,7 @@ public class SimpleACLAuthorizerTest {\n                         SimpleACLTopologyReadOnlyGroupAuthTestMock.class.getName());\n \n         Map<String, Object> topoConf = new HashMap<>();\n-        Collection<String> topologyReadOnlyGroupSet = new HashSet<>(Arrays.asList(\"group-readonly\"));\n+        Collection<String> topologyReadOnlyGroupSet = new HashSet<>(Collections.singletonList(\"group-readonly\"));\n         topoConf.put(Config.TOPOLOGY_READONLY_GROUPS, topologyReadOnlyGroupSet);\n \n         Subject userInReadOnlyGroup = createSubject(\"user-in-readonly-group\");\n@@ -342,26 +344,21 @@ public class SimpleACLAuthorizerTest {\n         IAuthorizer authorizer = new SimpleACLAuthorizer();\n         authorizer.prepare(clusterConf);\n \n-        Assert.assertFalse(authorizer.permit(new ReqContext(userInReadOnlyGroup), \"killTopology\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"killTopology\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userInReadOnlyGroup), \"killTopology\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"killTopology\", topoConf));\n \n-        Assert.assertTrue(authorizer.permit(new ReqContext(userInReadOnlyGroup), \"getTopologyInfo\", topoConf));\n-        Assert.assertFalse(authorizer.permit(new ReqContext(userB), \"getTopologyInfo\", topoConf));\n+        assertTrue(authorizer.permit(new ReqContext(userInReadOnlyGroup), \"getTopologyInfo\", topoConf));\n+        assertFalse(authorizer.permit(new ReqContext(userB), \"getTopologyInfo\", topoConf));\n     }\n \n     private Subject createSubject(String name) {\n         Set<Principal> principalSet = new HashSet<>();\n         principalSet.add(createPrincipal(name));\n-        return new Subject(true, principalSet, new HashSet(), new HashSet());\n+        return new Subject(true, principalSet, new HashSet<>(), new HashSet<>());\n     }\n \n     private Principal createPrincipal(String name) {\n-        return new Principal() {\n-            @Override\n-            public String getName() {\n-                return name;\n-            }\n-        };\n+        return () -> name;\n     }\n \n     public static class SimpleACLTopologyReadOnlyGroupAuthTestMock implements IGroupMappingServiceProvider {\n@@ -372,11 +369,11 @@ public class SimpleACLAuthorizerTest {\n         }\n \n         @Override\n-        public Set<String> getGroups(String user) throws IOException {\n+        public Set<String> getGroups(String user) {\n             if (\"user-in-readonly-group\".equals(user)) {\n-                return new HashSet<>(Arrays.asList(\"group-readonly\"));\n+                return new HashSet<>(Collections.singletonList(\"group-readonly\"));\n             } else {\n-                return new HashSet<>(Arrays.asList(user));\n+                return new HashSet<>(Collections.singletonList(user));\n             }\n         }\n     }\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -1,114 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version\n- * 2.0 (the \"License\"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions\n- * and limitations under the License.\n- */\n-\n-package org.apache.storm.hbase.bolt;\n-\n-import java.util.LinkedList;\n-import java.util.List;\n-import java.util.Map;\n-import org.apache.hadoop.hbase.client.Durability;\n-import org.apache.hadoop.hbase.client.Mutation;\n-import org.apache.storm.hbase.bolt.mapper.HBaseMapper;\n-import org.apache.storm.hbase.common.ColumnList;\n-import org.apache.storm.task.OutputCollector;\n-import org.apache.storm.task.TopologyContext;\n-import org.apache.storm.topology.OutputFieldsDeclarer;\n-import org.apache.storm.tuple.Tuple;\n-import org.apache.storm.utils.BatchHelper;\n-import org.apache.storm.utils.TupleUtils;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-/**\n- * Basic bolt for writing to HBase.\n- *\n- * <p>Note: Each HBaseBolt defined in a topology is tied to a specific table.\n- */\n-@SuppressWarnings(\"checkstyle:AbbreviationAsWordInName\")\n-public class HBaseBolt extends AbstractHBaseBolt {\n-    private static final Logger LOG = LoggerFactory.getLogger(HBaseBolt.class);\n-    private static final int DEFAULT_FLUSH_INTERVAL_SECS = 1;\n-\n-    @SuppressWarnings(\"checkstyle:AbbreviationAsWordInName\")\n-    boolean writeToWAL = true;\n-    List<Mutation> batchMutations;\n-    int flushIntervalSecs = DEFAULT_FLUSH_INTERVAL_SECS;\n-    int batchSize;\n-    BatchHelper batchHelper;\n-\n-    public HBaseBolt(String tableName, HBaseMapper mapper) {\n-        super(tableName, mapper);\n-        this.batchMutations = new LinkedList<>();\n-    }\n-\n-    @SuppressWarnings(\"checkstyle:AbbreviationAsWordInName\")\n-    public HBaseBolt writeToWAL(boolean writeToWAL) {\n-        this.writeToWAL = writeToWAL;\n-        return this;\n-    }\n-\n-    public HBaseBolt withConfigKey(String configKey) {\n-        this.configKey = configKey;\n-        return this;\n-    }\n-\n-    public HBaseBolt withBatchSize(int batchSize) {\n-        this.batchSize = batchSize;\n-        return this;\n-    }\n-\n-    public HBaseBolt withFlushIntervalSecs(int flushIntervalSecs) {\n-        this.flushIntervalSecs = flushIntervalSecs;\n-        return this;\n-    }\n-\n-    @Override\n-    public Map<String, Object> getComponentConfiguration() {\n-        return TupleUtils.putTickFrequencyIntoComponentConfig(super.getComponentConfiguration(), flushIntervalSecs);\n-    }\n-\n-\n-    @Override\n-    public void execute(Tuple tuple) {\n-        try {\n-            if (batchHelper.shouldHandle(tuple)) {\n-                byte[] rowKey = this.mapper.rowKey(tuple);\n-                ColumnList cols = this.mapper.columns(tuple);\n-                List<Mutation> mutations =\n-                    hBaseClient.constructMutationReq(rowKey, cols, writeToWAL ? Durability.SYNC_WAL : Durability.SKIP_WAL);\n-                batchMutations.addAll(mutations);\n-                batchHelper.addBatch(tuple);\n-            }\n-\n-            if (batchHelper.shouldFlush()) {\n-                this.hBaseClient.batchMutate(batchMutations);\n-                LOG.debug(\"acknowledging tuples after batchMutate\");\n-                batchHelper.ack();\n-                batchMutations.clear();\n-            }\n-        } catch (Exception e) {\n-            batchHelper.fail(e);\n-            batchMutations.clear();\n-        }\n-    }\n-\n-    @Override\n-    public void prepare(Map<String, Object> map, TopologyContext topologyContext, OutputCollector collector) {\n-        super.prepare(map, topologyContext, collector);\n-        this.batchHelper = new BatchHelper(batchSize, collector);\n-    }\n-\n-    @Override\n-    public void declareOutputFields(OutputFieldsDeclarer outputFieldsDeclarer) {\n-\n-    }\n-}\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -1,71 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.storm.solr.topology;\n-\n-import java.io.IOException;\n-\n-import org.apache.solr.client.solrj.SolrClient;\n-import org.apache.solr.client.solrj.impl.CloudSolrClient;\n-import org.apache.storm.Config;\n-import org.apache.storm.StormSubmitter;\n-import org.apache.storm.generated.StormTopology;\n-import org.apache.storm.solr.config.SolrCommitStrategy;\n-import org.apache.storm.solr.config.SolrConfig;\n-\n-public abstract class SolrTopology {\n-    protected static String COLLECTION = \"gettingstarted\";\n-\n-    public void run(String[] args) throws Exception {\n-        final StormTopology topology = getTopology();\n-        final Config config = getConfig();\n-\n-        String topoName = \"test\";\n-        if (args.length > 0) {\n-            topoName = args[0];\n-        }\n-        submitTopologyRemoteCluster(topoName, topology, config);\n-    }\n-\n-    protected abstract StormTopology getTopology() throws IOException;\n-\n-    protected void submitTopologyRemoteCluster(String arg, StormTopology topology, Config config) throws Exception {\n-        StormSubmitter.submitTopology(arg, config, topology);\n-    }\n-\n-    protected Config getConfig() {\n-        Config config = new Config();\n-        config.setDebug(true);\n-        return config;\n-    }\n-\n-    protected SolrCommitStrategy getSolrCommitStgy() {\n-        return null;                          // To Commit to Solr and Ack every tuple\n-    }\n-\n-    protected static SolrConfig getSolrConfig() {\n-        String zkHostString = \"127.0.0.1:9983\";  // zkHostString for Solr gettingstarted example\n-        return new SolrConfig(zkHostString);\n-    }\n-\n-    protected static SolrClient getSolrClient() {\n-        String zkHostString = \"127.0.0.1:9983\";  // zkHostString for Solr gettingstarted example\n-        return new CloudSolrClient(zkHostString);\n-    }\n-\n-}\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -23,19 +23,18 @@ import java.util.concurrent.ArrayBlockingQueue;\n import java.util.concurrent.ThreadPoolExecutor;\n import java.util.concurrent.TimeUnit;\n import javax.security.auth.Subject;\n-import javax.security.auth.login.Configuration;\n import org.apache.storm.thrift.TException;\n import org.apache.storm.thrift.TProcessor;\n import org.apache.storm.thrift.protocol.TBinaryProtocol;\n import org.apache.storm.thrift.protocol.TProtocol;\n import org.apache.storm.thrift.server.THsHaServer;\n import org.apache.storm.thrift.server.TServer;\n-import org.apache.storm.thrift.transport.TFramedTransport;\n import org.apache.storm.thrift.transport.TMemoryInputTransport;\n import org.apache.storm.thrift.transport.TNonblockingServerSocket;\n import org.apache.storm.thrift.transport.TSocket;\n import org.apache.storm.thrift.transport.TTransport;\n import org.apache.storm.thrift.transport.TTransportException;\n+import org.apache.storm.thrift.transport.layered.TFramedTransport;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -1,79 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version\n- * 2.0 (the \"License\"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions\n- * and limitations under the License.\n- */\n-\n-package org.apache.storm.hbase.trident.mapper;\n-\n-import static org.apache.storm.hbase.common.Utils.toBytes;\n-import static org.apache.storm.hbase.common.Utils.toLong;\n-\n-import org.apache.storm.hbase.common.ColumnList;\n-import org.apache.storm.trident.tuple.TridentTuple;\n-import org.apache.storm.tuple.Fields;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-public class SimpleTridentHBaseMapper implements TridentHBaseMapper {\n-    private static final Logger LOG = LoggerFactory.getLogger(SimpleTridentHBaseMapper.class);\n-\n-    private String rowKeyField;\n-    private byte[] columnFamily;\n-    private Fields columnFields;\n-    private Fields counterFields;\n-\n-    public SimpleTridentHBaseMapper() {\n-    }\n-\n-\n-    public SimpleTridentHBaseMapper withRowKeyField(String rowKeyField) {\n-        this.rowKeyField = rowKeyField;\n-        return this;\n-    }\n-\n-    public SimpleTridentHBaseMapper withColumnFields(Fields columnFields) {\n-        this.columnFields = columnFields;\n-        return this;\n-    }\n-\n-    public SimpleTridentHBaseMapper withCounterFields(Fields counterFields) {\n-        this.counterFields = counterFields;\n-        return this;\n-    }\n-\n-    public SimpleTridentHBaseMapper withColumnFamily(String columnFamily) {\n-        this.columnFamily = columnFamily.getBytes();\n-        return this;\n-    }\n-\n-\n-    @Override\n-    public byte[] rowKey(TridentTuple tuple) {\n-        Object objVal = tuple.getValueByField(this.rowKeyField);\n-        return toBytes(objVal);\n-    }\n-\n-    @Override\n-    public ColumnList columns(TridentTuple tuple) {\n-        ColumnList cols = new ColumnList();\n-        if (this.columnFields != null) {\n-            // TODO timestamps\n-            for (String field : this.columnFields) {\n-                cols.addColumn(this.columnFamily, field.getBytes(), toBytes(tuple.getValueByField(field)));\n-            }\n-        }\n-        if (this.counterFields != null) {\n-            for (String field : this.counterFields) {\n-                cols.addCounter(this.columnFamily, field.getBytes(), toLong(tuple.getValueByField(field)));\n-            }\n-        }\n-        return cols;\n-    }\n-}\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -20,9 +20,9 @@ import org.apache.storm.Config;\n import org.apache.storm.drpc.DRPCInvocationsClient;\n import org.apache.storm.generated.AuthorizationException;\n import org.apache.storm.generated.DistributedRPCInvocations;\n+import org.apache.storm.shade.net.minidev.json.JSONValue;\n+import org.apache.storm.shade.net.minidev.json.parser.ParseException;\n import org.apache.storm.shade.org.apache.commons.lang.builder.ToStringBuilder;\n-import org.apache.storm.shade.org.json.simple.JSONValue;\n-import org.apache.storm.shade.org.json.simple.parser.ParseException;\n import org.apache.storm.thrift.TException;\n import org.apache.storm.thrift.transport.TTransportException;\n import org.apache.storm.trident.drpc.ReturnResultsReducer.ReturnResultsState;\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -18,16 +18,16 @@\n \n package org.apache.storm;\n \n+import java.util.Map;\n import org.apache.storm.generated.InvalidTopologyException;\n import org.apache.storm.generated.StormTopology;\n import org.apache.storm.generated.SubmitOptions;\n import org.apache.storm.generated.TopologyInitialStatus;\n import org.apache.storm.testing.TestWordCounter;\n import org.apache.storm.topology.TopologyBuilder;\n-import org.junit.Assert;\n-import org.junit.Test;\n+import org.junit.jupiter.api.Test;\n \n-import java.util.Map;\n+import static org.junit.jupiter.api.Assertions.fail;\n \n public class TestStormSubmitter {\n \n@@ -44,16 +44,16 @@ public class TestStormSubmitter {\n \n         try {\n             StormSubmitter.submitTopologyAs(\"test-topo-without-spout\", topoConf, topology, opts, null, \"none\");\n-            Assert.fail(\"Topology without spout should fail in submission\");\n+            fail(\"Topology without spout should fail in submission\");\n         } catch (InvalidTopologyException ex) {\n             if (!ex.getMessage().contains(expectedExceptionMsgFragment)) {\n                 String err = String.format(\"Topology submit failure should contain string \\\"%s\\\", but is \\\"%s\\\"\",\n                         expectedExceptionMsgFragment, ex.getMessage());\n-                Assert.fail(err);\n+                fail(err);\n             }\n         } catch (Throwable ex) {\n             ex.printStackTrace();\n-            Assert.fail(\"Unexpected exception submitting topology without spout: \" + ex);\n+            fail(\"Unexpected exception submitting topology without spout: \" + ex);\n         }\n     }\n }\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -1,27 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version\n- * 2.0 (the \"License\"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions\n- * and limitations under the License.\n- */\n-\n-package org.apache.storm.hbase.trident.state;\n-\n-import java.util.List;\n-import org.apache.storm.trident.operation.TridentCollector;\n-import org.apache.storm.trident.state.BaseStateUpdater;\n-import org.apache.storm.trident.tuple.TridentTuple;\n-\n-public class HBaseUpdater extends BaseStateUpdater<HBaseState> {\n-\n-    @Override\n-    @SuppressWarnings(\"checkstyle:ParameterName\")\n-    public void updateState(HBaseState hBaseState, List<TridentTuple> tuples, TridentCollector collector) {\n-        hBaseState.updateState(tuples, collector);\n-    }\n-}\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -77,7 +77,6 @@ import org.apache.storm.blobstore.BlobStore;\n import org.apache.storm.blobstore.ClientBlobStore;\n import org.apache.storm.blobstore.NimbusBlobStore;\n import org.apache.storm.generated.AuthorizationException;\n-import org.apache.storm.generated.ClusterSummary;\n import org.apache.storm.generated.ComponentCommon;\n import org.apache.storm.generated.ComponentObject;\n import org.apache.storm.generated.GlobalStreamId;\n@@ -94,14 +93,15 @@ import org.apache.storm.shade.com.google.common.annotations.VisibleForTesting;\n import org.apache.storm.shade.com.google.common.collect.Lists;\n import org.apache.storm.shade.com.google.common.collect.MapDifference;\n import org.apache.storm.shade.com.google.common.collect.Maps;\n+import org.apache.storm.shade.net.minidev.json.JSONValue;\n+import org.apache.storm.shade.net.minidev.json.parser.ParseException;\n import org.apache.storm.shade.org.apache.commons.io.FileUtils;\n import org.apache.storm.shade.org.apache.commons.io.input.ClassLoaderObjectInputStream;\n import org.apache.storm.shade.org.apache.commons.lang.StringUtils;\n import org.apache.storm.shade.org.apache.zookeeper.ZooDefs;\n import org.apache.storm.shade.org.apache.zookeeper.data.ACL;\n import org.apache.storm.shade.org.apache.zookeeper.data.Id;\n-import org.apache.storm.shade.org.json.simple.JSONValue;\n-import org.apache.storm.shade.org.json.simple.parser.ParseException;\n+import org.apache.storm.shade.org.yaml.snakeyaml.LoaderOptions;\n import org.apache.storm.shade.org.yaml.snakeyaml.Yaml;\n import org.apache.storm.shade.org.yaml.snakeyaml.constructor.SafeConstructor;\n import org.apache.storm.thrift.TBase;\n@@ -176,7 +176,7 @@ public class Utils {\n         try {\n             in = getConfigFileInputStream(name);\n             if (null != in) {\n-                Yaml yaml = new Yaml(new SafeConstructor());\n+                Yaml yaml = new Yaml(new SafeConstructor(new LoaderOptions()));\n                 @SuppressWarnings(\"unchecked\")\n                 Map<String, Object> ret = (Map<String, Object>) yaml.load(new InputStreamReader(in));\n                 if (null != ret) {\n@@ -387,6 +387,7 @@ public class Utils {\n                                         int priority, final boolean isFactory, boolean startImmediately,\n                                         String threadName) {\n         SmartThread thread = new SmartThread(new Runnable() {\n+            @Override\n             public void run() {\n                 try {\n                     final Callable<Long> fn = isFactory ? (Callable<Long>) afn.call() : afn;\n@@ -417,6 +418,7 @@ public class Utils {\n             thread.setUncaughtExceptionHandler(eh);\n         } else {\n             thread.setUncaughtExceptionHandler(new Thread.UncaughtExceptionHandler() {\n+                @Override\n                 public void uncaughtException(Thread t, Throwable e) {\n                     LOG.error(\"Async loop died!\", e);\n                     Utils.exitProcess(1, \"Async loop died!\");\n@@ -721,12 +723,16 @@ public class Utils {\n     }\n \n     private static TDeserializer getDes() {\n-        TDeserializer des = threadDes.get();\n-        if (des == null) {\n-            des = new TDeserializer();\n-            threadDes.set(des);\n+        try {\n+            TDeserializer des = threadDes.get();\n+            if (des == null) {\n+                des = new TDeserializer();\n+                threadDes.set(des);\n+            }\n+            return des;\n+        } catch (Exception e) {\n+            throw new RuntimeException(e);\n         }\n-        return des;\n     }\n \n     public static void sleepNoSimulation(long millis) {\n@@ -849,7 +855,6 @@ public class Utils {\n      *\n      * @param str   the encoded string.\n      * @param clazz the thrift class we are expecting.\n-     * @param <T>   The type of clazz\n      * @return the decoded object\n      */\n     public static <T> T deserializeFromString(String str, Class<T> clazz) {\n@@ -1086,7 +1091,7 @@ public class Utils {\n                 }\n                 Matcher m = optsPattern.matcher(option);\n                 while (m.find()) {\n-                    int value = Integer.parseInt(m.group(1));\n+                    long value = Long.parseLong(m.group(1));\n                     char unitChar = m.group(2).toLowerCase().charAt(0);\n                     int unit;\n                     switch (unitChar) {\n@@ -1233,9 +1238,18 @@ public class Utils {\n      */\n     public static void validateTopologyBlobStoreMap(Map<String, Object> topoConf, NimbusBlobStore client)\n         throws InvalidTopologyException, AuthorizationException {\n-        Map<String, Object> blobStoreMap = (Map<String, Object>) topoConf.get(Config.TOPOLOGY_BLOBSTORE_MAP);\n+        Map<String, Map<String, Object>> blobStoreMap = (Map<String, Map<String, Object>>) topoConf.get(Config.TOPOLOGY_BLOBSTORE_MAP);\n         if (blobStoreMap != null) {\n             for (String key : blobStoreMap.keySet()) {\n+\n+                Map<String, Object> blobConf = blobStoreMap.get(key);\n+                try {\n+                    ObjectReader.getBoolean(blobConf.get(\"uncompress\"), false);\n+                    ObjectReader.getBoolean(blobConf.get(\"workerRestart\"), false);\n+                } catch (IllegalArgumentException e) {\n+                    throw new WrappedInvalidTopologyException(\"Invalid blob conf option: \" + e.getMessage());\n+                }\n+\n                 // try to get BlobMeta\n                 // This will check if the key exists and if the subject has authorization\n                 try {\n@@ -1428,7 +1442,7 @@ public class Utils {\n \n     public static Object readYamlFile(String yamlFile) {\n         try (FileReader reader = new FileReader(yamlFile)) {\n-            return new Yaml(new SafeConstructor()).load(reader);\n+            return new Yaml(new SafeConstructor(new LoaderOptions())).load(reader);\n         } catch (Exception ex) {\n             LOG.error(\"Failed to read yaml file.\", ex);\n         }\n@@ -1676,7 +1690,7 @@ public class Utils {\n         if (cp == null || cp.isEmpty()) {\n             return conf;\n         }\n-        Yaml yaml = new Yaml(new SafeConstructor());\n+        Yaml yaml = new Yaml(new SafeConstructor(new LoaderOptions()));\n         Map<String, Object> defaultsConf = null;\n         Map<String, Object> stormConf = null;\n \n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -1,68 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version\n- * 2.0 (the \"License\"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions\n- * and limitations under the License.\n- */\n-\n-package org.apache.storm.hbase.topology;\n-\n-import java.util.HashMap;\n-import java.util.Map;\n-import org.apache.storm.Config;\n-import org.apache.storm.StormSubmitter;\n-import org.apache.storm.hbase.bolt.HBaseLookupBolt;\n-import org.apache.storm.hbase.bolt.mapper.HBaseProjectionCriteria;\n-import org.apache.storm.hbase.bolt.mapper.SimpleHBaseMapper;\n-import org.apache.storm.topology.TopologyBuilder;\n-import org.apache.storm.tuple.Fields;\n-\n-\n-public class LookupWordCount {\n-    private static final String WORD_SPOUT = \"WORD_SPOUT\";\n-    private static final String LOOKUP_BOLT = \"LOOKUP_BOLT\";\n-    private static final String TOTAL_COUNT_BOLT = \"TOTAL_COUNT_BOLT\";\n-\n-    public static void main(String[] args) throws Exception {\n-        Config config = new Config();\n-\n-        Map<String, Object> hbConf = new HashMap<String, Object>();\n-        if (args.length > 0) {\n-            hbConf.put(\"hbase.rootdir\", args[0]);\n-        }\n-        config.put(\"hbase.conf\", hbConf);\n-\n-        WordSpout spout = new WordSpout();\n-\n-        SimpleHBaseMapper mapper = new SimpleHBaseMapper().withRowKeyField(\"word\");\n-        HBaseProjectionCriteria projectionCriteria = new HBaseProjectionCriteria();\n-        projectionCriteria.addColumn(new HBaseProjectionCriteria.ColumnMetaData(\"cf\", \"count\"));\n-\n-        WordCountValueMapper rowToTupleMapper = new WordCountValueMapper();\n-\n-        HBaseLookupBolt lookupBolt = new HBaseLookupBolt(\"WordCount\", mapper, rowToTupleMapper)\n-                .withConfigKey(\"hbase.conf\")\n-                .withProjectionCriteria(projectionCriteria);\n-\n-        //wordspout -> lookupbolt -> totalCountBolt\n-        TopologyBuilder builder = new TopologyBuilder();\n-        builder.setSpout(WORD_SPOUT, spout, 1);\n-        builder.setBolt(LOOKUP_BOLT, lookupBolt, 1).shuffleGrouping(WORD_SPOUT);\n-        TotalWordCounter totalBolt = new TotalWordCounter();\n-        builder.setBolt(TOTAL_COUNT_BOLT, totalBolt, 1).fieldsGrouping(LOOKUP_BOLT, new Fields(\"columnName\"));\n-        String topoName = \"test\";\n-        if (args.length == 1) {\n-            topoName = args[1];\n-        } else if (args.length > 1) {\n-            System.out.println(\"Usage: LookupWordCount <hbase.rootdir>\");\n-            return;\n-        }\n-\n-        StormSubmitter.submitTopology(topoName, config, builder.createTopology());\n-    }\n-}\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -12,8 +12,9 @@\n \n package org.apache.storm.hdfs.spout;\n \n+import static org.hamcrest.MatcherAssert.assertThat;\n import static org.hamcrest.core.Is.is;\n-import static org.junit.Assert.assertThat;\n+import static org.junit.jupiter.api.Assertions.*;\n \n import java.io.BufferedReader;\n import java.io.File;\n@@ -41,38 +42,36 @@ import org.apache.hadoop.util.ReflectionUtils;\n import org.apache.storm.Config;\n import org.apache.storm.hdfs.common.HdfsUtils;\n import org.apache.storm.hdfs.common.HdfsUtils.Pair;\n-import org.apache.storm.hdfs.testing.MiniDFSClusterRule;\n+import org.apache.storm.hdfs.testing.MiniDFSClusterExtensionClassLevel;\n import org.apache.storm.spout.SpoutOutputCollector;\n import org.apache.storm.task.TopologyContext;\n-import org.junit.After;\n-import org.junit.AfterClass;\n-import org.junit.Assert;\n-import org.junit.Before;\n-import org.junit.BeforeClass;\n-import org.junit.ClassRule;\n-import org.junit.Rule;\n-import org.junit.Test;\n-import org.junit.rules.TemporaryFolder;\n+import org.junit.jupiter.api.AfterAll;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.RegisterExtension;\n+import org.junit.jupiter.api.io.TempDir;\n \n public class TestHdfsSpout {\n \n     private static final Configuration conf = new Configuration();\n-    @ClassRule\n-    public static MiniDFSClusterRule DFS_CLUSTER_RULE = new MiniDFSClusterRule();\n+    @RegisterExtension\n+    public static final MiniDFSClusterExtensionClassLevel DFS_CLUSTER_EXTENSION = new MiniDFSClusterExtensionClassLevel();\n     private static DistributedFileSystem fs;\n-    @Rule\n-    public TemporaryFolder tempFolder = new TemporaryFolder();\n+    @TempDir\n+    public File tempFolder;\n     public File baseFolder;\n     private Path source;\n     private Path archive;\n     private Path badfiles;\n \n-    @BeforeClass\n+    @BeforeAll\n     public static void setupClass() throws IOException {\n-        fs = DFS_CLUSTER_RULE.getDfscluster().getFileSystem();\n+        fs = DFS_CLUSTER_EXTENSION.getDfscluster().getFileSystem();\n     }\n \n-    @AfterClass\n+    @AfterAll\n     public static void teardownClass() throws IOException {\n         fs.close();\n     }\n@@ -121,9 +120,10 @@ public class TestHdfsSpout {\n         }\n     }\n \n-    @Before\n+    @BeforeEach\n     public void setup() throws Exception {\n-        baseFolder = tempFolder.newFolder(\"hdfsspout\");\n+        baseFolder = new File(tempFolder, \"hdfsspout\");\n+        baseFolder.mkdir();\n         source = new Path(baseFolder.toString() + \"/source\");\n         fs.mkdirs(source);\n         archive = new Path(baseFolder.toString() + \"/archive\");\n@@ -132,7 +132,7 @@ public class TestHdfsSpout {\n         fs.mkdirs(badfiles);\n     }\n \n-    @After\n+    @AfterEach\n     public void shutDown() throws IOException {\n         fs.delete(new Path(baseFolder.toString()), true);\n     }\n@@ -244,7 +244,7 @@ public class TestHdfsSpout {\n \n                 // consume file 1 partially\n                 List<String> res = runSpout(spout, \"r2\");\n-                Assert.assertEquals(2, res.size());\n+                assertEquals(2, res.size());\n \n                 // abandon file\n                 FileLock lock = getField(spout, \"lock\");\n@@ -252,28 +252,28 @@ public class TestHdfsSpout {\n                 Thread.sleep(lockExpirySec * 2 * 1000);\n \n                 // check lock file presence\n-                Assert.assertTrue(fs.exists(lock.getLockFile()));\n+                assertTrue(fs.exists(lock.getLockFile()));\n \n                 // create another spout to take over processing and read a few lines\n                 List<String> res2 = runSpout(spout2, \"r3\");\n-                Assert.assertEquals(3, res2.size());\n+                assertEquals(3, res2.size());\n \n                 // check lock file presence\n-                Assert.assertTrue(fs.exists(lock.getLockFile()));\n+                assertTrue(fs.exists(lock.getLockFile()));\n \n                 // check lock file contents\n                 List<String> contents = readTextFile(fs, lock.getLockFile().toString());\n-                Assert.assertFalse(contents.isEmpty());\n+                assertFalse(contents.isEmpty());\n \n                 // finish up reading the file\n                 res2 = runSpout(spout2, \"r2\");\n-                Assert.assertEquals(4, res2.size());\n+                assertEquals(4, res2.size());\n \n                 // check lock file is gone\n-                Assert.assertFalse(fs.exists(lock.getLockFile()));\n+                assertFalse(fs.exists(lock.getLockFile()));\n                 FileReader rdr = getField(spout2, \"reader\");\n-                Assert.assertNull(rdr);\n-                Assert.assertTrue(getBoolField(spout2, \"fileReadCompletely\"));\n+                assertNull(rdr);\n+                assertTrue(getBoolField(spout2, \"fileReadCompletely\"));\n             }\n         }\n     }\n@@ -303,35 +303,35 @@ public class TestHdfsSpout {\n \n                 // consume file 1 partially\n                 List<String> res = runSpout(spout, \"r2\");\n-                Assert.assertEquals(2, res.size());\n+                assertEquals(2, res.size());\n                 // abandon file\n                 FileLock lock = getField(spout, \"lock\");\n                 TestFileLock.closeUnderlyingLockFile(lock);\n                 Thread.sleep(lockExpirySec * 2 * 1000);\n \n                 // check lock file presence\n-                Assert.assertTrue(fs.exists(lock.getLockFile()));\n+                assertTrue(fs.exists(lock.getLockFile()));\n \n                 // create another spout to take over processing and read a few lines\n                 List<String> res2 = runSpout(spout2, \"r3\");\n-                Assert.assertEquals(3, res2.size());\n+                assertEquals(3, res2.size());\n \n                 // check lock file presence\n-                Assert.assertTrue(fs.exists(lock.getLockFile()));\n+                assertTrue(fs.exists(lock.getLockFile()));\n \n                 // check lock file contents\n                 List<String> contents = getTextFileContents(fs, lock.getLockFile());\n-                Assert.assertFalse(contents.isEmpty());\n+                assertFalse(contents.isEmpty());\n \n                 // finish up reading the file\n                 res2 = runSpout(spout2, \"r3\");\n-                Assert.assertEquals(4, res2.size());\n+                assertEquals(4, res2.size());\n \n                 // check lock file is gone\n-                Assert.assertFalse(fs.exists(lock.getLockFile()));\n+                assertFalse(fs.exists(lock.getLockFile()));\n                 FileReader rdr = getField(spout2, \"reader\");\n-                Assert.assertNull(rdr);\n-                Assert.assertTrue(getBoolField(spout2, \"fileReadCompletely\"));\n+                assertNull(rdr);\n+                assertTrue(getBoolField(spout2, \"fileReadCompletely\"));\n             }\n         }\n     }\n@@ -347,7 +347,7 @@ public class TestHdfsSpout {\n         for (Pair<HdfsSpout.MessageId, List<Object>> item : collector.items) {\n             actual.add(item.getValue().get(0).toString());\n         }\n-        Assert.assertEquals(expected, actual);\n+        assertEquals(expected, actual);\n     }\n \n     private List<String> getTextFileContents(FileSystem fs, Path txtFile) throws IOException {\n@@ -369,7 +369,7 @@ public class TestHdfsSpout {\n             List<String> lines = getSeqFileContents(fs, seqFile);\n             expected.addAll(lines);\n         }\n-        Assert.assertTrue(expected.equals(collector.lines));\n+        assertTrue(expected.equals(collector.lines));\n     }\n \n     private List<String> getSeqFileContents(FileSystem fs, Path... seqFiles) throws IOException {\n@@ -419,26 +419,26 @@ public class TestHdfsSpout {\n             // read few lines from file1 dont ack\n             runSpout(spout, \"r3\");\n             FileReader reader = getField(spout, \"reader\");\n-            Assert.assertNotNull(reader);\n-            Assert.assertEquals(false, getBoolField(spout, \"fileReadCompletely\"));\n+            assertNotNull(reader);\n+            assertFalse(getBoolField(spout, \"fileReadCompletely\"));\n \n             // read remaining lines\n             runSpout(spout, \"r3\");\n             reader = getField(spout, \"reader\");\n-            Assert.assertNotNull(reader);\n-            Assert.assertEquals(true, getBoolField(spout, \"fileReadCompletely\"));\n+            assertNotNull(reader);\n+            assertTrue(getBoolField(spout, \"fileReadCompletely\"));\n \n             // ack few\n             runSpout(spout, \"a0\", \"a1\", \"a2\");\n             reader = getField(spout, \"reader\");\n-            Assert.assertNotNull(reader);\n-            Assert.assertEquals(true, getBoolField(spout, \"fileReadCompletely\"));\n+            assertNotNull(reader);\n+            assertTrue(getBoolField(spout, \"fileReadCompletely\"));\n \n             //ack rest\n             runSpout(spout, \"a3\", \"a4\");\n             reader = getField(spout, \"reader\");\n-            Assert.assertNull(reader);\n-            Assert.assertEquals(true, getBoolField(spout, \"fileReadCompletely\"));\n+            assertNull(reader);\n+            assertTrue(getBoolField(spout, \"fileReadCompletely\"));\n \n             // go to next file\n             Path file2 = new Path(source.toString() + \"/file2.txt\");\n@@ -446,18 +446,18 @@ public class TestHdfsSpout {\n \n             // Read 1 line\n             runSpout(spout, \"r1\");\n-            Assert.assertNotNull(getField(spout, \"reader\"));\n-            Assert.assertEquals(false, getBoolField(spout, \"fileReadCompletely\"));\n+            assertNotNull(getField(spout, \"reader\"));\n+            assertFalse(getBoolField(spout, \"fileReadCompletely\"));\n \n             // ack 1 tuple\n             runSpout(spout, \"a5\");\n-            Assert.assertNotNull(getField(spout, \"reader\"));\n-            Assert.assertEquals(false, getBoolField(spout, \"fileReadCompletely\"));\n+            assertNotNull(getField(spout, \"reader\"));\n+            assertFalse(getBoolField(spout, \"fileReadCompletely\"));\n \n             // read and ack remaining lines\n             runSpout(spout, \"r5\", \"a6\", \"a7\", \"a8\", \"a9\");\n-            Assert.assertNull(getField(spout, \"reader\"));\n-            Assert.assertEquals(true, getBoolField(spout, \"fileReadCompletely\"));\n+            assertNull(getField(spout, \"reader\"));\n+            assertTrue(getBoolField(spout, \"fileReadCompletely\"));\n         }\n     }\n \n@@ -482,9 +482,9 @@ public class TestHdfsSpout {\n \n             // consume both files\n             List<String> res = runSpout(spout, \"r11\");\n-            Assert.assertEquals(10, res.size());\n+            assertEquals(10, res.size());\n \n-            Assert.assertEquals(2, listDir(archive).size());\n+            assertEquals(2, listDir(archive).size());\n \n             Path f1 = new Path(archive + \"/file1.seq\");\n             Path f2 = new Path(archive + \"/file2.seq\");\n@@ -501,7 +501,7 @@ public class TestHdfsSpout {\n \n         createTextFile(file1, 6);\n         createTextFile(file2, 7);\n-        Assert.assertEquals(2, listDir(source).size());\n+        assertEquals(2, listDir(source).size());\n \n         // 2) run spout\n         try (\n@@ -512,12 +512,12 @@ public class TestHdfsSpout {\n \n             List<String> res = runSpout(spout, \"r11\");\n             String[] expected = new String[]{ \"[line 0]\", \"[line 1]\", \"[line 2]\", \"[line 0]\", \"[line 1]\", \"[line 2]\" };\n-            Assert.assertArrayEquals(expected, res.toArray());\n+            assertArrayEquals(expected, res.toArray());\n \n             // 3) make sure 6 lines (3 from each file) were read in all\n-            Assert.assertEquals(((MockCollector) spout.getCollector()).lines.size(), 6);\n+            assertEquals(((MockCollector) spout.getCollector()).lines.size(), 6);\n             ArrayList<Path> badFiles = HdfsUtils.listFilesByModificationTime(fs, badfiles, 0);\n-            Assert.assertEquals(badFiles.size(), 2);\n+            assertEquals(badFiles.size(), 2);\n         }\n     }\n \n@@ -538,18 +538,18 @@ public class TestHdfsSpout {\n \n             // 1) read initial lines in file, then check if lock exists\n             List<String> res = runSpout(spout, \"r5\");\n-            Assert.assertEquals(5, res.size());\n+            assertEquals(5, res.size());\n             List<String> lockFiles = listDir(spout.getLockDirPath());\n-            Assert.assertEquals(1, lockFiles.size());\n+            assertEquals(1, lockFiles.size());\n \n             // 2) check log file content line count == tuples emitted + 1\n             List<String> lines = readTextFile(fs, lockFiles.get(0));\n-            Assert.assertEquals(lines.size(), res.size() + 1);\n+            assertEquals(lines.size(), res.size() + 1);\n \n             // 3) read remaining lines in file, then ensure lock is gone\n             runSpout(spout, \"r6\");\n             lockFiles = listDir(spout.getLockDirPath());\n-            Assert.assertEquals(0, lockFiles.size());\n+            assertEquals(0, lockFiles.size());\n \n             // 4)  --- Create another input file and reverify same behavior ---\n             Path file2 = new Path(source.toString() + \"/file2.txt\");\n@@ -557,18 +557,18 @@ public class TestHdfsSpout {\n \n             // 5) read initial lines in file, then check if lock exists\n             res = runSpout(spout, \"r5\");\n-            Assert.assertEquals(15, res.size());\n+            assertEquals(15, res.size());\n             lockFiles = listDir(spout.getLockDirPath());\n-            Assert.assertEquals(1, lockFiles.size());\n+            assertEquals(1, lockFiles.size());\n \n             // 6) check log file content line count == tuples emitted + 1\n             lines = readTextFile(fs, lockFiles.get(0));\n-            Assert.assertEquals(6, lines.size());\n+            assertEquals(6, lines.size());\n \n             // 7) read remaining lines in file, then ensure lock is gone\n             runSpout(spout, \"r6\");\n             lockFiles = listDir(spout.getLockDirPath());\n-            Assert.assertEquals(0, lockFiles.size());\n+            assertEquals(0, lockFiles.size());\n         }\n     }\n \n@@ -592,12 +592,12 @@ public class TestHdfsSpout {\n             // 2) check log file contents\n             String lockFile = listDir(spout.getLockDirPath()).get(0);\n             List<String> lines = readTextFile(fs, lockFile);\n-            Assert.assertEquals(lines.size(), 3);\n+            assertEquals(lines.size(), 3);\n \n             // 3) read 6th line and see if another log entry was made\n             runSpout(spout, \"r1\");\n             lines = readTextFile(fs, lockFile);\n-            Assert.assertEquals(lines.size(), 4);\n+            assertEquals(lines.size(), 4);\n         }\n     }\n \n@@ -621,13 +621,13 @@ public class TestHdfsSpout {\n             // 2) check log file contents\n             String lockFile = listDir(spout.getLockDirPath()).get(0);\n             List<String> lines = readTextFile(fs, lockFile);\n-            Assert.assertEquals(lines.size(), 1);\n+            assertEquals(lines.size(), 1);\n             Thread.sleep(3000); // allow freq_sec to expire\n \n             // 3) read another line and see if another log entry was made\n             runSpout(spout, \"r1\");\n             lines = readTextFile(fs, lockFile);\n-            Assert.assertEquals(2, lines.size());\n+            assertEquals(2, lines.size());\n         }\n     }\n \n@@ -640,7 +640,7 @@ public class TestHdfsSpout {\n     private AutoCloseableHdfsSpout makeSpout(String readerType, String[] outputFields) {\n         HdfsSpout spout = new HdfsSpout().withOutputFields(outputFields)\n                                          .setReaderType(readerType)\n-                                         .setHdfsUri(DFS_CLUSTER_RULE.getDfscluster().getURI().toString())\n+                                         .setHdfsUri(DFS_CLUSTER_EXTENSION.getDfscluster().getURI().toString())\n                                          .setSourceDir(source.toString())\n                                          .setArchiveDir(archive.toString())\n                                          .setBadFilesDir(badfiles.toString());\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -1,132 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.storm.rocketmq.trident.state;\n-\n-import java.io.Serializable;\n-import java.util.LinkedList;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Properties;\n-import java.util.UUID;\n-\n-import org.apache.commons.lang.Validate;\n-import org.apache.rocketmq.client.exception.MQClientException;\n-import org.apache.rocketmq.client.producer.DefaultMQProducer;\n-import org.apache.rocketmq.common.message.Message;\n-import org.apache.storm.rocketmq.RocketMqConfig;\n-import org.apache.storm.rocketmq.common.mapper.TupleToMessageMapper;\n-import org.apache.storm.rocketmq.common.selector.TopicSelector;\n-import org.apache.storm.topology.FailedException;\n-import org.apache.storm.trident.operation.TridentCollector;\n-import org.apache.storm.trident.state.State;\n-import org.apache.storm.trident.tuple.TridentTuple;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-public class RocketMqState implements State {\n-\n-    private static final Logger LOG = LoggerFactory.getLogger(RocketMqState.class);\n-\n-    private Options options;\n-    private DefaultMQProducer producer;\n-\n-    protected RocketMqState(Map<String, Object> map, Options options) {\n-        this.options = options;\n-    }\n-\n-    public static class Options implements Serializable {\n-        private TopicSelector selector;\n-        private TupleToMessageMapper mapper;\n-        private Properties properties;\n-\n-        public Options withSelector(TopicSelector selector) {\n-            this.selector = selector;\n-            return this;\n-        }\n-\n-        public Options withMapper(TupleToMessageMapper mapper) {\n-            this.mapper = mapper;\n-            return this;\n-        }\n-\n-        public Options withProperties(Properties properties) {\n-            this.properties = properties;\n-            return this;\n-        }\n-    }\n-\n-    protected void prepare() {\n-        Validate.notEmpty(options.properties, \"Producer properties can not be empty\");\n-        Validate.notNull(options.selector, \"TopicSelector can not be null\");\n-        Validate.notNull(options.mapper, \"TupleToMessageMapper can not be null\");\n-\n-        producer = new DefaultMQProducer();\n-        producer.setInstanceName(UUID.randomUUID().toString());\n-        RocketMqConfig.buildProducerConfigs(options.properties, producer);\n-\n-        try {\n-            producer.start();\n-        } catch (MQClientException e) {\n-            throw new RuntimeException(e);\n-        }\n-    }\n-\n-    @Override\n-    public void beginCommit(Long txid) {\n-        LOG.debug(\"beginCommit is noop.\");\n-    }\n-\n-    @Override\n-    public void commit(Long txid) {\n-        LOG.debug(\"commit is noop.\");\n-    }\n-\n-    /**\n-     * Update the RocketMQ state.\n-     * @param tuples trident tuples\n-     * @param collector trident collector\n-     */\n-    public void updateState(List<TridentTuple> tuples, TridentCollector collector) {\n-        List<Message> messages = new LinkedList<>();\n-\n-        for (TridentTuple tuple : tuples) {\n-            String topic = options.selector.getTopic(tuple);\n-            String tag = options.selector.getTag(tuple);\n-            String key = options.mapper.getKeyFromTuple(tuple);\n-            byte[] value = options.mapper.getValueFromTuple(tuple);\n-\n-            if (topic == null) {\n-                LOG.warn(\"skipping Message with Key = \" + key + \", topic selector returned null.\");\n-                continue;\n-            }\n-\n-            Message msg = new Message(topic, tag, key, value);\n-            messages.add(msg);\n-        }\n-\n-        try {\n-            this.producer.send(messages);\n-        } catch (Exception e) {\n-            LOG.warn(\"Batch write failed. Triggering replay.\", e);\n-            collector.reportError(e);\n-            throw new FailedException(e);\n-        }\n-    }\n-\n-}\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -16,15 +16,15 @@\n  * limitations under the License.\n  */\n /**\n- * Autogenerated by Thrift Compiler (0.13.0)\n+ * Autogenerated by Thrift Compiler (0.18.1)\n  *\n  * DO NOT EDIT UNLESS YOU ARE SURE THAT YOU KNOW WHAT YOU ARE DOING\n  *  @generated\n  */\n package org.apache.storm.generated;\n \n+@javax.annotation.Generated(value = \"Autogenerated by Thrift Compiler (0.18.1)\")\n @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n-@javax.annotation.Generated(value = \"Autogenerated by Thrift Compiler (0.13.0)\")\n public class DistributedRPC {\n \n   public interface Iface {\n@@ -42,9 +42,11 @@ public class DistributedRPC {\n   public static class Client extends org.apache.storm.thrift.TServiceClient implements Iface {\n     public static class Factory implements org.apache.storm.thrift.TServiceClientFactory<Client> {\n       public Factory() {}\n+      @Override\n       public Client getClient(org.apache.storm.thrift.protocol.TProtocol prot) {\n         return new Client(prot);\n       }\n+      @Override\n       public Client getClient(org.apache.storm.thrift.protocol.TProtocol iprot, org.apache.storm.thrift.protocol.TProtocol oprot) {\n         return new Client(iprot, oprot);\n       }\n@@ -59,6 +61,7 @@ public class DistributedRPC {\n       super(iprot, oprot);\n     }\n \n+    @Override\n     public java.lang.String execute(java.lang.String functionName, java.lang.String funcArgs) throws DRPCExecutionException, AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_execute(functionName, funcArgs);\n@@ -98,6 +101,7 @@ public class DistributedRPC {\n         this.clientManager = clientManager;\n         this.protocolFactory = protocolFactory;\n       }\n+    @Override\n       public AsyncClient getAsyncClient(org.apache.storm.thrift.transport.TNonblockingTransport transport) {\n         return new AsyncClient(protocolFactory, clientManager, transport);\n       }\n@@ -107,6 +111,7 @@ public class DistributedRPC {\n       super(protocolFactory, clientManager, transport);\n     }\n \n+    @Override\n     public void execute(java.lang.String functionName, java.lang.String funcArgs, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       execute_call method_call = new execute_call(functionName, funcArgs, resultHandler, this, ___protocolFactory, ___transport);\n@@ -123,6 +128,7 @@ public class DistributedRPC {\n         this.funcArgs = funcArgs;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"execute\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         execute_args args = new execute_args();\n@@ -132,6 +138,7 @@ public class DistributedRPC {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public java.lang.String getResult() throws DRPCExecutionException, AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n@@ -164,10 +171,12 @@ public class DistributedRPC {\n         super(\"execute\");\n       }\n \n+      @Override\n       public execute_args getEmptyArgsInstance() {\n         return new execute_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -177,6 +186,7 @@ public class DistributedRPC {\n         return false;\n       }\n \n+      @Override\n       public execute_result getResult(I iface, execute_args args) throws org.apache.storm.thrift.TException {\n         execute_result result = new execute_result();\n         try {\n@@ -212,13 +222,16 @@ public class DistributedRPC {\n         super(\"execute\");\n       }\n \n+      @Override\n       public execute_args getEmptyArgsInstance() {\n         return new execute_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String>() { \n+          @Override\n           public void onComplete(java.lang.String o) {\n             execute_result result = new execute_result();\n             result.success = o;\n@@ -232,6 +245,7 @@ public class DistributedRPC {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -267,10 +281,12 @@ public class DistributedRPC {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, execute_args args, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.execute(args.functionName, args.funcArgs,resultHandler);\n       }\n@@ -278,6 +294,7 @@ public class DistributedRPC {\n \n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class execute_args implements org.apache.storm.thrift.TBase<execute_args, execute_args._Fields>, java.io.Serializable, Cloneable, Comparable<execute_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"execute_args\");\n \n@@ -344,10 +361,12 @@ public class DistributedRPC {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -389,6 +408,7 @@ public class DistributedRPC {\n       }\n     }\n \n+    @Override\n     public execute_args deepCopy() {\n       return new execute_args(this);\n     }\n@@ -447,6 +467,7 @@ public class DistributedRPC {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case FUNCTION_NAME:\n@@ -469,6 +490,7 @@ public class DistributedRPC {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case FUNCTION_NAME:\n@@ -482,6 +504,7 @@ public class DistributedRPC {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -498,8 +521,6 @@ public class DistributedRPC {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof execute_args)\n         return this.equals((execute_args)that);\n       return false;\n@@ -555,7 +576,7 @@ public class DistributedRPC {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_functionName()).compareTo(other.is_set_functionName());\n+      lastComparison = java.lang.Boolean.compare(is_set_functionName(), other.is_set_functionName());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -565,7 +586,7 @@ public class DistributedRPC {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_funcArgs()).compareTo(other.is_set_funcArgs());\n+      lastComparison = java.lang.Boolean.compare(is_set_funcArgs(), other.is_set_funcArgs());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -579,14 +600,17 @@ public class DistributedRPC {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -637,6 +661,7 @@ public class DistributedRPC {\n     }\n \n     private static class execute_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public execute_argsStandardScheme getScheme() {\n         return new execute_argsStandardScheme();\n       }\n@@ -644,6 +669,7 @@ public class DistributedRPC {\n \n     private static class execute_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<execute_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, execute_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -679,6 +705,7 @@ public class DistributedRPC {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, execute_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -700,6 +727,7 @@ public class DistributedRPC {\n     }\n \n     private static class execute_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public execute_argsTupleScheme getScheme() {\n         return new execute_argsTupleScheme();\n       }\n@@ -746,6 +774,7 @@ public class DistributedRPC {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class execute_result implements org.apache.storm.thrift.TBase<execute_result, execute_result._Fields>, java.io.Serializable, Cloneable, Comparable<execute_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"execute_result\");\n \n@@ -817,10 +846,12 @@ public class DistributedRPC {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -869,6 +900,7 @@ public class DistributedRPC {\n       }\n     }\n \n+    @Override\n     public execute_result deepCopy() {\n       return new execute_result(this);\n     }\n@@ -952,6 +984,7 @@ public class DistributedRPC {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case SUCCESS:\n@@ -982,6 +1015,7 @@ public class DistributedRPC {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case SUCCESS:\n@@ -998,6 +1032,7 @@ public class DistributedRPC {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -1016,8 +1051,6 @@ public class DistributedRPC {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof execute_result)\n         return this.equals((execute_result)that);\n       return false;\n@@ -1086,7 +1119,7 @@ public class DistributedRPC {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_success()).compareTo(other.is_set_success());\n+      lastComparison = java.lang.Boolean.compare(is_set_success(), other.is_set_success());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -1096,7 +1129,7 @@ public class DistributedRPC {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_e()).compareTo(other.is_set_e());\n+      lastComparison = java.lang.Boolean.compare(is_set_e(), other.is_set_e());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -1106,7 +1139,7 @@ public class DistributedRPC {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -1120,10 +1153,12 @@ public class DistributedRPC {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -1186,6 +1221,7 @@ public class DistributedRPC {\n     }\n \n     private static class execute_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public execute_resultStandardScheme getScheme() {\n         return new execute_resultStandardScheme();\n       }\n@@ -1193,6 +1229,7 @@ public class DistributedRPC {\n \n     private static class execute_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<execute_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, execute_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -1238,6 +1275,7 @@ public class DistributedRPC {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, execute_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -1264,6 +1302,7 @@ public class DistributedRPC {\n     }\n \n     private static class execute_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public execute_resultTupleScheme getScheme() {\n         return new execute_resultTupleScheme();\n       }\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -1,57 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.storm.kinesis.spout.test;\n-\n-import com.amazonaws.ClientConfiguration;\n-import com.amazonaws.regions.Regions;\n-import com.amazonaws.services.kinesis.model.ShardIteratorType;\n-import org.apache.storm.Config;\n-import org.apache.storm.StormSubmitter;\n-import org.apache.storm.generated.AlreadyAliveException;\n-import org.apache.storm.generated.AuthorizationException;\n-import org.apache.storm.generated.InvalidTopologyException;\n-import org.apache.storm.kinesis.spout.CredentialsProviderChain;\n-import org.apache.storm.kinesis.spout.ExponentialBackoffRetrier;\n-import org.apache.storm.kinesis.spout.KinesisConfig;\n-import org.apache.storm.kinesis.spout.KinesisConnectionInfo;\n-import org.apache.storm.kinesis.spout.KinesisSpout;\n-import org.apache.storm.kinesis.spout.RecordToTupleMapper;\n-import org.apache.storm.kinesis.spout.ZkInfo;\n-import org.apache.storm.topology.TopologyBuilder;\n-\n-import java.util.Date;\n-\n-public class KinesisSpoutTopology {\n-    public static void main (String args[]) throws InvalidTopologyException, AuthorizationException, AlreadyAliveException {\n-        String topologyName = args[0];\n-        RecordToTupleMapper recordToTupleMapper = new TestRecordToTupleMapper();\n-        KinesisConnectionInfo kinesisConnectionInfo = new KinesisConnectionInfo(new CredentialsProviderChain(), new ClientConfiguration(), Regions.US_WEST_2,\n-                1000);\n-        ZkInfo zkInfo = new ZkInfo(\"localhost:2181\", \"/kinesisOffsets\", 20000, 15000, 10000L, 3, 2000);\n-        KinesisConfig kinesisConfig = new KinesisConfig(args[1], ShardIteratorType.TRIM_HORIZON,\n-                recordToTupleMapper, new Date(), new ExponentialBackoffRetrier(), zkInfo, kinesisConnectionInfo, 10000L);\n-        KinesisSpout kinesisSpout = new KinesisSpout(kinesisConfig);\n-        TopologyBuilder topologyBuilder = new TopologyBuilder();\n-        topologyBuilder.setSpout(\"spout\", kinesisSpout, 3);\n-        topologyBuilder.setBolt(\"bolt\", new KinesisBoltTest(), 1).shuffleGrouping(\"spout\");\n-        Config topologyConfig = new Config();\n-        topologyConfig.setDebug(true);\n-        topologyConfig.setNumWorkers(3);\n-        StormSubmitter.submitTopology(topologyName, topologyConfig, topologyBuilder.createTopology());\n-    }\n-}\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -15,8 +15,8 @@ package org.apache.storm.hive.bolt.mapper;\n import java.io.IOException;\n import java.text.SimpleDateFormat;\n import java.util.ArrayList;\n-import java.util.Date;\n import java.util.List;\n+import net.minidev.json.JSONObject;\n import org.apache.hive.hcatalog.streaming.HiveEndPoint;\n import org.apache.hive.hcatalog.streaming.RecordWriter;\n import org.apache.hive.hcatalog.streaming.StreamingException;\n@@ -25,7 +25,6 @@ import org.apache.hive.hcatalog.streaming.TransactionBatch;\n import org.apache.storm.trident.tuple.TridentTuple;\n import org.apache.storm.tuple.Fields;\n import org.apache.storm.tuple.Tuple;\n-import org.json.simple.JSONObject;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -1,35 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version\n- * 2.0 (the \"License\"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions\n- * and limitations under the License.\n- */\n-\n-package org.apache.storm.hbase.bolt.mapper;\n-\n-import java.io.Serializable;\n-\n-import org.apache.storm.hbase.common.ColumnList;\n-import org.apache.storm.tuple.Tuple;\n-\n-/**\n- * Maps a <code>org.apache.storm.tuple.Tuple</code> object to a row in an HBase table.\n- */\n-public interface HBaseMapper extends Serializable {\n-\n-    /**\n-     * Given a tuple, return the HBase rowkey.\n-     */\n-    byte[] rowKey(Tuple tuple);\n-\n-    /**\n-     * Given a tuple, return a list of HBase columns to insert.\n-     */\n-    ColumnList columns(Tuple tuple);\n-\n-}\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -131,10 +131,9 @@ public class Config extends HashMap<String, Object> {\n     public static final String TASK_CREDENTIALS_POLL_SECS = \"task.credentials.poll.secs\";\n     /**\n      * Whether to enable backpressure in for a certain topology.\n-     *\n-     * @deprecated: In Storm 2.0. Retained for enabling transition from 1.x. Will be removed soon.\n+     * Note: Retained for enabling transition from 1.x. Will be removed soon.\n      */\n-    @Deprecated\n+    @Deprecated(forRemoval = true, since = \"2.0.0\")\n     @IsBoolean\n     public static final String TOPOLOGY_BACKPRESSURE_ENABLE = \"topology.backpressure.enable\";\n     /**\n@@ -277,6 +276,19 @@ public class Config extends HashMap<String, Object> {\n     @IsBoolean\n     public static final String TOPOLOGY_ENABLE_V2_METRICS_TICK = \"topology.enable.v2.metrics.tick\";\n \n+    /**\n+     * Topology configuration to specify the V2 metrics tick interval in seconds.\n+     */\n+    @IsInteger\n+    @IsPositiveNumber\n+    public static final String TOPOLOGY_V2_METRICS_TICK_INTERVAL_SECONDS = \"topology.v2.metrics.tick.interval.seconds\";\n+\n+    /**\n+     * This config allows a topology to enable/disable reporting of __send-iconnection metrics.\n+     */\n+    @IsBoolean\n+    public static final String TOPOLOGY_ENABLE_SEND_ICONNECTION_METRICS = \"topology.enable.send.iconnection.metrics\";\n+\n     /**\n      * The class name of the {@link org.apache.storm.state.StateProvider} implementation. If not specified defaults to {@link\n      * org.apache.storm.state.InMemoryKeyValueStateProvider}. This can be overridden at the component level.\n@@ -409,14 +421,41 @@ public class Config extends HashMap<String, Object> {\n     /**\n      * How many executors to spawn for ackers.\n      *\n-     * <p>By not setting this variable or setting it as null, Storm will set the number of acker executors to be equal to\n-     * the number of workers configured for this topology (or the estimated number of workers if the Resource Aware Scheduler is used).\n-     * If this variable is set to 0, then Storm will immediately ack tuples as soon as they come off the spout,\n-     * effectively disabling reliability.</p>\n+     * <p>\n+     * 1. If not setting this variable or setting it as null,\n+     *   a. If RAS is not used:\n+     *        Nimbus will set it to {@link Config#TOPOLOGY_WORKERS}.\n+     *   b. If RAS is used:\n+     *        Nimbus will set it to (the estimate number of workers *  {@link Config#TOPOLOGY_RAS_ACKER_EXECUTORS_PER_WORKER}).\n+     *        {@link Config#TOPOLOGY_RAS_ACKER_EXECUTORS_PER_WORKER} is default to be 1 if not set.\n+     * 2. If this variable is set to 0,\n+     *    then Storm will immediately ack tuples as soon as they come off the spout,\n+     *    effectively disabling reliability.\n+     * 3. If this variable is set to a positive integer,\n+     *    Storm will not honor {@link Config#TOPOLOGY_RAS_ACKER_EXECUTORS_PER_WORKER} setting.\n+     *    Instead, nimbus will set it as (this variable / estimate num of workers).\n+     * </p>\n      */\n     @IsInteger\n     @IsPositiveNumber(includeZero = true)\n     public static final String TOPOLOGY_ACKER_EXECUTORS = \"topology.acker.executors\";\n+\n+    /**\n+     * How many ackers to put in when launching a new worker until we run out of ackers.\n+     *\n+     * <p>\n+     * This setting is RAS specific.\n+     * If {@link Config#TOPOLOGY_ACKER_EXECUTORS} is not configured,\n+     * this setting will be used to calculate {@link Config#TOPOLOGY_ACKER_EXECUTORS}.\n+     *\n+     * If {@link Config#TOPOLOGY_ACKER_EXECUTORS} is configured,\n+     * nimbus will ignore this and set it as ({@link Config#TOPOLOGY_ACKER_EXECUTORS} / estimate num of workers).\n+     * </p>\n+     */\n+    @IsInteger\n+    @IsPositiveNumber(includeZero = true)\n+    public static final String TOPOLOGY_RAS_ACKER_EXECUTORS_PER_WORKER = \"topology.ras.acker.executors.per.worker\";\n+\n     /**\n      * A list of classes implementing IEventLogger (See storm.yaml.example for exact config format). Each listed class will be routed all\n      * the events sampled from emitting tuples. If there's no class provided to the option, default event logger will be initialized and\n@@ -548,7 +587,7 @@ public class Config extends HashMap<String, Object> {\n     @IsInteger\n     public static final String TOPOLOGY_BUILTIN_METRICS_BUCKET_SIZE_SECS = \"topology.builtin.metrics.bucket.size.secs\";\n     /**\n-     * Whether or not to use Java serialization in a topology.\n+     * Whether or not to use Java serialization in a topology. Default is set false for security reasons.\n      */\n     @IsBoolean\n     public static final String TOPOLOGY_FALL_BACK_ON_JAVA_SERIALIZATION = \"topology.fall.back.on.java.serialization\";\n@@ -819,9 +858,18 @@ public class Config extends HashMap<String, Object> {\n     @IsString\n     public static final String STORM_DO_AS_USER = \"storm.doAsUser\";\n     /**\n-     * The number of machines that should be used by this topology to isolate it from all others. Set storm.scheduler to\n-     * org.apache.storm.scheduler.multitenant.MultitenantScheduler\n-     */\n+     * The maximum number of machines that should be used by this topology. This configuration can\n+     * be used to isolate topologies from each other. See {@code  org.apache.storm.scheduler.multitenant.MultitenantScheduler}.\n+     * Round Robin Strategy uses this value to avoid spreading a topology too\n+     * thinly over a large number of machines - avoiding the extreme case where the topology would be spread over\n+     * all workers and thus deny scheduling of other topologies. Round Robin scheduling will occupy all the workers on\n+     * this limited number of machines, forcing other topologies to be scheduled on other machines; thus isolating the\n+     * topology from other topologies.\n+     * Set {@code storm.scheduler} to {@code org.apache.storm.scheduler.multitenant.MultitenantScheduler}\n+     * Alternatively set {@code storm.scheduler} to {@code org.apache.storm.scheduler.resource.ResourceAwareScheduler}\n+     * using {@link Config#TOPOLOGY_SCHEDULER_STRATEGY} set to\n+     * {@code org.apache.storm.scheduler.resource.strategies.scheduling.RoundRobinResourceAwareStrategy}\n+     * */\n     @IsInteger\n     @IsPositiveNumber\n     public static final String TOPOLOGY_ISOLATED_MACHINES = \"topology.isolate.machines\";\n@@ -1181,11 +1229,17 @@ public class Config extends HashMap<String, Object> {\n     @IsListEntryCustom(entryValidatorClasses = { MetricReportersValidator.class })\n     public static final String TOPOLOGY_METRICS_REPORTERS = \"topology.metrics.reporters\";\n \n+    /**\n+     * A list of system metrics reporters that will get added to each topology.\n+     */\n+    @IsListEntryCustom(entryValidatorClasses = { MetricReportersValidator.class })\n+    public static final String STORM_TOPOLOGY_METRICS_SYSTEM_REPORTERS = \"storm.topology.metrics.system.reporters\";\n+\n     /**\n      * Configure the topology metrics reporters to be used on workers.\n-     * @deprecated Use {@link Config#TOPOLOGY_METRICS_REPORTERS} instead.\n+     * Use {@link Config#TOPOLOGY_METRICS_REPORTERS} instead.\n      */\n-    @Deprecated\n+    @Deprecated(forRemoval = true, since = \"2.0.0\")\n     @IsListEntryCustom(entryValidatorClasses = { MetricReportersValidator.class })\n     public static final String STORM_METRICS_REPORTERS = \"storm.metrics.reporters\";\n \n@@ -1214,9 +1268,9 @@ public class Config extends HashMap<String, Object> {\n      * If the instance field of the principal is the string \"_HOST\", it will\n      * be replaced with the host name of the server the daemon is running on\n      * (by calling {@link #getBlobstoreHDFSPrincipal(Map conf)} method).\n-     * @Deprecated Use {@link Config#STORM_HDFS_LOGIN_PRINCIPAL} instead.\n+     * Note: Use {@link Config#STORM_HDFS_LOGIN_PRINCIPAL} instead.\n      */\n-    @Deprecated\n+    @Deprecated(forRemoval = true, since = \"2.0.0\")\n     @IsString\n     public static final String BLOBSTORE_HDFS_PRINCIPAL = \"blobstore.hdfs.principal\";\n     /**\n@@ -1397,6 +1451,7 @@ public class Config extends HashMap<String, Object> {\n     public static final String STORM_MESSAGING_TRANSPORT = \"storm.messaging.transport\";\n     /**\n      * Netty based messaging: Is authentication required for Netty messaging from client worker process to server worker process.\n+     * See https://issues.apache.org/jira/browse/STORM-348 for more details\n      */\n     @IsBoolean\n     public static final String STORM_MESSAGING_NETTY_AUTHENTICATION = \"storm.messaging.netty.authentication\";\n@@ -1611,43 +1666,6 @@ public class Config extends HashMap<String, Object> {\n      */\n     @IsString\n     public static final String STORM_WORKERS_ARTIFACTS_DIR = \"storm.workers.artifacts.dir\";\n-    /**\n-     * A list of hosts of Exhibitor servers used to discover/maintain connection to ZooKeeper cluster. Any configured ZooKeeper servers will\n-     * be used for the curator/exhibitor backup connection string.\n-     */\n-    @IsStringList\n-    public static final String STORM_EXHIBITOR_SERVERS = \"storm.exhibitor.servers\";\n-    /**\n-     * The port Storm will use to connect to each of the exhibitor servers.\n-     */\n-    @IsInteger\n-    @IsPositiveNumber\n-    public static final String STORM_EXHIBITOR_PORT = \"storm.exhibitor.port\";\n-    /*\n-     * How often to poll Exhibitor cluster in millis.\n-     */\n-    @IsString\n-    public static final String STORM_EXHIBITOR_URIPATH = \"storm.exhibitor.poll.uripath\";\n-    /**\n-     * How often to poll Exhibitor cluster in millis.\n-     */\n-    @IsInteger\n-    public static final String STORM_EXHIBITOR_POLL = \"storm.exhibitor.poll.millis\";\n-    /**\n-     * The number of times to retry an Exhibitor operation.\n-     */\n-    @IsInteger\n-    public static final String STORM_EXHIBITOR_RETRY_TIMES = \"storm.exhibitor.retry.times\";\n-    /*\n-     * The interval between retries of an Exhibitor operation.\n-     */\n-    @IsInteger\n-    public static final String STORM_EXHIBITOR_RETRY_INTERVAL = \"storm.exhibitor.retry.interval\";\n-    /**\n-     * The ceiling of the interval between retries of an Exhibitor operation.\n-     */\n-    @IsInteger\n-    public static final String STORM_EXHIBITOR_RETRY_INTERVAL_CEILING = \"storm.exhibitor.retry.intervalceiling.millis\";\n     /**\n      * The connection timeout for clients to ZooKeeper.\n      */\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -49,7 +49,6 @@ import org.apache.storm.daemon.Acker;\n import org.apache.storm.daemon.GrouperFactory;\n import org.apache.storm.daemon.StormCommon;\n import org.apache.storm.daemon.Task;\n-import org.apache.storm.daemon.metrics.ErrorReportingMetrics;\n import org.apache.storm.daemon.worker.WorkerState;\n import org.apache.storm.executor.bolt.BoltExecutor;\n import org.apache.storm.executor.error.IReportError;\n@@ -66,11 +65,13 @@ import org.apache.storm.grouping.LoadAwareCustomStreamGrouping;\n import org.apache.storm.grouping.LoadMapping;\n import org.apache.storm.metric.api.IMetric;\n import org.apache.storm.metric.api.IMetricsConsumer;\n+import org.apache.storm.metrics2.PerReporterGauge;\n+import org.apache.storm.metrics2.RateCounter;\n import org.apache.storm.shade.com.google.common.annotations.VisibleForTesting;\n import org.apache.storm.shade.com.google.common.collect.Lists;\n+import org.apache.storm.shade.net.minidev.json.JSONValue;\n+import org.apache.storm.shade.net.minidev.json.parser.ParseException;\n import org.apache.storm.shade.org.jctools.queues.MpscChunkedArrayQueue;\n-import org.apache.storm.shade.org.json.simple.JSONValue;\n-import org.apache.storm.shade.org.json.simple.parser.ParseException;\n import org.apache.storm.stats.ClientStatsUtil;\n import org.apache.storm.stats.CommonStats;\n import org.apache.storm.task.WorkerTopologyContext;\n@@ -119,7 +120,6 @@ public abstract class Executor implements Callable, JCQueue.Consumer {\n     protected final Boolean isDebug;\n     protected final Boolean hasEventLoggers;\n     protected final boolean ackingEnabled;\n-    protected final ErrorReportingMetrics errorReportingMetrics;\n     protected final MpscChunkedArrayQueue<AddressedTuple> pendingEmits = new MpscChunkedArrayQueue<>(1024, (int) Math.pow(2, 30));\n     private final AddressedTuple flushTuple;\n     protected ExecutorTransfer executorTransfer;\n@@ -128,6 +128,9 @@ public abstract class Executor implements Callable, JCQueue.Consumer {\n     protected String hostname;\n     private static final double msDurationFactor = 1.0 / TimeUnit.MILLISECONDS.toNanos(1);\n     private AtomicBoolean needToRefreshCreds = new AtomicBoolean(false);\n+    private final RateCounter reportedErrorCount;\n+    private final boolean enableV2MetricsDataPoints;\n+    private final Integer v2MetricsTickInterval;\n \n     protected Executor(WorkerState workerData, List<Long> executorId, Map<String, String> credentials, String type) {\n         this.workerData = workerData;\n@@ -180,8 +183,12 @@ public abstract class Executor implements Callable, JCQueue.Consumer {\n         } catch (UnknownHostException ignored) {\n             this.hostname = \"\";\n         }\n-        this.errorReportingMetrics = new ErrorReportingMetrics();\n         flushTuple = AddressedTuple.createFlushTuple(workerTopologyContext);\n+        this.reportedErrorCount = workerData.getMetricRegistry().rateCounter(\"__reported-error-count\", componentId,\n+                taskIds.get(0));\n+\n+        enableV2MetricsDataPoints = ObjectReader.getBoolean(topoConf.get(Config.TOPOLOGY_ENABLE_V2_METRICS_TICK), false);\n+        v2MetricsTickInterval = ObjectReader.getInt(topoConf.get(Config.TOPOLOGY_V2_METRICS_TICK_INTERVAL_SECONDS), 60);\n     }\n \n     public static Executor mkExecutor(WorkerState workerState, List<Long> executorId, Map<String, String> credentials) {\n@@ -328,15 +335,17 @@ public abstract class Executor implements Callable, JCQueue.Consumer {\n             List<IMetricsConsumer.DataPoint> dataPoints = new ArrayList<>();\n             if (nameToRegistry != null) {\n                 for (Map.Entry<String, IMetric> entry : nameToRegistry.entrySet()) {\n+                    String name = entry.getKey();\n                     IMetric metric = entry.getValue();\n                     Object value = metric.getValueAndReset();\n+                    Map<String, String> dimensions = metric.getDimensions();\n                     if (value != null) {\n-                        IMetricsConsumer.DataPoint dataPoint = new IMetricsConsumer.DataPoint(entry.getKey(), value);\n+                        IMetricsConsumer.DataPoint dataPoint = new IMetricsConsumer.DataPoint(name, value, dimensions);\n                         dataPoints.add(dataPoint);\n                     }\n                 }\n             }\n-            addV2Metrics(taskId, dataPoints);\n+            addV2Metrics(taskId, dataPoints, interval);\n \n             if (!dataPoints.isEmpty()) {\n                 IMetricsConsumer.TaskInfo taskInfo = new IMetricsConsumer.TaskInfo(\n@@ -352,11 +361,16 @@ public abstract class Executor implements Callable, JCQueue.Consumer {\n     }\n \n     // updates v1 metric dataPoints with v2 metric API data\n-    private void addV2Metrics(int taskId, List<IMetricsConsumer.DataPoint> dataPoints) {\n-        boolean enableV2MetricsDataPoints = ObjectReader.getBoolean(topoConf.get(Config.TOPOLOGY_ENABLE_V2_METRICS_TICK), false);\n+    private void addV2Metrics(int taskId, List<IMetricsConsumer.DataPoint> dataPoints, int interval) {\n         if (!enableV2MetricsDataPoints) {\n             return;\n         }\n+\n+        // only report v2 metric on the proper metrics tick interval\n+        if (interval != v2MetricsTickInterval) {\n+            return;\n+        }\n+\n         processGauges(taskId, dataPoints);\n         processCounters(taskId, dataPoints);\n         processHistograms(taskId, dataPoints);\n@@ -367,7 +381,13 @@ public abstract class Executor implements Callable, JCQueue.Consumer {\n     private void processGauges(int taskId, List<IMetricsConsumer.DataPoint> dataPoints) {\n         Map<String, Gauge> gauges = workerData.getMetricRegistry().getTaskGauges(taskId);\n         for (Map.Entry<String, Gauge> entry : gauges.entrySet()) {\n-            Object v = entry.getValue().getValue();\n+            Gauge gauge = entry.getValue();\n+            Object v;\n+            if (gauge instanceof PerReporterGauge) {\n+                v = ((PerReporterGauge) gauge).getValueForReporter(this);\n+            } else {\n+                v = gauge.getValue();\n+            }\n             if (v instanceof Number) {\n                 IMetricsConsumer.DataPoint dataPoint = new IMetricsConsumer.DataPoint(entry.getKey(), v);\n                 dataPoints.add(dataPoint);\n@@ -413,27 +433,29 @@ public abstract class Executor implements Callable, JCQueue.Consumer {\n     private void addMeteredDatapoints(String baseName, Metered metered, List<IMetricsConsumer.DataPoint> dataPoints) {\n         IMetricsConsumer.DataPoint dataPoint = new IMetricsConsumer.DataPoint(baseName + \".count\", metered.getCount());\n         dataPoints.add(dataPoint);\n-        addConvertedMetric(baseName, \".m1_rate\", metered.getOneMinuteRate(), dataPoints);\n-        addConvertedMetric(baseName, \".m5_rate\", metered.getFiveMinuteRate(), dataPoints);\n-        addConvertedMetric(baseName, \".m15_rate\", metered.getFifteenMinuteRate(), dataPoints);\n-        addConvertedMetric(baseName, \".mean_rate\", metered.getMeanRate(), dataPoints);\n+        addConvertedMetric(baseName, \".m1_rate\", metered.getOneMinuteRate(), dataPoints, false);\n+        addConvertedMetric(baseName, \".m5_rate\", metered.getFiveMinuteRate(), dataPoints, false);\n+        addConvertedMetric(baseName, \".m15_rate\", metered.getFifteenMinuteRate(), dataPoints, false);\n+        addConvertedMetric(baseName, \".mean_rate\", metered.getMeanRate(), dataPoints, false);\n     }\n \n     private void addSnapshotDatapoints(String baseName, Snapshot snapshot, List<IMetricsConsumer.DataPoint> dataPoints) {\n-        addConvertedMetric(baseName, \".max\", snapshot.getMax(), dataPoints);\n-        addConvertedMetric(baseName, \".mean\", snapshot.getMean(), dataPoints);\n-        addConvertedMetric(baseName, \".min\", snapshot.getMin(), dataPoints);\n-        addConvertedMetric(baseName, \".stddev\", snapshot.getStdDev(), dataPoints);\n-        addConvertedMetric(baseName, \".p50\", snapshot.getMedian(), dataPoints);\n-        addConvertedMetric(baseName, \".p75\", snapshot.get75thPercentile(), dataPoints);\n-        addConvertedMetric(baseName, \".p95\", snapshot.get95thPercentile(), dataPoints);\n-        addConvertedMetric(baseName, \".p98\", snapshot.get98thPercentile(), dataPoints);\n-        addConvertedMetric(baseName, \".p99\", snapshot.get99thPercentile(), dataPoints);\n-        addConvertedMetric(baseName, \".p999\", snapshot.get999thPercentile(), dataPoints);\n-    }\n-\n-    private void addConvertedMetric(String baseName, String suffix, double value, List<IMetricsConsumer.DataPoint> dataPoints) {\n-        IMetricsConsumer.DataPoint dataPoint = new IMetricsConsumer.DataPoint(baseName + suffix, convertDuration(value));\n+        addConvertedMetric(baseName, \".max\", snapshot.getMax(), dataPoints, true);\n+        addConvertedMetric(baseName, \".mean\", snapshot.getMean(), dataPoints, true);\n+        addConvertedMetric(baseName, \".min\", snapshot.getMin(), dataPoints, true);\n+        addConvertedMetric(baseName, \".stddev\", snapshot.getStdDev(), dataPoints, true);\n+        addConvertedMetric(baseName, \".p50\", snapshot.getMedian(), dataPoints, true);\n+        addConvertedMetric(baseName, \".p75\", snapshot.get75thPercentile(), dataPoints, true);\n+        addConvertedMetric(baseName, \".p95\", snapshot.get95thPercentile(), dataPoints, true);\n+        addConvertedMetric(baseName, \".p98\", snapshot.get98thPercentile(), dataPoints, true);\n+        addConvertedMetric(baseName, \".p99\", snapshot.get99thPercentile(), dataPoints, true);\n+        addConvertedMetric(baseName, \".p999\", snapshot.get999thPercentile(), dataPoints, true);\n+    }\n+\n+    private void addConvertedMetric(String baseName, String suffix, double value,\n+                                    List<IMetricsConsumer.DataPoint> dataPoints, boolean needConversion) {\n+        IMetricsConsumer.DataPoint dataPoint\n+            = new IMetricsConsumer.DataPoint(baseName + suffix, needConversion ? convertDuration(value) : value);\n         dataPoints.add(dataPoint);\n     }\n \n@@ -443,25 +465,38 @@ public abstract class Executor implements Callable, JCQueue.Consumer {\n     }\n \n     protected void setupMetrics() {\n+        boolean v2TickScheduled = !enableV2MetricsDataPoints;\n         for (final Integer interval : intervalToTaskToMetricToRegistry.keySet()) {\n-            StormTimer timerTask = workerData.getUserTimer();\n-            timerTask.scheduleRecurring(interval, interval,\n-                () -> {\n-                    TupleImpl tuple =\n+            scheduleMetricsTick(interval);\n+            if (interval == v2MetricsTickInterval) {\n+                v2TickScheduled = true;\n+            }\n+        }\n+\n+        if (!v2TickScheduled) {\n+            LOG.info(\"Scheduling v2 metrics tick for interval {}\", v2MetricsTickInterval);\n+            scheduleMetricsTick(v2MetricsTickInterval);\n+        }\n+    }\n+\n+    private void scheduleMetricsTick(int interval) {\n+        StormTimer timerTask = workerData.getUserTimer();\n+        timerTask.scheduleRecurring(interval, interval,\n+            () -> {\n+                TupleImpl tuple =\n                         new TupleImpl(workerTopologyContext, new Values(interval), Constants.SYSTEM_COMPONENT_ID,\n-                                      (int) Constants.SYSTEM_TASK_ID, Constants.METRICS_TICK_STREAM_ID);\n-                    AddressedTuple metricsTickTuple = new AddressedTuple(AddressedTuple.BROADCAST_DEST, tuple);\n-                    try {\n-                        receiveQueue.publish(metricsTickTuple);\n-                        receiveQueue.flush();  // avoid buffering\n-                    } catch (InterruptedException e) {\n-                        LOG.warn(\"Thread interrupted when publishing metrics. Setting interrupt flag.\");\n-                        Thread.currentThread().interrupt();\n-                        return;\n-                    }\n+                                (int) Constants.SYSTEM_TASK_ID, Constants.METRICS_TICK_STREAM_ID);\n+                AddressedTuple metricsTickTuple = new AddressedTuple(AddressedTuple.BROADCAST_DEST, tuple);\n+                try {\n+                    receiveQueue.publish(metricsTickTuple);\n+                    receiveQueue.flush();  // avoid buffering\n+                } catch (InterruptedException e) {\n+                    LOG.warn(\"Thread interrupted when publishing metrics. Setting interrupt flag.\");\n+                    Thread.currentThread().interrupt();\n+                    return;\n                 }\n-            );\n-        }\n+            }\n+        );\n     }\n \n     protected void setupTicks(boolean isSpout) {\n@@ -636,10 +671,6 @@ public abstract class Executor implements Callable, JCQueue.Consumer {\n         return reportError;\n     }\n \n-    public ErrorReportingMetrics getErrorReportingMetrics() {\n-        return errorReportingMetrics;\n-    }\n-\n     public WorkerTopologyContext getWorkerTopologyContext() {\n         return workerTopologyContext;\n     }\n@@ -680,4 +711,8 @@ public abstract class Executor implements Callable, JCQueue.Consumer {\n     public void setLocalExecutorTransfer(ExecutorTransfer executorTransfer) {\n         this.executorTransfer = executorTransfer;\n     }\n+\n+    public void incrementReportedErrorCount() {\n+        reportedErrorCount.inc(1L);\n+    }\n }\n",
            "security_relevancy": "potentially_security_relevant"
        },
        {
            "diff": "@@ -13,7 +13,6 @@\n package org.apache.storm.command;\n \n import java.util.Map;\n-import org.apache.storm.generated.Nimbus;\n import org.apache.storm.utils.NimbusClient;\n \n public class Monitor {\n@@ -47,11 +46,6 @@ public class Monitor {\n             monitor.setTopology(topologyName);\n         }\n \n-        NimbusClient.withConfiguredClient(new NimbusClient.WithNimbus() {\n-            @Override\n-            public void run(Nimbus.Iface nimbus) throws Exception {\n-                monitor.metrics(nimbus);\n-            }\n-        });\n+        NimbusClient.withConfiguredClient(nimbus -> monitor.metrics(nimbus));\n     }\n }\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -64,12 +64,14 @@ public class Login {\n     private String loginContextName = null;\n     private String principal = null;\n     private long lastLogin = 0;\n+    private String jaasConfFile = null;\n+    private Configuration configuration = null;\n \n     /**\n      * Login constructor. The constructor starts the thread used\n      * to periodically re-login to the Kerberos Ticket Granting Server.\n      * @param loginContextName\n-     *               name of section in JAAS file that will be use to login.\n+     *               name of section in JAAS file that will be used to login.\n      *               Passed as first param to javax.security.auth.login.LoginContext().\n      *\n      * @param callbackHandler\n@@ -79,12 +81,16 @@ public class Login {\n      */\n     public Login(final String loginContextName, CallbackHandler callbackHandler, String jaasConfFile)\n         throws LoginException {\n-        this.callbackHandler = callbackHandler;\n-        login = login(loginContextName, jaasConfFile);\n         this.loginContextName = loginContextName;\n-        subject = login.getSubject();\n-        isKrbTicket = !subject.getPrivateCredentials(KerberosTicket.class).isEmpty();\n-        AppConfigurationEntry[] entries = this.getConfiguration(jaasConfFile).getAppConfigurationEntry(loginContextName);\n+        this.callbackHandler = callbackHandler;\n+        this.jaasConfFile = jaasConfFile;\n+        this.configuration = getConfiguration(jaasConfFile);\n+\n+        this.login = login();\n+        this.subject = login.getSubject();\n+        this.isKrbTicket = !subject.getPrivateCredentials(KerberosTicket.class).isEmpty();\n+\n+        AppConfigurationEntry[] entries = configuration.getAppConfigurationEntry(loginContextName);\n         for (AppConfigurationEntry entry : entries) {\n             // there will only be a single entry, so this for() loop will only be iterated through once.\n             if (entry.getOptions().get(\"useTicketCache\") != null) {\n@@ -108,7 +114,7 @@ public class Login {\n         // TGT's existing expiry date and the configured MIN_TIME_BEFORE_RELOGIN. For testing and development,\n         // you can decrease the interval of expiration of tickets (for example, to 3 minutes) by running :\n         //  \"modprinc -maxlife 3mins <principal>\" in kadmin.\n-        thread = new Thread(new Runnable() {\n+        this.thread = new Thread(new Runnable() {\n             @Override\n             public void run() {\n                 LOG.info(\"TGT refresh thread started.\");\n@@ -247,7 +253,7 @@ public class Login {\n         thread.setDaemon(true);\n     }\n \n-    private Configuration getConfiguration(String jaasConfFile) {\n+    private static Configuration getConfiguration(String jaasConfFile) {\n         File configFile = new File(jaasConfFile);\n         if (!configFile.canRead()) {\n             throw new RuntimeException(\"File \" + jaasConfFile + \" cannot be read.\");\n@@ -286,7 +292,7 @@ public class Login {\n         return loginContextName;\n     }\n \n-    private synchronized LoginContext login(final String loginContextName, String jaasConfFile) throws LoginException {\n+    private synchronized LoginContext login() throws LoginException {\n         if (loginContextName == null) {\n             throw new LoginException(\"loginContext name (JAAS file section header) was null. \"\n                     + \"Please check your java.security.login.auth.config (=\"\n@@ -294,9 +300,9 @@ public class Login {\n                     + \") and your \" + ZooKeeperSaslClient.LOGIN_CONTEXT_NAME_KEY + \"(=\"\n                     + System.getProperty(ZooKeeperSaslClient.LOGIN_CONTEXT_NAME_KEY, \"Client\") + \")\");\n         }\n-        Configuration configuration = this.getConfiguration(jaasConfFile);\n         LoginContext loginContext;\n         try {\n+            // The subject is null for our initial login attempt.\n             loginContext = new LoginContext(loginContextName, null, callbackHandler, configuration);\n             loginContext.login();\n         } catch (LoginException e) {\n@@ -384,7 +390,7 @@ public class Login {\n     }\n \n     /**\n-     * Re-login a principal. This method assumes that {@link #login(String)} has happened already.\n+     * Re-login a principal. This method assumes that {@link #login()} has happened already.\n      * @throws javax.security.auth.login.LoginException on a failure\n      */\n     // c.f. HADOOP-6559\n@@ -404,11 +410,13 @@ public class Login {\n             //the Java kerberos login module code, only the kerberos credentials\n             //are cleared\n             login.logout();\n-            //login and also update the subject field of this instance to\n-            //have the new credentials (pass it to the LoginContext constructor)\n-            login = new LoginContext(loginContextName, getSubject());\n+            //login with original callback handler and config, and also update the\n+            //subject field of this instance to have the new credentials (pass it\n+            //to the LoginContext constructor)\n+            login = new LoginContext(loginContextName, getSubject(), callbackHandler, configuration);\n             LOG.info(\"Initiating re-login for \" + principal);\n             login.login();\n+            LOG.info(\"Successfully re-logged in to context \" + loginContextName + \" using \" + jaasConfFile);\n             setLogin(login);\n         }\n     }\n",
            "security_relevancy": "security_relevant"
        },
        {
            "diff": "@@ -1,150 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version\n- * 2.0 (the \"License\"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the License for the specific language governing permissions\n- * and limitations under the License.\n- */\n-\n-package org.apache.storm.cassandra.trident.state;\n-\n-import com.datastax.driver.core.BatchStatement;\n-import com.datastax.driver.core.Session;\n-import com.datastax.driver.core.Statement;\n-import com.google.common.base.Preconditions;\n-import java.io.Serializable;\n-import java.util.ArrayList;\n-import java.util.List;\n-import java.util.Map;\n-import org.apache.storm.cassandra.client.SimpleClient;\n-import org.apache.storm.cassandra.client.SimpleClientProvider;\n-import org.apache.storm.cassandra.query.CQLResultSetValuesMapper;\n-import org.apache.storm.cassandra.query.CQLStatementTupleMapper;\n-import org.apache.storm.topology.FailedException;\n-import org.apache.storm.trident.operation.TridentCollector;\n-import org.apache.storm.trident.state.State;\n-import org.apache.storm.trident.tuple.TridentTuple;\n-import org.apache.storm.tuple.Values;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-public class CassandraState implements State {\n-\n-    private static final Logger LOG = LoggerFactory.getLogger(CassandraState.class);\n-\n-    private final Map<String, Object> conf;\n-    private final Options options;\n-\n-    private Session session;\n-    private SimpleClient client;\n-\n-    protected CassandraState(Map<String, Object> conf, Options options) {\n-        this.conf = conf;\n-        this.options = options;\n-    }\n-\n-    @Override\n-    public void beginCommit(Long txid) {\n-        LOG.debug(\"beginCommit is no operation\");\n-    }\n-\n-    @Override\n-    public void commit(Long txid) {\n-        LOG.debug(\"commit is no operation\");\n-    }\n-\n-    public void prepare() {\n-        Preconditions.checkNotNull(options.cqlStatementTupleMapper, \"CassandraState.Options should have cqlStatementTupleMapper\");\n-\n-        client = options.clientProvider.getClient(conf);\n-        session = client.connect();\n-    }\n-\n-    public void cleanup() {\n-        try {\n-            session.close();\n-        } catch (Exception e) {\n-            LOG.warn(\"Error occurred while closing Session\", e);\n-        } finally {\n-            client.close();\n-        }\n-    }\n-\n-    public void updateState(List<TridentTuple> tuples, final TridentCollector collector) {\n-\n-        List<Statement> statements = new ArrayList<>();\n-        for (TridentTuple tuple : tuples) {\n-            statements.addAll(options.cqlStatementTupleMapper.map(conf, session, tuple));\n-        }\n-\n-        try {\n-            if (options.batchingType != null) {\n-                BatchStatement batchStatement = new BatchStatement(options.batchingType);\n-                batchStatement.addAll(statements);\n-                session.execute(batchStatement);\n-            } else {\n-                for (Statement statement : statements) {\n-                    session.execute(statement);\n-                }\n-            }\n-        } catch (Exception e) {\n-            LOG.warn(\"Batch write operation is failed.\");\n-            collector.reportError(e);\n-            throw new FailedException(e);\n-        }\n-\n-    }\n-\n-    public List<List<Values>> batchRetrieve(List<TridentTuple> tridentTuples) {\n-        Preconditions.checkNotNull(options.cqlResultSetValuesMapper, \"CassandraState.Options should have cqlResultSetValuesMapper\");\n-\n-        List<List<Values>> batchRetrieveResult = new ArrayList<>();\n-        try {\n-            for (TridentTuple tridentTuple : tridentTuples) {\n-                List<Statement> statements = options.cqlStatementTupleMapper.map(conf, session, tridentTuple);\n-                for (Statement statement : statements) {\n-                    List<List<Values>> values = options.cqlResultSetValuesMapper.map(session, statement, tridentTuple);\n-                    batchRetrieveResult.addAll(values);\n-                }\n-            }\n-        } catch (Exception e) {\n-            LOG.warn(\"Batch retrieve operation is failed\", e);\n-            throw new FailedException(e);\n-        }\n-        return batchRetrieveResult;\n-    }\n-\n-    public static final class Options implements Serializable {\n-        private final SimpleClientProvider clientProvider;\n-        private CQLStatementTupleMapper cqlStatementTupleMapper;\n-        private CQLResultSetValuesMapper cqlResultSetValuesMapper;\n-        private BatchStatement.Type batchingType;\n-\n-        public Options(SimpleClientProvider clientProvider) {\n-            this.clientProvider = clientProvider;\n-        }\n-\n-        @SuppressWarnings(\"checkstyle:AbbreviationAsWordInName\")\n-        public Options withCQLStatementTupleMapper(CQLStatementTupleMapper cqlStatementTupleMapper) {\n-            this.cqlStatementTupleMapper = cqlStatementTupleMapper;\n-            return this;\n-        }\n-\n-        @SuppressWarnings(\"checkstyle:AbbreviationAsWordInName\")\n-        public Options withCQLResultSetValuesMapper(CQLResultSetValuesMapper cqlResultSetValuesMapper) {\n-            this.cqlResultSetValuesMapper = cqlResultSetValuesMapper;\n-            return this;\n-        }\n-\n-        public Options withBatching(BatchStatement.Type batchingType) {\n-            this.batchingType = batchingType;\n-            return this;\n-        }\n-\n-    }\n-\n-}\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -65,16 +65,19 @@ class Server extends ConnectionWithStatus implements IStatefulObject, ISaslServe\n     private final IConnectionCallback cb;\n     private final Supplier<Object> newConnectionResponse;\n     private volatile boolean closing = false;\n+    private final boolean isNettyAuthRequired;\n \n     /**\n      * Starts Netty at the given port.\n      * @param topoConf The topology config\n      * @param port The port to start Netty at\n      * @param cb The callback to deliver incoming messages to\n-     * @param newConnectionResponse The response to send to clients when they connect. Can be null.\n+     * @param newConnectionResponse The response to send to clients when they connect. Can be null. If authentication\n+     *                              is required, the message will be sent after authentication is complete.\n      */\n     Server(Map<String, Object> topoConf, int port, IConnectionCallback cb, Supplier<Object> newConnectionResponse) {\n         this.topoConf = topoConf;\n+        this.isNettyAuthRequired = (Boolean) topoConf.get(Config.STORM_MESSAGING_NETTY_AUTHENTICATION);\n         this.port = port;\n         ser = new KryoValuesSerializer(topoConf);\n         this.cb = cb;\n@@ -252,8 +255,9 @@ class Server extends ConnectionWithStatus implements IStatefulObject, ISaslServe\n      **/\n     @Override\n     public void channelActive(Channel c) {\n-        if (newConnectionResponse != null) {\n-            c.writeAndFlush(newConnectionResponse.get(), c.voidPromise());\n+        if (!isNettyAuthRequired) {\n+            //if authentication is not required, treat it as authenticated.\n+            authenticated(c);\n         }\n         allChannels.add(c);\n     }\n@@ -285,6 +289,14 @@ class Server extends ConnectionWithStatus implements IStatefulObject, ISaslServe\n \n     @Override\n     public void authenticated(Channel c) {\n+        if (isNettyAuthRequired) {\n+            LOG.debug(\"The channel {} is active and authenticated\", c);\n+        } else {\n+            LOG.debug(\"The channel {} is active\", c);\n+        }\n+        if (newConnectionResponse != null) {\n+            c.writeAndFlush(newConnectionResponse.get(), c.voidPromise());\n+        }\n     }\n \n     @Override\n",
            "security_relevancy": "security_relevant"
        },
        {
            "diff": "@@ -1,80 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version\n- * 2.0 (the \"License\"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at\n- * <p/>\n- * http://www.apache.org/licenses/LICENSE-2.0\n- * <p/>\n- * Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the License for the specific language governing permissions\n- * and limitations under the License.\n- */\n-\n-package org.apache.storm.starter.trident;\n-\n-import java.util.HashMap;\n-import org.apache.storm.Config;\n-import org.apache.storm.StormSubmitter;\n-import org.apache.storm.generated.StormTopology;\n-import org.apache.storm.hbase.trident.windowing.HBaseWindowsStoreFactory;\n-import org.apache.storm.trident.Stream;\n-import org.apache.storm.trident.TridentTopology;\n-import org.apache.storm.trident.operation.Consumer;\n-import org.apache.storm.trident.testing.CountAsAggregator;\n-import org.apache.storm.trident.testing.FixedBatchSpout;\n-import org.apache.storm.trident.testing.Split;\n-import org.apache.storm.trident.tuple.TridentTuple;\n-import org.apache.storm.trident.windowing.WindowsStoreFactory;\n-import org.apache.storm.trident.windowing.config.TumblingCountWindow;\n-import org.apache.storm.tuple.Fields;\n-import org.apache.storm.tuple.Values;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-/**\n- * Sample application of trident windowing which uses {@link HBaseWindowsStoreFactory}'s store for storing tuples in window.\n- *\n- */\n-public class TridentHBaseWindowingStoreTopology {\n-    private static final Logger LOG = LoggerFactory.getLogger(TridentHBaseWindowingStoreTopology.class);\n-\n-    public static StormTopology buildTopology(WindowsStoreFactory windowsStore) throws Exception {\n-        FixedBatchSpout spout = new FixedBatchSpout(new Fields(\"sentence\"), 3, new Values(\"the cow jumped over the moon\"),\n-                                                    new Values(\"the man went to the store and bought some candy\"),\n-                                                    new Values(\"four score and seven years ago\"),\n-                                                    new Values(\"how many apples can you eat\"), new Values(\"to be or not to be the person\"));\n-        spout.setCycle(true);\n-\n-        TridentTopology topology = new TridentTopology();\n-\n-        Stream stream = topology.newStream(\"spout1\", spout).parallelismHint(16).each(new Fields(\"sentence\"),\n-                                                                                     new Split(), new Fields(\"word\"))\n-                                .window(TumblingCountWindow.of(1000), windowsStore, new Fields(\"word\"), new CountAsAggregator(),\n-                                        new Fields(\"count\"))\n-                                .peek(new Consumer() {\n-                                    @Override\n-                                    public void accept(TridentTuple input) {\n-                                        LOG.info(\"Received tuple: [{}]\", input);\n-                                    }\n-                                });\n-\n-        return topology.build();\n-    }\n-\n-    public static void main(String[] args) throws Exception {\n-        Config conf = new Config();\n-        conf.setMaxSpoutPending(20);\n-        conf.put(Config.TOPOLOGY_TRIDENT_WINDOWING_INMEMORY_CACHE_LIMIT, 100);\n-\n-        // window-state table should already be created with cf:tuples column\n-        HBaseWindowsStoreFactory windowStoreFactory =\n-            new HBaseWindowsStoreFactory(new HashMap<String, Object>(), \"window-state\", \"cf\".getBytes(\"UTF-8\"), \"tuples\".getBytes(\"UTF-8\"));\n-        String topoName = \"wordCounterWithWindowing\";\n-        if (args.length > 0) {\n-            topoName = args[0];\n-        }\n-        conf.setNumWorkers(3);\n-        StormSubmitter.submitTopologyWithProgressBar(topoName, conf, buildTopology(windowStoreFactory));\n-    }\n-\n-}\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -24,7 +24,6 @@ import java.util.concurrent.ConcurrentHashMap;\n import javax.security.auth.Subject;\n import javax.security.auth.callback.CallbackHandler;\n import javax.security.auth.kerberos.KerberosTicket;\n-import javax.security.auth.login.Configuration;\n import javax.security.auth.login.LoginException;\n import javax.security.sasl.Sasl;\n import org.apache.storm.generated.WorkerToken;\n@@ -138,7 +137,7 @@ public class KerberosSaslTransportPlugin extends SaslTransportPlugin {\n         return kerberosConnect(transport, serverHost, asUser);\n     }\n \n-    private TTransport kerberosConnect(TTransport transport, String serverHost, String asUser) throws IOException {\n+    private TTransport kerberosConnect(TTransport transport, String serverHost, String asUser) throws IOException, TTransportException {\n         //login our user\n         SortedMap<String, ?> authConf = ClientAuthUtils.pullConfig(conf, ClientAuthUtils.LOGIN_CONTEXT_CLIENT);\n         if (authConf == null) {\n",
            "security_relevancy": "potentially_security_relevant"
        },
        {
            "diff": "@@ -1,79 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version\n- * 2.0 (the \"License\"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions\n- * and limitations under the License.\n- */\n-\n-package org.apache.storm.hbase.topology;\n-\n-import java.util.HashMap;\n-import java.util.Map;\n-import org.apache.storm.Config;\n-import org.apache.storm.StormSubmitter;\n-import org.apache.storm.hbase.bolt.HBaseBolt;\n-import org.apache.storm.hbase.bolt.mapper.SimpleHBaseMapper;\n-import org.apache.storm.hbase.security.HBaseSecurityUtil;\n-import org.apache.storm.topology.TopologyBuilder;\n-import org.apache.storm.tuple.Fields;\n-\n-\n-public class PersistentWordCount {\n-    private static final String WORD_SPOUT = \"WORD_SPOUT\";\n-    private static final String COUNT_BOLT = \"COUNT_BOLT\";\n-    private static final String HBASE_BOLT = \"HBASE_BOLT\";\n-\n-\n-    public static void main(String[] args) throws Exception {\n-        Config config = new Config();\n-\n-        Map<String, Object> hbConf = new HashMap<>();\n-        if (args.length > 0) {\n-            hbConf.put(\"hbase.rootdir\", args[0]);\n-        }\n-        config.put(\"hbase.conf\", hbConf);\n-\n-        WordSpout spout = new WordSpout();\n-        WordCounter bolt = new WordCounter();\n-\n-        SimpleHBaseMapper mapper = new SimpleHBaseMapper()\n-            .withRowKeyField(\"word\")\n-            .withColumnFields(new Fields(\"word\"))\n-            .withCounterFields(new Fields(\"count\"))\n-            .withColumnFamily(\"cf\");\n-\n-        HBaseBolt hbase = new HBaseBolt(\"WordCount\", mapper)\n-            .withConfigKey(\"hbase.conf\");\n-\n-\n-        // wordSpout ==> countBolt ==> HBaseBolt\n-        TopologyBuilder builder = new TopologyBuilder();\n-\n-        builder.setSpout(WORD_SPOUT, spout, 1);\n-        builder.setBolt(COUNT_BOLT, bolt, 1).shuffleGrouping(WORD_SPOUT);\n-        builder.setBolt(HBASE_BOLT, hbase, 1).fieldsGrouping(COUNT_BOLT, new Fields(\"word\"));\n-\n-        String topoName = \"test\";\n-        if (args.length == 2) {\n-            topoName = args[0];\n-        } else if (args.length == 4) {\n-            System.out.println(\"hdfs url: \" + args[0]\n-                    + \", keytab file: \" + args[2]\n-                    + \", principal name: \" + args[3]\n-                    + \", toplogy name: \" + args[1]);\n-            hbConf.put(HBaseSecurityUtil.STORM_KEYTAB_FILE_KEY, args[2]);\n-            hbConf.put(HBaseSecurityUtil.STORM_USER_NAME_KEY, args[3]);\n-            config.setNumWorkers(3);\n-            topoName = args[1];\n-        } else if (args.length != 1) {\n-            System.out.println(\"Usage: PersistentWordCount <hbase.rootdir> [topology name] [keytab file] [principal name]\");\n-            return;\n-        }\n-        StormSubmitter.submitTopology(topoName, config, builder.createTopology());\n-    }\n-}\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -22,6 +22,7 @@ import org.apache.storm.Config;\n import org.apache.storm.messaging.IConnection;\n import org.apache.storm.messaging.IConnectionCallback;\n import org.apache.storm.messaging.IContext;\n+import org.apache.storm.metrics2.StormMetricRegistry;\n import org.apache.storm.shade.io.netty.channel.EventLoopGroup;\n import org.apache.storm.shade.io.netty.channel.nio.NioEventLoopGroup;\n import org.apache.storm.shade.io.netty.util.HashedWheelTimer;\n@@ -32,12 +33,18 @@ public class Context implements IContext {\n     private List<Server> serverConnections;\n     private EventLoopGroup workerEventLoopGroup;\n     private HashedWheelTimer clientScheduleService;\n+    private StormMetricRegistry metricRegistry = null;\n \n     /**\n      * initialization per Storm configuration.\n      */\n     @Override\n     public void prepare(Map<String, Object> topoConf) {\n+        prepare(topoConf, null);\n+    }\n+\n+    @Override\n+    public void prepare(Map<String, Object> topoConf, StormMetricRegistry metricRegistry) {\n         this.topoConf = topoConf;\n         serverConnections = new ArrayList<>();\n \n@@ -49,6 +56,7 @@ public class Context implements IContext {\n         this.workerEventLoopGroup = new NioEventLoopGroup(maxWorkers > 0 ? maxWorkers : 0, workerFactory);\n \n         clientScheduleService = new HashedWheelTimer(new NettyRenameThreadFactory(\"client-schedule-service\"));\n+        this.metricRegistry = metricRegistry;\n     }\n \n     /**\n@@ -67,7 +75,7 @@ public class Context implements IContext {\n     @Override\n     public IConnection connect(String stormId, String host, int port, AtomicBoolean[] remoteBpStatus) {\n         return new Client(topoConf, remoteBpStatus, workerEventLoopGroup,\n-                                        clientScheduleService, host, port);\n+                                        clientScheduleService, host, port, metricRegistry);\n     }\n \n     /**\n",
            "security_relevancy": "potentially_security_relevant"
        },
        {
            "diff": "@@ -1,30 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.storm.solr.util;\n-\n-import java.text.DateFormat;\n-import java.text.SimpleDateFormat;\n-import java.util.Date;\n-\n-public class TestUtil {\n-    public static String getDate() {\n-        DateFormat df = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss'Z'\");\n-        return df.format(new Date());\n-    }\n-}\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -1,43 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.storm.rocketmq.trident.state;\n-\n-import java.util.Map;\n-\n-import org.apache.storm.task.IMetricsContext;\n-import org.apache.storm.trident.state.State;\n-import org.apache.storm.trident.state.StateFactory;\n-\n-public class RocketMqStateFactory implements StateFactory {\n-\n-    private RocketMqState.Options options;\n-\n-    public RocketMqStateFactory(RocketMqState.Options options) {\n-        this.options = options;\n-    }\n-\n-    @Override\n-    public State makeState(Map<String, Object> conf, IMetricsContext metrics,\n-            int partitionIndex, int numPartitions) {\n-        RocketMqState state = new RocketMqState(conf, options);\n-        state.prepare();\n-        return state;\n-    }\n-\n-}\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -1,35 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.storm.mongodb.trident.state;\n-\n-import java.util.List;\n-\n-import org.apache.storm.trident.operation.TridentCollector;\n-import org.apache.storm.trident.state.BaseStateUpdater;\n-import org.apache.storm.trident.tuple.TridentTuple;\n-\n-public class MongoStateUpdater extends BaseStateUpdater<MongoState>  {\n-\n-    @Override\n-    public void updateState(MongoState state, List<TridentTuple> tuples,\n-            TridentCollector collector) {\n-        state.updateState(tuples, collector);\n-    }\n-\n-}\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -1,82 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version\n- * 2.0 (the \"License\"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions\n- * and limitations under the License.\n- */\n-\n-package org.apache.storm.hbase.bolt;\n-\n-import java.io.IOException;\n-import java.util.Collections;\n-import java.util.HashMap;\n-import java.util.Map;\n-import org.apache.commons.lang.Validate;\n-import org.apache.hadoop.conf.Configuration;\n-import org.apache.hadoop.hbase.HBaseConfiguration;\n-import org.apache.storm.Config;\n-import org.apache.storm.hbase.bolt.mapper.HBaseMapper;\n-import org.apache.storm.hbase.common.HBaseClient;\n-import org.apache.storm.task.OutputCollector;\n-import org.apache.storm.task.TopologyContext;\n-import org.apache.storm.topology.base.BaseRichBolt;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-// TODO support more configuration options, for now we're defaulting to the hbase-*.xml files found on the classpath\n-public abstract class AbstractHBaseBolt extends BaseRichBolt {\n-    private static final Logger LOG = LoggerFactory.getLogger(AbstractHBaseBolt.class);\n-\n-    protected transient OutputCollector collector;\n-    @SuppressWarnings(\"checkstyle:MemberName\")\n-    protected transient HBaseClient hBaseClient;\n-    protected String tableName;\n-    protected HBaseMapper mapper;\n-    protected String configKey;\n-\n-    public AbstractHBaseBolt(String tableName, HBaseMapper mapper) {\n-        Validate.notEmpty(tableName, \"Table name can not be blank or null\");\n-        Validate.notNull(mapper, \"mapper can not be null\");\n-        this.tableName = tableName;\n-        this.mapper = mapper;\n-    }\n-\n-    @Override\n-    public void prepare(Map<String, Object> topoConf, TopologyContext topologyContext, OutputCollector collector) {\n-        this.collector = collector;\n-        final Configuration hbConfig = HBaseConfiguration.create();\n-\n-        Map<String, Object> conf = (Map<String, Object>) topoConf.get(this.configKey);\n-        if (conf == null) {\n-            LOG.warn(\"HBase configuration not found using key '\" + this.configKey + \"'\");\n-            conf = Collections.emptyMap();\n-        }\n-\n-        if (conf.get(\"hbase.rootdir\") == null) {\n-            LOG.warn(\"No 'hbase.rootdir' value found in configuration! Using HBase defaults.\");\n-        }\n-        for (String key : conf.keySet()) {\n-            hbConfig.set(key, String.valueOf(conf.get(key)));\n-        }\n-\n-        //heck for backward compatibility, we need to pass TOPOLOGY_AUTO_CREDENTIALS to hbase conf\n-        //the conf instance is instance of persistentMap so making a copy.\n-        Map<String, Object> hbaseConfMap = new HashMap<>(conf);\n-        hbaseConfMap.put(Config.TOPOLOGY_AUTO_CREDENTIALS, topoConf.get(Config.TOPOLOGY_AUTO_CREDENTIALS));\n-        this.hBaseClient = new HBaseClient(hbaseConfMap, hbConfig, tableName);\n-    }\n-\n-    @Override\n-    public void cleanup() {\n-        try {\n-            hBaseClient.close();\n-        } catch (IOException e) {\n-            LOG.error(\"HBase Client Close Failed \", e);\n-        }\n-    }\n-}\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -19,8 +19,8 @@ import java.util.Map;\n import org.apache.storm.Config;\n import org.apache.storm.generated.AuthorizationException;\n import org.apache.storm.generated.DistributedRPCInvocations;\n-import org.apache.storm.shade.org.json.simple.JSONValue;\n-import org.apache.storm.shade.org.json.simple.parser.ParseException;\n+import org.apache.storm.shade.net.minidev.json.JSONValue;\n+import org.apache.storm.shade.net.minidev.json.parser.ParseException;\n import org.apache.storm.task.OutputCollector;\n import org.apache.storm.task.TopologyContext;\n import org.apache.storm.thrift.TException;\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -20,14 +20,14 @@ import java.util.Map;\n \n import org.apache.storm.Config;\n import org.apache.storm.cluster.DaemonType;\n+import org.apache.storm.shade.net.minidev.json.JSONValue;\n+import org.apache.storm.shade.net.minidev.json.parser.ParseException;\n import org.apache.storm.shade.org.apache.curator.framework.CuratorFramework;\n import org.apache.storm.shade.org.apache.curator.framework.api.PathAndBytesable;\n import org.apache.storm.shade.org.apache.curator.framework.api.ProtectACLCreateModePathAndBytesable;\n import org.apache.storm.shade.org.apache.zookeeper.CreateMode;\n import org.apache.storm.shade.org.apache.zookeeper.KeeperException;\n import org.apache.storm.shade.org.apache.zookeeper.data.ACL;\n-import org.apache.storm.shade.org.json.simple.JSONValue;\n-import org.apache.storm.shade.org.json.simple.parser.ParseException;\n import org.apache.storm.utils.CuratorUtils;\n import org.apache.storm.utils.Utils;\n import org.apache.storm.utils.ZookeeperAuthInfo;\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -20,6 +20,7 @@ package org.apache.storm.utils;\n \n import java.util.ArrayList;\n import java.util.Arrays;\n+import java.util.Collections;\n import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n@@ -37,33 +38,32 @@ import org.apache.storm.testing.TestWordSpout;\n import org.apache.storm.thrift.transport.TTransportException;\n import org.apache.storm.topology.BoltDeclarer;\n import org.apache.storm.topology.TopologyBuilder;\n-import org.junit.Assert;\n-import org.junit.Test;\n+import org.junit.jupiter.api.Test;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n-import static org.junit.Assert.*;\n+import static org.junit.jupiter.api.Assertions.*;\n \n public class UtilsTest {\n     public static final Logger LOG = LoggerFactory.getLogger(UtilsTest.class);\n \n     @Test\n     public void isZkAuthenticationConfiguredTopologyTest() {\n-        Assert.assertFalse(\n-            \"Returns null if given null config\",\n-            Utils.isZkAuthenticationConfiguredTopology(null));\n+        assertFalse(\n+            Utils.isZkAuthenticationConfiguredTopology(null),\n+            \"Returns null if given null config\");\n \n-        Assert.assertFalse(\n-            \"Returns false if scheme key is missing\",\n-            Utils.isZkAuthenticationConfiguredTopology(emptyMockMap()));\n+        assertFalse(\n+            Utils.isZkAuthenticationConfiguredTopology(emptyMockMap()),\n+            \"Returns false if scheme key is missing\");\n \n-        Assert.assertFalse(\n-            \"Returns false if scheme value is null\",\n-            Utils.isZkAuthenticationConfiguredTopology(topologyMockMap(null)));\n+        assertFalse(\n+            Utils.isZkAuthenticationConfiguredTopology(topologyMockMap(null)),\n+            \"Returns false if scheme value is null\");\n \n-        Assert.assertTrue(\n-            \"Returns true if scheme value is string\",\n-            Utils.isZkAuthenticationConfiguredTopology(topologyMockMap(\"foobar\")));\n+        assertTrue(\n+            Utils.isZkAuthenticationConfiguredTopology(topologyMockMap(\"foobar\")),\n+            \"Returns true if scheme value is string\");\n     }\n \n     private Map<String, Object> topologyMockMap(String value) {\n@@ -85,11 +85,11 @@ public class UtilsTest {\n     }\n \n     private void doParseJvmHeapMemByChildOptsTest(String message, String opt, double expected) {\n-        doParseJvmHeapMemByChildOptsTest(message, Arrays.asList(opt), expected);\n+        doParseJvmHeapMemByChildOptsTest(message, Collections.singletonList(opt), expected);\n     }\n \n     private void doParseJvmHeapMemByChildOptsTest(String message, List<String> opts, double expected) {\n-        Assert.assertEquals(message, Utils.parseJvmHeapMemByChildOpts(opts, 123.0), expected, 0);\n+        assertEquals(expected, Utils.parseJvmHeapMemByChildOpts(opts, 123.0), 0, message);\n     }\n \n     @Test\n@@ -104,6 +104,7 @@ public class UtilsTest {\n         doParseJvmHeapMemByChildOptsTest(\"Xmx100M results in 100 MB\", \"Xmx100m\", 100.0);\n         doParseJvmHeapMemByChildOptsTest(\"Xmx100m results in 100 MB\", \"Xmx100M\", 100.0);\n         doParseJvmHeapMemByChildOptsTest(\"-Xmx100M results in 100 MB\", \"-Xmx100m\", 100.0);\n+        doParseJvmHeapMemByChildOptsTest(\"-Xmx2048M results in 2048 MB\", \"-Xmx2048m\", 2048.0);\n     }\n \n     @Test\n@@ -111,6 +112,7 @@ public class UtilsTest {\n         doParseJvmHeapMemByChildOptsTest(\"Xmx1g results in 1024 MB\", \"Xmx1g\", 1024.0);\n         doParseJvmHeapMemByChildOptsTest(\"Xmx1G results in 1024 MB\", \"Xmx1G\", 1024.0);\n         doParseJvmHeapMemByChildOptsTest(\"-Xmx1g results in 1024 MB\", \"-Xmx1g\", 1024.0);\n+        doParseJvmHeapMemByChildOptsTest(\"-Xmx2g results in 2048 MB\", \"-Xmx2g\", 2048.0);\n     }\n \n     @Test\n@@ -142,33 +144,27 @@ public class UtilsTest {\n         Map<String, Object> config = ConfigUtils.readStormConfig();\n         config.put(Config.STORM_NIMBUS_RETRY_TIMES, 0);\n \n-        try {\n-            new NimbusClient(config, \"\", 65535);\n-            Assert.fail(\"Expected exception to be thrown\");\n-        } catch (RuntimeException e) {\n-            Assert.assertTrue(\n-                \"Cause is not TTransportException \" + e,\n-                Utils.exceptionCauseIsInstanceOf(TTransportException.class, e));\n-        }\n+        Exception e = assertThrows(RuntimeException.class, () -> new NimbusClient(config, \"\", 65535));\n+        assertEquals(TTransportException.class, e.getCause(), \"Cause is not TTransportException \" + e);\n     }\n \n     @Test\n     public void isZkAuthenticationConfiguredStormServerTest() {\n-        Assert.assertFalse(\n-            \"Returns false if given null config\",\n-            Utils.isZkAuthenticationConfiguredStormServer(null));\n+        assertFalse(\n+            Utils.isZkAuthenticationConfiguredStormServer(null),\n+            \"Returns false if given null config\");\n \n-        Assert.assertFalse(\n-            \"Returns false if scheme key is missing\",\n-            Utils.isZkAuthenticationConfiguredStormServer(emptyMockMap()));\n+        assertFalse(\n+            Utils.isZkAuthenticationConfiguredStormServer(emptyMockMap()),\n+            \"Returns false if scheme key is missing\");\n \n-        Assert.assertFalse(\n-            \"Returns false if scheme value is null\",\n-            Utils.isZkAuthenticationConfiguredStormServer(serverMockMap(null)));\n+        assertFalse(\n+            Utils.isZkAuthenticationConfiguredStormServer(serverMockMap(null)),\n+            \"Returns false if scheme value is null\");\n \n-        Assert.assertTrue(\n-            \"Returns true if scheme value is string\",\n-            Utils.isZkAuthenticationConfiguredStormServer(serverMockMap(\"foobar\")));\n+        assertTrue(\n+            Utils.isZkAuthenticationConfiguredStormServer(serverMockMap(\"foobar\")),\n+            \"Returns true if scheme value is string\");\n     }\n \n     @Test\n@@ -177,7 +173,7 @@ public class UtilsTest {\n         String oldValue = System.getProperty(key);\n         try {\n             System.setProperty(\"java.security.auth.login.config\", \"anything\");\n-            Assert.assertTrue(Utils.isZkAuthenticationConfiguredStormServer(emptyMockMap()));\n+            assertTrue(Utils.isZkAuthenticationConfiguredStormServer(emptyMockMap()));\n         } finally {\n             // reset property\n             if (oldValue == null) {\n@@ -191,14 +187,14 @@ public class UtilsTest {\n     @Test\n     public void testIsValidConfEmpty() {\n         Map<String, Object> map0 = ImmutableMap.of();\n-        Assert.assertTrue(Utils.isValidConf(map0, map0));\n+        assertTrue(Utils.isValidConf(map0, map0));\n     }\n \n     @Test\n     public void testIsValidConfIdentical() {\n         Map<String, Object> map1 = ImmutableMap.of(\"k0\", ImmutableList.of(1L, 2L), \"k1\", ImmutableSet.of('s', 'f'),\n                                                    \"k2\", \"as\");\n-        Assert.assertTrue(Utils.isValidConf(map1, map1));\n+        assertTrue(Utils.isValidConf(map1, map1));\n     }\n \n     @Test\n@@ -207,7 +203,7 @@ public class UtilsTest {\n                                                    \"k2\", \"as\");\n         Map<String, Object> map2 = ImmutableMap.of(\"k0\", ImmutableList.of(1L, 2L), \"k1\", ImmutableSet.of('s', 'f'),\n                                                    \"k2\", \"as\");\n-        Assert.assertTrue(Utils.isValidConf(map1, map2)); // test deep equal\n+        assertTrue(Utils.isValidConf(map1, map2)); // test deep equal\n     }\n \n     @Test\n@@ -216,21 +212,21 @@ public class UtilsTest {\n                                                    \"k2\", \"as\");\n         Map<String, Object> map3 = ImmutableMap.of(\"k0\", ImmutableList.of(1L, 2L), \"k1\", ImmutableSet.of('s', 't'),\n                                                    \"k2\", \"as\");\n-        Assert.assertFalse(Utils.isValidConf(map1, map3));\n+        assertFalse(Utils.isValidConf(map1, map3));\n     }\n \n     @Test\n     public void testIsValidConfPrimitiveNotEqual() {\n         Map<String, Object> map4 = ImmutableMap.of(\"k0\", 2L);\n         Map<String, Object> map5 = ImmutableMap.of(\"k0\", 3L);\n-        Assert.assertFalse(Utils.isValidConf(map4, map5));\n+        assertFalse(Utils.isValidConf(map4, map5));\n     }\n \n     @Test\n     public void testIsValidConfEmptyNotEqual() {\n         Map<String, Object> map0 = ImmutableMap.of();\n         Map<String, Object> map5 = ImmutableMap.of(\"k0\", 3L);\n-        Assert.assertFalse(Utils.isValidConf(map0, map5));\n+        assertFalse(Utils.isValidConf(map0, map5));\n     }\n \n     @Test\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -1,139 +0,0 @@\n-/*******************************************************************************\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- *******************************************************************************/\n-\n-package org.apache.storm.eventhubs.bolt;\n-\n-import com.microsoft.azure.eventhubs.EventData;\n-import com.microsoft.azure.eventhubs.EventHubClient;\n-import com.microsoft.azure.eventhubs.PartitionSender;\n-import com.microsoft.azure.servicebus.ServiceBusException;\n-import java.util.Map;\n-import java.util.concurrent.ExecutionException;\n-import org.apache.storm.eventhubs.spout.EventHubException;\n-import org.apache.storm.task.OutputCollector;\n-import org.apache.storm.task.TopologyContext;\n-import org.apache.storm.topology.OutputFieldsDeclarer;\n-import org.apache.storm.topology.base.BaseRichBolt;\n-import org.apache.storm.tuple.Tuple;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-/**\n- * A bolt that writes event message to EventHub.\n- */\n-public class EventHubBolt extends BaseRichBolt {\n-    private static final long serialVersionUID = 1L;\n-    private static final Logger logger = LoggerFactory\n-        .getLogger(EventHubBolt.class);\n-\n-    protected OutputCollector collector;\n-    protected PartitionSender sender;\n-    protected EventHubClient ehClient;\n-    protected EventHubBoltConfig boltConfig;\n-\n-    public EventHubBolt(String connectionString, String entityPath) {\n-        boltConfig = new EventHubBoltConfig(connectionString, entityPath);\n-    }\n-\n-    public EventHubBolt(String userName, String password, String namespace,\n-                        String entityPath, boolean partitionMode) {\n-        boltConfig = new EventHubBoltConfig(userName, password, namespace,\n-                                            entityPath, partitionMode);\n-    }\n-\n-    public EventHubBolt(EventHubBoltConfig config) {\n-        boltConfig = config;\n-    }\n-\n-    @Override\n-    public void prepare(Map<String, Object> config, TopologyContext context,\n-                        OutputCollector collector) {\n-        this.collector = collector;\n-        String myPartitionId = null;\n-        if (boltConfig.getPartitionMode()) {\n-            // We can use the task index (starting from 0) as the partition ID\n-            myPartitionId = \"\" + context.getThisTaskIndex();\n-        }\n-        logger.info(\"creating sender: \" + boltConfig.getConnectionString()\n-                    + \", \" + boltConfig.getEntityPath() + \", \" + myPartitionId);\n-        try {\n-            ehClient = EventHubClient.createFromConnectionStringSync(boltConfig.getConnectionString());\n-            if (boltConfig.getPartitionMode()) {\n-                sender = ehClient.createPartitionSenderSync(Integer.toString(context.getThisTaskIndex()));\n-            }\n-        } catch (Exception ex) {\n-            collector.reportError(ex);\n-            throw new RuntimeException(ex);\n-        }\n-\n-    }\n-\n-    @Override\n-    public void execute(Tuple tuple) {\n-        try {\n-            EventData sendEvent = new EventData(boltConfig.getEventDataFormat().serialize(tuple));\n-            if (boltConfig.getPartitionMode() && sender != null) {\n-                sender.sendSync(sendEvent);\n-            } else if (boltConfig.getPartitionMode() && sender == null) {\n-                throw new EventHubException(\"Sender is null\");\n-            } else if (!boltConfig.getPartitionMode() && ehClient != null) {\n-                ehClient.sendSync(sendEvent);\n-            } else if (!boltConfig.getPartitionMode() && ehClient == null) {\n-                throw new EventHubException(\"ehclient is null\");\n-            }\n-            collector.ack(tuple);\n-        } catch (EventHubException ex) {\n-            collector.reportError(ex);\n-            collector.fail(tuple);\n-        } catch (ServiceBusException e) {\n-            collector.reportError(e);\n-            collector.fail(tuple);\n-        }\n-    }\n-\n-    @Override\n-    public void cleanup() {\n-        if (sender != null) {\n-            try {\n-                sender.close().whenComplete((voidargs, error) -> {\n-                    try {\n-                        if (error != null) {\n-                            logger.error(\"Exception during sender cleanup phase\" + error.toString());\n-                        }\n-                        ehClient.closeSync();\n-                    } catch (Exception e) {\n-                        logger.error(\"Exception during ehclient cleanup phase\" + e.toString());\n-                    }\n-                }).get();\n-            } catch (InterruptedException e) {\n-                logger.error(\"Exception occured during cleanup phase\" + e.toString());\n-            } catch (ExecutionException e) {\n-                logger.error(\"Exception occured during cleanup phase\" + e.toString());\n-            }\n-            logger.info(\"Eventhub Bolt cleaned up\");\n-            sender = null;\n-            ehClient = null;\n-        }\n-    }\n-\n-    @Override\n-    public void declareOutputFields(OutputFieldsDeclarer declarer) {\n-\n-    }\n-\n-}\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -13,12 +13,13 @@\n package org.apache.storm.hive.common;\n \n import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+\n+import java.io.File;\n import java.io.IOException;\n import java.util.Arrays;\n import java.util.HashMap;\n import java.util.concurrent.ExecutorService;\n import java.util.concurrent.Executors;\n-import junit.framework.Assert;\n import org.apache.hadoop.hive.conf.HiveConf;\n import org.apache.hadoop.hive.metastore.txn.TxnDbUtil;\n import org.apache.hadoop.security.UserGroupInformation;\n@@ -38,11 +39,11 @@ import org.apache.storm.tuple.Fields;\n import org.apache.storm.tuple.Tuple;\n import org.apache.storm.tuple.TupleImpl;\n import org.apache.storm.tuple.Values;\n-import org.junit.Rule;\n-import org.junit.Test;\n-import org.junit.rules.TemporaryFolder;\n+import org.junit.jupiter.api.Test;\n import org.mockito.Mockito;\n \n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+\n public class TestHiveWriter {\n     public static final String PART1_NAME = \"city\";\n     public static final String PART2_NAME = \"state\";\n@@ -54,8 +55,6 @@ public class TestHiveWriter {\n     private final int port;\n     private final String metaStoreURI;\n     private final HiveConf conf;\n-    @Rule\n-    public TemporaryFolder dbFolder = new TemporaryFolder();\n     int timeout = 10000; // msec\n     UserGroupInformation ugi = null;\n     private ExecutorService callTimeoutPool;\n@@ -113,11 +112,11 @@ public class TestHiveWriter {\n         writer.write(mapper.mapRecord(tuple));\n         tuple = generateTestTuple(\"2\", \"def\");\n         writer.write(mapper.mapRecord(tuple));\n-        Assert.assertEquals(writer.getTotalRecords(), 2);\n+        assertEquals(writer.getTotalRecords(), 2);\n         Mockito.verify(writer.getMockedTxBatch(), Mockito.times(2)).write(Mockito.any(byte[].class));\n         Mockito.verify(writer.getMockedTxBatch(), Mockito.never()).commit();\n         writer.flush(true);\n-        Assert.assertEquals(writer.getTotalRecords(), 0);\n+        assertEquals(writer.getTotalRecords(), 0);\n         Mockito.verify(writer.getMockedTxBatch(), Mockito.atLeastOnce()).commit();\n \n         tuple = generateTestTuple(\"3\", \"ghi\");\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -26,10 +26,9 @@ import org.apache.storm.sql.runtime.DataSourcesRegistry;\n import org.apache.storm.sql.runtime.FieldInfo;\n import org.apache.storm.sql.runtime.ISqlStreamsDataSource;\n import org.apache.storm.topology.IRichBolt;\n-import org.junit.After;\n-import org.junit.Assert;\n-import org.junit.Before;\n-import org.junit.Test;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n \n import java.io.File;\n import java.io.IOException;\n@@ -37,6 +36,9 @@ import java.net.URI;\n import java.util.List;\n import java.util.Properties;\n \n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+\n public class TestHdfsDataSourcesProvider {\n \n     private static final List<FieldInfo> FIELDS = ImmutableList.of(\n@@ -53,7 +55,7 @@ public class TestHdfsDataSourcesProvider {\n         TBL_PROPERTIES.put(\"hdfs.rotation.time.seconds\", \"120\");\n     }\n \n-    @Before\n+    @BeforeEach\n     public void setup() throws Exception {\n         Configuration conf = new Configuration();\n         conf.set(\"fs.trash.interval\", \"10\");\n@@ -67,7 +69,7 @@ public class TestHdfsDataSourcesProvider {\n         hdfsURI = \"hdfs://localhost:\" + hdfsCluster.getNameNodePort() + \"/\";\n     }\n \n-    @After\n+    @AfterEach\n     public void shutDown() throws IOException {\n         hdfsCluster.shutdown();\n     }\n@@ -77,10 +79,10 @@ public class TestHdfsDataSourcesProvider {\n     public void testHdfsSink() throws Exception {\n         ISqlStreamsDataSource ds = DataSourcesRegistry.constructStreamsDataSource(\n             URI.create(hdfsURI), null, null, TBL_PROPERTIES, FIELDS);\n-        Assert.assertNotNull(ds);\n+        assertNotNull(ds);\n \n         IRichBolt consumer = ds.getConsumer();\n \n-        Assert.assertEquals(HdfsBolt.class, consumer.getClass());\n+        assertEquals(HdfsBolt.class, consumer.getClass());\n     }\n }\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -15,6 +15,7 @@ package org.apache.storm.hdfs.bolt;\n import java.io.File;\n import java.io.IOException;\n import java.util.HashMap;\n+\n import org.apache.hadoop.conf.Configuration;\n import org.apache.hadoop.fs.FileStatus;\n import org.apache.hadoop.fs.FileSystem;\n@@ -33,7 +34,7 @@ import org.apache.storm.hdfs.bolt.rotation.FileSizeRotationPolicy;\n import org.apache.storm.hdfs.bolt.sync.CountSyncPolicy;\n import org.apache.storm.hdfs.bolt.sync.SyncPolicy;\n import org.apache.storm.hdfs.common.Partitioner;\n-import org.apache.storm.hdfs.testing.MiniDFSClusterRule;\n+import org.apache.storm.hdfs.testing.MiniDFSClusterExtension;\n import org.apache.storm.task.GeneralTopologyContext;\n import org.apache.storm.task.OutputCollector;\n import org.apache.storm.task.TopologyContext;\n@@ -43,26 +44,24 @@ import org.apache.storm.tuple.Tuple;\n import org.apache.storm.tuple.TupleImpl;\n import org.apache.storm.tuple.Values;\n import org.apache.storm.utils.MockTupleHelpers;\n-import org.junit.After;\n-import org.junit.Assert;\n-import org.junit.Before;\n-import org.junit.Rule;\n-import org.junit.Test;\n-import org.junit.rules.ExpectedException;\n-import org.junit.runner.RunWith;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.extension.RegisterExtension;\n import org.mockito.Mock;\n-import org.mockito.runners.MockitoJUnitRunner;\n+import org.mockito.junit.jupiter.MockitoExtension;\n \n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n import static org.mockito.Mockito.verify;\n-import static org.mockito.Mockito.verifyZeroInteractions;\n+import static org.mockito.Mockito.verifyNoInteractions;\n \n \n-@RunWith(MockitoJUnitRunner.class)\n+@ExtendWith(MockitoExtension.class)\n public class TestHdfsBolt {\n-\n-    private static final String testRoot = \"/unittest\";\n-    @Rule\n-    public MiniDFSClusterRule dfsClusterRule = new MiniDFSClusterRule(() -> {\n+    @RegisterExtension\n+    public static final MiniDFSClusterExtension DFS_CLUSTER_EXTENSION = new MiniDFSClusterExtension(() -> {\n         Configuration conf = new Configuration();\n         conf.set(\"fs.trash.interval\", \"10\");\n         conf.setBoolean(\"dfs.permissions\", true);\n@@ -71,8 +70,7 @@ public class TestHdfsBolt {\n         conf.set(MiniDFSCluster.HDFS_MINIDFS_BASEDIR, baseDir.getAbsolutePath());\n         return conf;\n     });\n-    @Rule\n-    public ExpectedException thrown = ExpectedException.none();\n+    private static final String testRoot = \"/unittest\";\n     Tuple tuple1 = generateTestTuple(1, \"First Tuple\", \"SFO\", \"CA\");\n     Tuple tuple2 = generateTestTuple(1, \"Second Tuple\", \"SJO\", \"CA\");\n     private String hdfsURI;\n@@ -82,13 +80,13 @@ public class TestHdfsBolt {\n     @Mock\n     private TopologyContext topologyContext;\n \n-    @Before\n+    @BeforeEach\n     public void setup() throws Exception {\n-        fs = dfsClusterRule.getDfscluster().getFileSystem();\n-        hdfsURI = \"hdfs://localhost:\" + dfsClusterRule.getDfscluster().getNameNodePort() + \"/\";\n+        fs = DFS_CLUSTER_EXTENSION.getDfscluster().getFileSystem();\n+        hdfsURI = \"hdfs://localhost:\" + DFS_CLUSTER_EXTENSION.getDfscluster().getNameNodePort() + \"/\";\n     }\n \n-    @After\n+    @AfterEach\n     public void shutDown() throws IOException {\n         fs.close();\n     }\n@@ -104,7 +102,7 @@ public class TestHdfsBolt {\n         verify(collector).ack(tuple1);\n         verify(collector).ack(tuple2);\n \n-        Assert.assertEquals(2, countNonZeroLengthFiles(testRoot));\n+        assertEquals(2, countNonZeroLengthFiles(testRoot));\n     }\n \n     @Test\n@@ -127,8 +125,8 @@ public class TestHdfsBolt {\n         verify(collector).ack(tuple1);\n         verify(collector).ack(tuple2);\n \n-        Assert.assertEquals(1, countNonZeroLengthFiles(testRoot + \"/SFO\"));\n-        Assert.assertEquals(1, countNonZeroLengthFiles(testRoot + \"/SJO\"));\n+        assertEquals(1, countNonZeroLengthFiles(testRoot + \"/SFO\"));\n+        assertEquals(1, countNonZeroLengthFiles(testRoot + \"/SJO\"));\n     }\n \n     @Test\n@@ -137,13 +135,13 @@ public class TestHdfsBolt {\n         bolt.prepare(new Config(), topologyContext, collector);\n         bolt.execute(tuple1);\n \n-        verifyZeroInteractions(collector);\n+        verifyNoInteractions(collector);\n \n         bolt.execute(tuple2);\n         verify(collector).ack(tuple1);\n         verify(collector).ack(tuple2);\n \n-        Assert.assertEquals(1, countNonZeroLengthFiles(testRoot));\n+        assertEquals(1, countNonZeroLengthFiles(testRoot));\n     }\n \n     @Test\n@@ -155,8 +153,7 @@ public class TestHdfsBolt {\n         fs.setSafeMode(SafeModeAction.SAFEMODE_ENTER);\n \n         // All writes/syncs will fail so this should cause a RuntimeException\n-        thrown.expect(RuntimeException.class);\n-        bolt.execute(tuple1);\n+        assertThrows(RuntimeException.class, () -> bolt.execute(tuple1));\n \n     }\n \n@@ -185,8 +182,8 @@ public class TestHdfsBolt {\n             //\n         }\n \n-        Assert.assertEquals(1, countNonZeroLengthFiles(testRoot));\n-        Assert.assertEquals(0, countZeroLengthFiles(testRoot));\n+        assertEquals(1, countNonZeroLengthFiles(testRoot));\n+        assertEquals(0, countZeroLengthFiles(testRoot));\n     }\n \n     @Test\n@@ -197,12 +194,12 @@ public class TestHdfsBolt {\n         bolt.execute(tuple1);\n \n         //Should not have flushed to file system yet\n-        Assert.assertEquals(0, countNonZeroLengthFiles(testRoot));\n+        assertEquals(0, countNonZeroLengthFiles(testRoot));\n \n         bolt.execute(MockTupleHelpers.mockTickTuple());\n \n         //Tick should have flushed it\n-        Assert.assertEquals(1, countNonZeroLengthFiles(testRoot));\n+        assertEquals(1, countNonZeroLengthFiles(testRoot));\n     }\n     \n     @Test\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -24,11 +24,11 @@ import org.apache.storm.utils.MockTupleHelpers;\n import org.testng.annotations.Test;\n \n import static org.fest.assertions.api.Assertions.assertThat;\n-import static org.mockito.Matchers.any;\n+import static org.mockito.ArgumentMatchers.any;\n import static org.mockito.Mockito.mock;\n import static org.mockito.Mockito.times;\n import static org.mockito.Mockito.verify;\n-import static org.mockito.Mockito.verifyZeroInteractions;\n+import static org.mockito.Mockito.verifyNoInteractions;\n import static org.mockito.Mockito.when;\n \n public class RollingCountBoltTest {\n@@ -57,7 +57,7 @@ public class RollingCountBoltTest {\n         bolt.execute(tickTuple);\n \n         // then\n-        verifyZeroInteractions(collector);\n+        verifyNoInteractions(collector);\n     }\n \n     @SuppressWarnings(\"rawtypes\")\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -1,264 +0,0 @@\n-/*******************************************************************************\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- *******************************************************************************/\n-\n-package org.apache.storm.eventhubs.spout;\n-\n-import com.microsoft.azure.eventhubs.EventHubClient;\n-import com.microsoft.azure.servicebus.ConnectionStringBuilder;\n-import java.io.Serializable;\n-import java.util.ArrayList;\n-import java.util.List;\n-\n-public class EventHubSpoutConfig implements Serializable {\n-    public static final String EH_SERVICE_FQDN_SUFFIX = \"servicebus.windows.net\";\n-    private static final long serialVersionUID = 1L;\n-    private final String userName;\n-    private final String password;\n-    private final String namespace;\n-    private final String entityPath;\n-    private final int partitionCount;\n-\n-    private String zkConnectionString = null; // if null then use zookeeper used\n-    // by Storm\n-    private int checkpointIntervalInSeconds = 10;\n-    private int receiverCredits = 1024;\n-    private int maxPendingMsgsPerPartition = 1024;\n-    private long enqueueTimeFilter = 0; // timestamp in millisecond, 0 means\n-    // disabling filter\n-    private String connectionString;\n-    private String topologyName;\n-    private int receiverTimeoutInMillis = 1000; // default\n-    private IEventDataScheme scheme = new StringEventDataScheme();\n-    private String consumerGroupName = EventHubClient.DEFAULT_CONSUMER_GROUP_NAME;\n-    private String outputStreamId;\n-\n-\n-    // These are mandatory parameters\n-    public EventHubSpoutConfig(String username, String password,\n-                               String namespace, String entityPath, int partitionCount) {\n-        this.userName = username;\n-        this.password = password;\n-        this.connectionString = new ConnectionStringBuilder(namespace, entityPath,\n-                                                            username, password).toString();\n-        this.namespace = namespace;\n-        this.entityPath = entityPath;\n-        this.partitionCount = partitionCount;\n-    }\n-\n-    // Keep this constructor for backward compatibility\n-    public EventHubSpoutConfig(String username, String password,\n-                               String namespace, String entityPath, int partitionCount,\n-                               String zkConnectionString) {\n-        this(username, password, namespace, entityPath, partitionCount);\n-        setZkConnectionString(zkConnectionString);\n-    }\n-\n-    // Keep this constructor for backward compatibility\n-    public EventHubSpoutConfig(String username, String password,\n-                               String namespace, String entityPath, int partitionCount,\n-                               String zkConnectionString, int checkpointIntervalInSeconds,\n-                               int receiverCredits) {\n-        this(username, password, namespace, entityPath, partitionCount,\n-             zkConnectionString);\n-        setCheckpointIntervalInSeconds(checkpointIntervalInSeconds);\n-        setReceiverCredits(receiverCredits);\n-    }\n-\n-    public EventHubSpoutConfig(String username, String password,\n-                               String namespace, String entityPath, int partitionCount,\n-                               String zkConnectionString, int checkpointIntervalInSeconds,\n-                               int receiverCredits, long enqueueTimeFilter) {\n-        this(username, password, namespace, entityPath, partitionCount,\n-             zkConnectionString, checkpointIntervalInSeconds,\n-             receiverCredits);\n-        setEnqueueTimeFilter(enqueueTimeFilter);\n-    }\n-\n-    // Keep this constructor for backward compatibility\n-    public EventHubSpoutConfig(String username, String password,\n-                               String namespace, String entityPath, int partitionCount,\n-                               String zkConnectionString, int checkpointIntervalInSeconds,\n-                               int receiverCredits, int maxPendingMsgsPerPartition,\n-                               long enqueueTimeFilter) {\n-\n-        this(username, password, namespace, entityPath, partitionCount,\n-             zkConnectionString, checkpointIntervalInSeconds,\n-             receiverCredits);\n-        setMaxPendingMsgsPerPartition(maxPendingMsgsPerPartition);\n-        setEnqueueTimeFilter(enqueueTimeFilter);\n-    }\n-\n-    public String getNamespace() {\n-        return namespace;\n-    }\n-\n-    public String getEntityPath() {\n-        return entityPath;\n-    }\n-\n-    public int getPartitionCount() {\n-        return partitionCount;\n-    }\n-\n-    public String getZkConnectionString() {\n-        return zkConnectionString;\n-    }\n-\n-    public void setZkConnectionString(String value) {\n-        zkConnectionString = value;\n-    }\n-\n-    public EventHubSpoutConfig withZkConnectionString(String value) {\n-        setZkConnectionString(value);\n-        return this;\n-    }\n-\n-    public int getCheckpointIntervalInSeconds() {\n-        return checkpointIntervalInSeconds;\n-    }\n-\n-    public void setCheckpointIntervalInSeconds(int value) {\n-        checkpointIntervalInSeconds = value;\n-    }\n-\n-    public EventHubSpoutConfig withCheckpointIntervalInSeconds(int value) {\n-        setCheckpointIntervalInSeconds(value);\n-        return this;\n-    }\n-\n-    public int getReceiverCredits() {\n-        return receiverCredits;\n-    }\n-\n-    public void setReceiverCredits(int value) {\n-        receiverCredits = value;\n-    }\n-\n-    public EventHubSpoutConfig withReceiverCredits(int value) {\n-        setReceiverCredits(value);\n-        return this;\n-    }\n-\n-    public int getMaxPendingMsgsPerPartition() {\n-        return maxPendingMsgsPerPartition;\n-    }\n-\n-    public void setMaxPendingMsgsPerPartition(int value) {\n-        maxPendingMsgsPerPartition = value;\n-    }\n-\n-    public EventHubSpoutConfig withMaxPendingMsgsPerPartition(int value) {\n-        setMaxPendingMsgsPerPartition(value);\n-        return this;\n-    }\n-\n-    public long getEnqueueTimeFilter() {\n-        return enqueueTimeFilter;\n-    }\n-\n-    public void setEnqueueTimeFilter(long value) {\n-        enqueueTimeFilter = value;\n-    }\n-\n-    public EventHubSpoutConfig withEnqueueTimeFilter(long value) {\n-        setEnqueueTimeFilter(value);\n-        return this;\n-    }\n-\n-    public String getTopologyName() {\n-        return topologyName;\n-    }\n-\n-    public void setTopologyName(String value) {\n-        topologyName = value;\n-    }\n-\n-    public EventHubSpoutConfig withTopologyName(String value) {\n-        setTopologyName(value);\n-        return this;\n-    }\n-\n-    public IEventDataScheme getEventDataScheme() {\n-        return scheme;\n-    }\n-\n-    public void setEventDataScheme(IEventDataScheme scheme) {\n-        this.scheme = scheme;\n-    }\n-\n-    public EventHubSpoutConfig withEventDataScheme(IEventDataScheme value) {\n-        setEventDataScheme(value);\n-        return this;\n-    }\n-\n-    public String getConsumerGroupName() {\n-        return consumerGroupName;\n-    }\n-\n-    public void setConsumerGroupName(String value) {\n-        consumerGroupName = value;\n-    }\n-\n-    public EventHubSpoutConfig withConsumerGroupName(String value) {\n-        setConsumerGroupName(value);\n-        return this;\n-    }\n-\n-    public List<String> getPartitionList() {\n-        List<String> partitionList = new ArrayList<String>();\n-\n-        for (int i = 0; i < this.partitionCount; i++) {\n-            partitionList.add(Integer.toString(i));\n-        }\n-\n-        return partitionList;\n-    }\n-\n-    public String getConnectionString() {\n-        return connectionString;\n-    }\n-\n-    /*Keeping it for backward compatibility*/\n-    public void setTargetAddress(String targetFqnAddress) {\n-    }\n-\n-    public void setTargetAddress() {\n-\n-    }\n-\n-    public EventHubSpoutConfig withTargetAddress(String targetFqnAddress) {\n-        setTargetAddress(targetFqnAddress);\n-        return this;\n-    }\n-\n-    public String getOutputStreamId() {\n-        return outputStreamId;\n-    }\n-\n-    public void setOutputStreamId(String outputStreamId) {\n-        this.outputStreamId = outputStreamId;\n-    }\n-\n-    public int getReceiverTimeoutInMillis() {\n-        return receiverTimeoutInMillis;\n-    }\n-\n-    public void setReceiverTimeoutInMillis(int receiverTimeoutInMillis) {\n-        this.receiverTimeoutInMillis = receiverTimeoutInMillis;\n-    }\n-}\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -18,10 +18,10 @@\n \n package org.apache.storm;\n \n-import java.lang.reflect.InvocationTargetException;\n import java.util.ArrayList;\n import java.util.Arrays;\n import java.util.Collection;\n+import java.util.Collections;\n import java.util.HashMap;\n import java.util.LinkedList;\n import java.util.List;\n@@ -62,22 +62,19 @@ import org.apache.storm.validation.ConfigValidationAnnotations.IsNoDuplicateInLi\n import org.apache.storm.validation.ConfigValidationAnnotations.IsString;\n import org.apache.storm.validation.ConfigValidationAnnotations.NotNull;\n \n-import org.junit.Assert;\n-import org.junit.Test;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n+import org.junit.jupiter.api.Test;\n \n+import static org.junit.jupiter.api.Assertions.assertFalse;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n import static org.mockito.Mockito.mock;\n import static org.mockito.Mockito.when;\n \n public class TestConfigValidate {\n \n-    private static final Logger LOG = LoggerFactory.getLogger(TestConfigValidate.class);\n-\n     @Test\n-    public void validPacemakerAuthTest() throws InstantiationException, IllegalAccessException, NoSuchFieldException, NoSuchMethodException,\n-        InvocationTargetException {\n-        Map<String, Object> conf = new HashMap<String, Object>();\n+    public void validPacemakerAuthTest() {\n+        Map<String, Object> conf = new HashMap<>();\n         conf.put(Config.PACEMAKER_AUTH_METHOD, \"NONE\");\n         ConfigValidation.validateFields(conf);\n         conf.put(Config.PACEMAKER_AUTH_METHOD, \"DIGEST\");\n@@ -86,20 +83,16 @@ public class TestConfigValidate {\n         ConfigValidation.validateFields(conf);\n     }\n \n-    @Test(expected = IllegalArgumentException.class)\n-    public void invalidPacemakerAuthTest() throws InstantiationException, IllegalAccessException, NoSuchFieldException,\n-        NoSuchMethodException, InvocationTargetException {\n-        Map<String, Object> conf = new HashMap<String, Object>();\n+    @Test\n+    public void invalidPacemakerAuthTest() {\n+        Map<String, Object> conf = new HashMap<>();\n         conf.put(Config.PACEMAKER_AUTH_METHOD, \"invalid\");\n-        ConfigValidation.validateFields(conf);\n+        assertThrows(IllegalArgumentException.class, () -> ConfigValidation.validateFields(conf));\n     }\n \n     @Test\n-    public void validConfigTest() throws InstantiationException, IllegalAccessException, NoSuchFieldException, NoSuchMethodException,\n-        InvocationTargetException {\n-\n-\n-        Map<String, Object> conf = new HashMap<String, Object>();\n+    public void validConfigTest() {\n+        Map<String, Object> conf = new HashMap<>();\n         conf.put(Config.STORM_MESSAGING_NETTY_SOCKET_BACKLOG, 5);\n         conf.put(Config.STORM_MESSAGING_NETTY_MIN_SLEEP_MS, 500);\n         conf.put(Config.STORM_MESSAGING_NETTY_AUTHENTICATION, true);\n@@ -107,24 +100,22 @@ public class TestConfigValidate {\n         ConfigValidation.validateFields(conf);\n     }\n \n-    @Test(expected = IllegalArgumentException.class)\n-    public void invalidConfigTest() throws InvocationTargetException, NoSuchMethodException, NoSuchFieldException, InstantiationException,\n-        IllegalAccessException {\n-        Map<String, Object> conf = new HashMap<String, Object>();\n+    @Test\n+    public void invalidConfigTest() {\n+        Map<String, Object> conf = new HashMap<>();\n         conf.put(Config.STORM_MESSAGING_NETTY_SOCKET_BACKLOG, 5);\n         conf.put(Config.STORM_MESSAGING_NETTY_MIN_SLEEP_MS, 500);\n         conf.put(Config.STORM_MESSAGING_NETTY_AUTHENTICATION, \"invalid\");\n \n-        ConfigValidation.validateFields(conf);\n+        assertThrows(IllegalArgumentException.class, () -> ConfigValidation.validateFields(conf));\n     }\n \n-    @Test(expected = InvalidTopologyException.class)\n-    public void testValidateTopologyBlobStoreMapWithBlobStore() throws InvalidTopologyException, AuthorizationException,\n-        KeyNotFoundException {\n+    @Test\n+    public void testValidateTopologyBlobStoreMapWithBlobStore() throws Throwable {\n         Map<String, Object> topoConf = new HashMap<>();\n-        Map<String, Map> topologyMap = new HashMap<>();\n-        topologyMap.put(\"key1\", new HashMap<String, String>());\n-        topologyMap.put(\"key2\", new HashMap<String, String>());\n+        Map<String, Map<String, String>> topologyMap = new HashMap<>();\n+        topologyMap.put(\"key1\", new HashMap<>());\n+        topologyMap.put(\"key2\", new HashMap<>());\n         topoConf.put(Config.TOPOLOGY_BLOBSTORE_MAP, topologyMap);\n         Subject subject = ReqContext.context().subject();\n \n@@ -132,51 +123,79 @@ public class TestConfigValidate {\n         when(blobStoreMock.getBlobMeta(\"key1\", subject)).thenReturn(null);\n         when(blobStoreMock.getBlobMeta(\"key2\", subject)).thenThrow(new KeyNotFoundException());\n \n-        Utils.validateTopologyBlobStoreMap(topoConf, blobStoreMock);\n+        assertThrows(InvalidTopologyException.class,\n+            () -> Utils.validateTopologyBlobStoreMap(topoConf, blobStoreMock));\n     }\n \n-    @Test(expected = InvalidTopologyException.class)\n-    public void testValidateTopologyBlobStoreMapWithNimbusBlobStore() throws InvalidTopologyException, AuthorizationException,\n-        KeyNotFoundException {\n+    @Test\n+    public void testValidateTopologyBlobStoreMissingKey() throws Throwable {\n         Map<String, Object> topoConf = new HashMap<>();\n-        Map<String, Map> topologyMap = new HashMap<>();\n-        topologyMap.put(\"key1\", new HashMap<String, String>());\n-        topologyMap.put(\"key2\", new HashMap<String, String>());\n+        Map<String, Map<String, String>> topologyMap = new HashMap<>();\n+        topologyMap.put(\"key1\", new HashMap<>());\n+        topologyMap.put(\"key2\", new HashMap<>());\n         topoConf.put(Config.TOPOLOGY_BLOBSTORE_MAP, topologyMap);\n \n         NimbusBlobStore nimbusBlobStoreMock = mock(NimbusBlobStore.class);\n         when(nimbusBlobStoreMock.getBlobMeta(\"key1\")).thenReturn(null);\n         when(nimbusBlobStoreMock.getBlobMeta(\"key2\")).thenThrow(new KeyNotFoundException());\n \n+        assertThrows(InvalidTopologyException.class,\n+            () -> Utils.validateTopologyBlobStoreMap(topoConf, nimbusBlobStoreMock));\n+    }\n+\n+    @Test\n+    public void testValidateTopologyBlobStoreMap() throws InvalidTopologyException, AuthorizationException,\n+            KeyNotFoundException {\n+        Map<String, Object> topoConf = new HashMap<>();\n+        Map<String, Map<String, Object>> topologyMap = new HashMap<>();\n+        Map<String, Object> blobConf = new HashMap<>();\n+        blobConf.put(\"uncompress\", false);\n+        topologyMap.put(\"key1\", blobConf);\n+        topologyMap.put(\"key2\", blobConf);\n+        topoConf.put(Config.TOPOLOGY_BLOBSTORE_MAP, topologyMap);\n+\n+        NimbusBlobStore nimbusBlobStoreMock = mock(NimbusBlobStore.class);\n+        when(nimbusBlobStoreMock.getBlobMeta(\"key1\")).thenReturn(null);\n+        when(nimbusBlobStoreMock.getBlobMeta(\"key2\")).thenReturn(null);\n+\n         Utils.validateTopologyBlobStoreMap(topoConf, nimbusBlobStoreMock);\n     }\n \n     @Test\n-    public void defaultYamlTest() throws InvocationTargetException, NoSuchMethodException, NoSuchFieldException, InstantiationException,\n-        IllegalAccessException {\n+    public void testValidateTopologyBlobStoreMapInvalidOption() {\n+        Map<String, Object> topoConf = new HashMap<>();\n+        Map<String, Map<String, Object>> topologyMap = new HashMap<>();\n+        Map<String, Object> blobConf = new HashMap<>();\n+        blobConf.put(\"uncompress\", \"false\");\n+        topologyMap.put(\"key1\", blobConf);\n+        topologyMap.put(\"key2\", blobConf);\n+        topoConf.put(Config.TOPOLOGY_BLOBSTORE_MAP, topologyMap);\n+\n+        NimbusBlobStore nimbusBlobStoreMock = mock(NimbusBlobStore.class);\n+\n+        assertThrows(InvalidTopologyException.class,\n+            () -> Utils.validateTopologyBlobStoreMap(topoConf, nimbusBlobStoreMock));\n+    }\n+\n+    @Test\n+    public void defaultYamlTest() {\n         Map<String, Object> conf = Utils.readStormConfig();\n         ConfigValidation.validateFields(conf);\n     }\n \n     @Test\n-    public void testTopologyWorkersIsInteger() throws InvocationTargetException, NoSuchMethodException, NoSuchFieldException,\n-        InstantiationException, IllegalAccessException {\n-        Map<String, Object> conf = new HashMap<String, Object>();\n+    public void testTopologyWorkersIsInteger() {\n+        Map<String, Object> conf = new HashMap<>();\n         conf.put(Config.TOPOLOGY_WORKERS, 42);\n         ConfigValidation.validateFields(conf);\n \n         conf.put(Config.TOPOLOGY_WORKERS, 3.14159);\n-        try {\n-            ConfigValidation.validateFields(conf);\n-            Assert.fail(\"Expected Exception not Thrown\");\n-        } catch (IllegalArgumentException ex) {\n-        }\n+        assertThrows(IllegalArgumentException.class, () -> ConfigValidation.validateFields(conf));\n     }\n \n     @Test\n-    public void testTopologyStatsSampleRateIsFloat() throws InvocationTargetException, NoSuchMethodException, NoSuchFieldException,\n-        InstantiationException, IllegalAccessException {\n-        Map<String, Object> conf = new HashMap<String, Object>();\n+    public void testTopologyStatsSampleRateIsFloat() {\n+        Map<String, Object> conf = new HashMap<>();\n         conf.put(Config.TOPOLOGY_STATS_SAMPLE_RATE, 0.5);\n         ConfigValidation.validateFields(conf);\n         conf.put(Config.TOPOLOGY_STATS_SAMPLE_RATE, 10);\n@@ -186,11 +205,10 @@ public class TestConfigValidate {\n     }\n \n     @Test\n-    public void testWorkerChildoptsIsStringOrStringList() throws InvocationTargetException, NoSuchMethodException, NoSuchFieldException,\n-        InstantiationException, IllegalAccessException {\n-        Map<String, Object> conf = new HashMap<String, Object>();\n-        Collection<Object> passCases = new LinkedList<Object>();\n-        Collection<Object> failCases = new LinkedList<Object>();\n+    public void testWorkerChildoptsIsStringOrStringList() {\n+        Map<String, Object> conf = new HashMap<>();\n+        Collection<Object> passCases = new LinkedList<>();\n+        Collection<Object> failCases = new LinkedList<>();\n \n         passCases.add(null);\n         passCases.add(\"some string\");\n@@ -208,62 +226,54 @@ public class TestConfigValidate {\n         }\n \n         for (Object value : failCases) {\n-            try {\n-                conf.put(Config.WORKER_CHILDOPTS, value);\n-                ConfigValidation.validateFields(conf);\n-                Assert.fail(\"Expected Exception not Thrown for value: \" + value);\n-            } catch (IllegalArgumentException Ex) {\n-            }\n+            conf.put(Config.WORKER_CHILDOPTS, value);\n+            assertThrows(IllegalArgumentException.class, () -> ConfigValidation.validateFields(conf));\n         }\n \n         //topology.worker.childopts validates\n-        conf = new HashMap<String, Object>();\n+        conf.clear();\n         for (Object value : passCases) {\n             conf.put(Config.TOPOLOGY_WORKER_CHILDOPTS, value);\n             ConfigValidation.validateFields(conf);\n         }\n \n         for (Object value : failCases) {\n-            try {\n-                conf.put(Config.TOPOLOGY_WORKER_CHILDOPTS, value);\n-                ConfigValidation.validateFields(conf);\n-                Assert.fail(\"Expected Exception not Thrown for value: \" + value);\n-            } catch (IllegalArgumentException Ex) {\n-            }\n+            conf.put(Config.TOPOLOGY_WORKER_CHILDOPTS, value);\n+            assertThrows(IllegalArgumentException.class, () -> ConfigValidation.validateFields(conf));\n         }\n     }\n \n     @Test\n     public void testValidity() {\n-        Map<String, Object> conf = new HashMap<String, Object>();\n+        Map<String, Object> conf = new HashMap<>();\n         conf.put(Config.TOPOLOGY_DEBUG, true);\n         conf.put(\"q\", \"asasdasd\");\n-        conf.put(\"aaa\", new Integer(\"123\"));\n-        conf.put(\"bbb\", new Long(\"456\"));\n-        List<Object> testList = new ArrayList<Object>();\n+        conf.put(\"aaa\", Integer.valueOf(\"123\"));\n+        conf.put(\"bbb\", Long.valueOf(\"456\"));\n+        List<Object> testList = new ArrayList<>();\n         testList.add(1);\n         testList.add(2);\n-        testList.add(new Integer(\"3\"));\n-        testList.add(new Long(\"4\"));\n+        testList.add(Integer.valueOf(\"3\"));\n+        testList.add(Long.valueOf(\"4\"));\n         testList.add(new Float(\"3\"));\n         testList.add(new Double(\"4\"));\n         testList.add(ImmutableList.of(\"asdf\", 3));\n         conf.put(\"eee\", testList);\n-        Assert.assertTrue(Utils.isValidConf(conf));\n+        assertTrue(Utils.isValidConf(conf));\n     }\n \n     @Test\n     public void testNonValidConfigChar() {\n-        Map<String, Object> conf = new HashMap<String, Object>();\n+        Map<String, Object> conf = new HashMap<>();\n         conf.put(\"q\", ImmutableList.of(\"asdf\", 'c'));\n-        Assert.assertFalse(Utils.isValidConf(conf));\n+        assertFalse(Utils.isValidConf(conf));\n     }\n \n     @Test\n     public void testNonValidConfigRandomObject() {\n-        Map<String, Object> conf = new HashMap<String, Object>();\n+        Map<String, Object> conf = new HashMap<>();\n         conf.put(\"q\", ImmutableList.of(\"asdf\", new TestConfigValidate()));\n-        Assert.assertFalse(Utils.isValidConf(conf));\n+        assertFalse(Utils.isValidConf(conf));\n     }\n \n     @Test\n@@ -271,13 +281,10 @@ public class TestConfigValidate {\n         KryoRegValidator validator = new KryoRegValidator();\n \n         // fail cases\n-        Object[] failCases = { ImmutableMap.of(\"f\", \"g\"), ImmutableList.of(1), Arrays.asList(ImmutableMap.of(\"a\", 1)) };\n+        Object[] failCases = { ImmutableMap.of(\"f\", \"g\"), ImmutableList.of(1),\n+            Collections.singletonList(ImmutableMap.of(\"a\", 1))};\n         for (Object value : failCases) {\n-            try {\n-                validator.validateField(\"test\", value);\n-                Assert.fail(\"Expected Exception not Thrown for value: \" + value);\n-            } catch (IllegalArgumentException e) {\n-            }\n+            assertThrows(IllegalArgumentException.class, () -> validator.validateField(\"test\", value));\n         }\n \n         // pass cases\n@@ -290,11 +297,7 @@ public class TestConfigValidate {\n \n         Object[] failCases = { 42.42, 42, -33, 23423423423.0, -32, -1, -0.00001, 0, -0, \"Forty-two\" };\n         for (Object value : failCases) {\n-            try {\n-                validator.validateField(\"test\", value);\n-                Assert.fail(\"Expected Exception not Thrown for value: \" + value);\n-            } catch (IllegalArgumentException Ex) {\n-            }\n+            assertThrows(IllegalArgumentException.class, () -> validator.validateField(\"test\", value));\n         }\n \n         Object[] passCases = { 64, 4294967296.0, 1, null };\n@@ -316,11 +319,7 @@ public class TestConfigValidate {\n         Object[] failCases = { -1.0, -1, -0.01, 0.0, 0, \"43\", \"string\" };\n \n         for (Object value : failCases) {\n-            try {\n-                validator.validateField(\"test\", value);\n-                Assert.fail(\"Expected Exception not Thrown for value: \" + value);\n-            } catch (IllegalArgumentException Ex) {\n-            }\n+            assertThrows(IllegalArgumentException.class, () -> validator.validateField(\"test\", value));\n         }\n \n         Object[] passCasesIncludeZero = { null, 1.0, 0.01, 0, 2147483647, 0.0 };\n@@ -332,11 +331,7 @@ public class TestConfigValidate {\n         Object[] failCasesIncludeZero = { -1.0, -1, -0.01, \"43\", \"string\" };\n \n         for (Object value : failCasesIncludeZero) {\n-            try {\n-                validator.validateField(\"test\", true, value);\n-                Assert.fail(\"Expected Exception not Thrown for value: \" + value);\n-            } catch (IllegalArgumentException Ex) {\n-            }\n+            assertThrows(IllegalArgumentException.class, () -> validator.validateField(\"test\", true, value));\n         }\n     }\n \n@@ -350,22 +345,18 @@ public class TestConfigValidate {\n             validator.validateField(\"test\", value);\n         }\n \n-        Object[] failCases = { 1.34, new Long(Integer.MAX_VALUE) + 1 };\n+        Object[] failCases = { 1.34, (long) Integer.MAX_VALUE + 1 };\n \n         for (Object value : failCases) {\n-            try {\n-                validator.validateField(\"test\", value);\n-                Assert.fail(\"Expected Exception not Thrown for value: \" + value);\n-            } catch (IllegalArgumentException Ex) {\n-            }\n+            assertThrows(IllegalArgumentException.class, () -> validator.validateField(\"test\", value));\n         }\n     }\n \n     @Test\n     public void NoDuplicateInListValidator() {\n         NoDuplicateInListValidator validator = new NoDuplicateInListValidator();\n-        Collection<Object> passCases = new LinkedList<Object>();\n-        Collection<Object> failCases = new LinkedList<Object>();\n+        Collection<Object> passCases = new LinkedList<>();\n+        Collection<Object> failCases = new LinkedList<>();\n \n         Object[] passCase1 = { 1000, 0, -1000 };\n         Object[] passCase2 = { \"one\", \"two\", \"three\" };\n@@ -390,22 +381,17 @@ public class TestConfigValidate {\n         failCases.add(Arrays.asList(failCase2));\n         failCases.add(Arrays.asList(failCase3));\n         for (Object value : failCases) {\n-            try {\n-                validator.validateField(\"test\", value);\n-                Assert.fail(\"Expected Exception not Thrown for value: \" + value);\n-            } catch (IllegalArgumentException Ex) {\n-            }\n+            assertThrows(IllegalArgumentException.class, () -> validator.validateField(\"test\", value));\n         }\n     }\n \n     @Test\n     public void testListEntryTypeValidator() {\n-        Collection<Object> testCases1 = new LinkedList<Object>();\n-        Collection<Object> testCases2 = new LinkedList<Object>();\n-        Collection<Object> testCases3 = new LinkedList<Object>();\n+        Collection<Object> testCases1 = new LinkedList<>();\n+        Collection<Object> testCases2 = new LinkedList<>();\n+        Collection<Object> testCases3 = new LinkedList<>();\n \n         Object[] testCase1 = { \"one\", \"two\", \"three\" };\n-        ;\n         Object[] testCase2 = { \"three\" };\n         testCases1.add(Arrays.asList(testCase1));\n         testCases1.add(Arrays.asList(testCase2));\n@@ -415,11 +401,7 @@ public class TestConfigValidate {\n         }\n \n         for (Object value : testCases1) {\n-            try {\n-                ListEntryTypeValidator.validateField(\"test\", Number.class, value);\n-                Assert.fail(\"Expected Exception not Thrown for value: \" + value);\n-            } catch (IllegalArgumentException Ex) {\n-            }\n+            assertThrows(IllegalArgumentException.class, () -> ListEntryTypeValidator.validateField(\"test\", Number.class, value));\n         }\n \n         Object[] testCase3 = { 1000, 0, 1000 };\n@@ -429,11 +411,7 @@ public class TestConfigValidate {\n         testCases2.add(Arrays.asList(testCase4));\n         testCases2.add(Arrays.asList(testCase5));\n         for (Object value : testCases2) {\n-            try {\n-                ListEntryTypeValidator.validateField(\"test\", String.class, value);\n-                Assert.fail(\"Expected Exception not Thrown for value: \" + value);\n-            } catch (IllegalArgumentException Ex) {\n-            }\n+            assertThrows(IllegalArgumentException.class, () -> ListEntryTypeValidator.validateField(\"test\", String.class, value));\n         }\n         for (Object value : testCases2) {\n             ListEntryTypeValidator.validateField(\"test\", Number.class, value);\n@@ -444,28 +422,19 @@ public class TestConfigValidate {\n         testCases3.add(Arrays.asList(testCase6));\n         testCases3.add(Arrays.asList(testCase7));\n         for (Object value : testCases3) {\n-            try {\n-                ListEntryTypeValidator.validateField(\"test\", String.class, value);\n-                Assert.fail(\"Expected Exception not Thrown for value: \" + value);\n-            } catch (IllegalArgumentException Ex) {\n-            }\n+            assertThrows(IllegalArgumentException.class, () -> ListEntryTypeValidator.validateField(\"test\", String.class, value));\n         }\n         for (Object value : testCases1) {\n-            try {\n-                ListEntryTypeValidator.validateField(\"test\", Number.class, value);\n-                Assert.fail(\"Expected Exception not Thrown for value: \" + value);\n-            } catch (IllegalArgumentException Ex) {\n-            }\n+            assertThrows(IllegalArgumentException.class, () -> ListEntryTypeValidator.validateField(\"test\", Number.class, value));\n         }\n     }\n \n     @Test\n-    public void testMapEntryTypeAnnotation() throws InvocationTargetException, NoSuchMethodException, NoSuchFieldException,\n-        InstantiationException, IllegalAccessException {\n+    public void testMapEntryTypeAnnotation() {\n         TestConfig config = new TestConfig();\n-        Collection<Object> passCases = new LinkedList<Object>();\n-        Collection<Object> failCases = new LinkedList<Object>();\n-        Map<Object, Object> passCase1 = new HashMap<Object, Object>();\n+        Collection<Object> passCases = new LinkedList<>();\n+        Collection<Object> failCases = new LinkedList<>();\n+        Map<Object, Object> passCase1 = new HashMap<>();\n         passCase1.put(\"aaa\", 5);\n         passCase1.put(\"bbb\", 6);\n         passCase1.put(\"ccc\", 7);\n@@ -474,14 +443,14 @@ public class TestConfigValidate {\n \n         for (Object value : passCases) {\n             config.put(TestConfig.TEST_MAP_CONFIG, value);\n-            ConfigValidation.validateFields(config, Arrays.asList(TestConfig.class));\n+            ConfigValidation.validateFields(config, Collections.singletonList(TestConfig.class));\n         }\n \n-        Map<Object, Object> failCase1 = new HashMap<Object, Object>();\n+        Map<Object, Object> failCase1 = new HashMap<>();\n         failCase1.put(\"aaa\", 5);\n         failCase1.put(5, 6);\n         failCase1.put(\"ccc\", 7);\n-        Map<Object, Object> failCase2 = new HashMap<Object, Object>();\n+        Map<Object, Object> failCase2 = new HashMap<>();\n         failCase2.put(\"aaa\", \"str\");\n         failCase2.put(\"bbb\", 6);\n         failCase2.put(\"ccc\", 7);\n@@ -489,22 +458,17 @@ public class TestConfigValidate {\n         failCases.add(failCase1);\n         failCases.add(failCase2);\n         for (Object value : failCases) {\n-            try {\n-                config.put(TestConfig.TEST_MAP_CONFIG, value);\n-                ConfigValidation.validateFields(config, Arrays.asList(TestConfig.class));\n-                Assert.fail(\"Expected Exception not Thrown for value: \" + value);\n-            } catch (IllegalArgumentException Ex) {\n-            }\n+            config.put(TestConfig.TEST_MAP_CONFIG, value);\n+            assertThrows(IllegalArgumentException.class, () -> ConfigValidation.validateFields(config, Collections.singletonList(TestConfig.class)));\n         }\n     }\n \n     @Test\n-    public void testMapEntryCustomAnnotation() throws InvocationTargetException, NoSuchMethodException, NoSuchFieldException,\n-        InstantiationException, IllegalAccessException {\n+    public void testMapEntryCustomAnnotation() {\n         TestConfig config = new TestConfig();\n-        Collection<Object> passCases = new LinkedList<Object>();\n-        Collection<Object> failCases = new LinkedList<Object>();\n-        Map<Object, Object> passCase1 = new HashMap<Object, Object>();\n+        Collection<Object> passCases = new LinkedList<>();\n+        Collection<Object> failCases = new LinkedList<>();\n+        Map<Object, Object> passCase1 = new HashMap<>();\n         passCase1.put(\"aaa\", 5);\n         passCase1.put(\"bbb\", 100);\n         passCase1.put(\"ccc\", Integer.MAX_VALUE);\n@@ -513,22 +477,22 @@ public class TestConfigValidate {\n \n         for (Object value : passCases) {\n             config.put(TestConfig.TEST_MAP_CONFIG_2, value);\n-            ConfigValidation.validateFields(config, Arrays.asList(TestConfig.class));\n+            ConfigValidation.validateFields(config, Collections.singletonList(TestConfig.class));\n         }\n \n-        Map<Object, Object> failCase1 = new HashMap<Object, Object>();\n+        Map<Object, Object> failCase1 = new HashMap<>();\n         failCase1.put(\"aaa\", 5);\n         failCase1.put(5, 6);\n         failCase1.put(\"ccc\", 7);\n-        Map<Object, Object> failCase2 = new HashMap<Object, Object>();\n+        Map<Object, Object> failCase2 = new HashMap<>();\n         failCase2.put(\"aaa\", \"str\");\n         failCase2.put(\"bbb\", 6);\n         failCase2.put(\"ccc\", 7);\n-        Map<Object, Object> failCase3 = new HashMap<Object, Object>();\n+        Map<Object, Object> failCase3 = new HashMap<>();\n         failCase3.put(\"aaa\", -1);\n         failCase3.put(\"bbb\", 6);\n         failCase3.put(\"ccc\", 7);\n-        Map<Object, Object> failCase4 = new HashMap<Object, Object>();\n+        Map<Object, Object> failCase4 = new HashMap<>();\n         failCase4.put(\"aaa\", 1);\n         failCase4.put(\"bbb\", 6);\n         failCase4.put(\"ccc\", 7.4);\n@@ -538,20 +502,16 @@ public class TestConfigValidate {\n         failCases.add(failCase3);\n         failCases.add(failCase4);\n         for (Object value : failCases) {\n-            try {\n-                config.put(TestConfig.TEST_MAP_CONFIG_2, value);\n-                ConfigValidation.validateFields(config, Arrays.asList(TestConfig.class));\n-                Assert.fail(\"Expected Exception not Thrown for value: \" + value);\n-            } catch (IllegalArgumentException Ex) {\n-            }\n+            config.put(TestConfig.TEST_MAP_CONFIG_2, value);\n+            assertThrows(IllegalArgumentException.class, () -> ConfigValidation.validateFields(config, Collections.singletonList(TestConfig.class)));\n         }\n     }\n \n     @Test\n     public void testExactlyOneOfCustomAnnotation() {\n         TestConfig config = new TestConfig();\n-        Collection<Object> passCases = new LinkedList<Object>();\n-        Collection<Object> failCases = new LinkedList<Object>();\n+        Collection<Object> passCases = new LinkedList<>();\n+        Collection<Object> failCases = new LinkedList<>();\n \n         List<Object> passCaseListOfList = new ArrayList<>();\n         passCaseListOfList.add(Arrays.asList(\"comp1\", \"comp2\"));\n@@ -604,7 +564,7 @@ public class TestConfigValidate {\n \n         for (Object value : passCases) {\n             config.put(TestConfig.TEST_MAP_CONFIG_9, value);\n-            ConfigValidation.validateFields(config, Arrays.asList(TestConfig.class));\n+            ConfigValidation.validateFields(config, Collections.singletonList(TestConfig.class));\n         }\n \n         List<Object> failCaseList = new ArrayList<>();\n@@ -667,21 +627,16 @@ public class TestConfigValidate {\n         failCases.add(null);\n \n         for (Object value : failCases) {\n-            try {\n-                config.put(TestConfig.TEST_MAP_CONFIG_9, value);\n-                ConfigValidation.validateFields(config, Arrays.asList(TestConfig.class));\n-                Assert.fail(\"Expected Exception not Thrown for value: \" + value);\n-            } catch (IllegalArgumentException Ex) {\n-            }\n+            config.put(TestConfig.TEST_MAP_CONFIG_9, value);\n+            assertThrows(IllegalArgumentException.class, () -> ConfigValidation.validateFields(config, Collections.singletonList(TestConfig.class)));\n         }\n     }\n \n     @Test\n-    public void testListEntryTypeAnnotation() throws InvocationTargetException, NoSuchMethodException, NoSuchFieldException,\n-        InstantiationException, IllegalAccessException {\n+    public void testListEntryTypeAnnotation() {\n         TestConfig config = new TestConfig();\n-        Collection<Object> passCases = new LinkedList<Object>();\n-        Collection<Object> failCases = new LinkedList<Object>();\n+        Collection<Object> passCases = new LinkedList<>();\n+        Collection<Object> failCases = new LinkedList<>();\n         Object[] passCase1 = { 1, 5.0, -0.01, 0, Integer.MAX_VALUE, Double.MIN_VALUE };\n         Object[] passCase2 = { 1 };\n         passCases.add(Arrays.asList(passCase1));\n@@ -689,7 +644,7 @@ public class TestConfigValidate {\n \n         for (Object value : passCases) {\n             config.put(TestConfig.TEST_MAP_CONFIG_3, value);\n-            ConfigValidation.validateFields(config, Arrays.asList(TestConfig.class));\n+            ConfigValidation.validateFields(config, Collections.singletonList(TestConfig.class));\n         }\n \n         Object[] failCase1 = { 1, 5.0, -0.01, 0, \"aaa\" };\n@@ -700,21 +655,16 @@ public class TestConfigValidate {\n         failCases.add(\"b\");\n         failCases.add(null);\n         for (Object value : failCases) {\n-            try {\n-                config.put(TestConfig.TEST_MAP_CONFIG_3, value);\n-                ConfigValidation.validateFields(config, Arrays.asList(TestConfig.class));\n-                Assert.fail(\"Expected Exception not Thrown for value: \" + value);\n-            } catch (IllegalArgumentException Ex) {\n-            }\n+            config.put(TestConfig.TEST_MAP_CONFIG_3, value);\n+            assertThrows(IllegalArgumentException.class, () -> ConfigValidation.validateFields(config, Collections.singletonList(TestConfig.class)));\n         }\n     }\n \n     @Test\n-    public void testListEntryCustomAnnotation() throws InvocationTargetException, NoSuchMethodException, NoSuchFieldException,\n-        InstantiationException, IllegalAccessException {\n+    public void testListEntryCustomAnnotation() {\n         TestConfig config = new TestConfig();\n-        Collection<Object> passCases = new LinkedList<Object>();\n-        Collection<Object> failCases = new LinkedList<Object>();\n+        Collection<Object> passCases = new LinkedList<>();\n+        Collection<Object> failCases = new LinkedList<>();\n         Object[] passCase1 = { 1, 5.0, 0.01, Double.MAX_VALUE };\n         Object[] passCase2 = { 1 };\n         passCases.add(Arrays.asList(passCase1));\n@@ -722,7 +672,7 @@ public class TestConfigValidate {\n \n         for (Object value : passCases) {\n             config.put(TestConfig.TEST_MAP_CONFIG_4, value);\n-            ConfigValidation.validateFields(config, Arrays.asList(TestConfig.class));\n+            ConfigValidation.validateFields(config, Collections.singletonList(TestConfig.class));\n         }\n \n         Object[] failCase1 = { 1, 5.0, -0.01, 3.0 };\n@@ -739,46 +689,36 @@ public class TestConfigValidate {\n         failCases.add(1);\n         failCases.add(\"b\");\n         for (Object value : failCases) {\n-            try {\n-                config.put(TestConfig.TEST_MAP_CONFIG_4, value);\n-                ConfigValidation.validateFields(config, Arrays.asList(TestConfig.class));\n-                Assert.fail(\"Expected Exception not Thrown for value: \" + value);\n-            } catch (IllegalArgumentException Ex) {\n-            }\n+            config.put(TestConfig.TEST_MAP_CONFIG_4, value);\n+            assertThrows(IllegalArgumentException.class, () -> ConfigValidation.validateFields(config, Collections.singletonList(TestConfig.class)));\n         }\n     }\n \n     @Test\n-    public void TestAcceptedStrings() throws InvocationTargetException, NoSuchMethodException, NoSuchFieldException, InstantiationException,\n-        IllegalAccessException {\n+    public void TestAcceptedStrings() {\n         TestConfig config = new TestConfig();\n         String[] passCases = { \"aaa\", \"bbb\", \"ccc\" };\n \n         for (Object value : passCases) {\n             config.put(TestConfig.TEST_MAP_CONFIG_5, value);\n-            ConfigValidation.validateFields(config, Arrays.asList(TestConfig.class));\n+            ConfigValidation.validateFields(config, Collections.singletonList(TestConfig.class));\n         }\n \n         String[] failCases = { \"aa\", \"bb\", \"cc\", \"abc\", \"a\", \"b\", \"c\", \"\" };\n         for (Object value : failCases) {\n-            try {\n-                config.put(TestConfig.TEST_MAP_CONFIG_5, value);\n-                ConfigValidation.validateFields(config, Arrays.asList(TestConfig.class));\n-                Assert.fail(\"Expected Exception not Thrown for value: \" + value);\n-            } catch (IllegalArgumentException Ex) {\n-            }\n+           config.put(TestConfig.TEST_MAP_CONFIG_5, value);\n+           assertThrows(IllegalArgumentException.class, () -> ConfigValidation.validateFields(config, Collections.singletonList(TestConfig.class)));\n         }\n     }\n \n     @Test\n-    public void TestImpersonationAclUserEntryValidator() throws InvocationTargetException, NoSuchMethodException, NoSuchFieldException,\n-        InstantiationException, IllegalAccessException {\n+    public void TestImpersonationAclUserEntryValidator() {\n         TestConfig config = new TestConfig();\n-        Collection<Object> passCases = new LinkedList<Object>();\n-        Collection<Object> failCases = new LinkedList<Object>();\n+        Collection<Object> passCases = new LinkedList<>();\n+        Collection<Object> failCases = new LinkedList<>();\n \n-        Map<String, Map<String, List<String>>> passCase1 = new HashMap<String, Map<String, List<String>>>();\n-        Map<String, List<String>> passCase1_hostsAndGroups = new HashMap<String, List<String>>();\n+        Map<String, Map<String, List<String>>> passCase1 = new HashMap<>();\n+        Map<String, List<String>> passCase1_hostsAndGroups = new HashMap<>();\n         String[] hosts = { \"host.1\", \"host.2\", \"host.3\" };\n         passCase1_hostsAndGroups.put(\"hosts\", Arrays.asList(hosts));\n         String[] groups = { \"group.1\", \"group.2\", \"group.3\" };\n@@ -788,18 +728,17 @@ public class TestConfigValidate {\n \n         for (Object value : passCases) {\n             config.put(TestConfig.TEST_MAP_CONFIG_6, value);\n-            ConfigValidation.validateFields(config, Arrays.asList(TestConfig.class));\n+            ConfigValidation.validateFields(config, Collections.singletonList(TestConfig.class));\n         }\n \n-        Map<String, Map<String, List<String>>> failCase1 = new HashMap<String, Map<String, List<String>>>();\n-        Map<String, List<String>> failCase1_hostsAndGroups = new HashMap<String, List<String>>();\n-        String[] failhosts = { \"host.1\", \"host.2\", \"host.3\" };\n+        Map<String, Map<String, List<String>>> failCase1 = new HashMap<>();\n+        Map<String, List<String>> failCase1_hostsAndGroups = new HashMap<>();\n         failCase1_hostsAndGroups.put(\"hosts\", Arrays.asList(hosts));\n         failCase1.put(\"jerry\", failCase1_hostsAndGroups);\n \n \n-        Map<String, Map<String, List<String>>> failCase2 = new HashMap<String, Map<String, List<String>>>();\n-        Map<String, List<String>> failCase2_hostsAndGroups = new HashMap<String, List<String>>();\n+        Map<String, Map<String, List<String>>> failCase2 = new HashMap<>();\n+        Map<String, List<String>> failCase2_hostsAndGroups = new HashMap<>();\n         String[] failgroups = { \"group.1\", \"group.2\", \"group.3\" };\n         failCase2_hostsAndGroups.put(\"groups\", Arrays.asList(groups));\n         failCase2.put(\"jerry\", failCase2_hostsAndGroups);\n@@ -810,24 +749,20 @@ public class TestConfigValidate {\n         failCases.add(5);\n \n         for (Object value : failCases) {\n-            try {\n-                config.put(TestConfig.TEST_MAP_CONFIG_6, value);\n-                ConfigValidation.validateFields(config, Arrays.asList(TestConfig.class));\n-                Assert.fail(\"Expected Exception not Thrown for value: \" + value);\n-            } catch (IllegalArgumentException Ex) {\n-            }\n+            config.put(TestConfig.TEST_MAP_CONFIG_6, value);\n+            assertThrows(IllegalArgumentException.class, () -> ConfigValidation.validateFields(config, Collections.singletonList(TestConfig.class)));\n         }\n     }\n \n     @Test\n     public void TestResourceAwareSchedulerUserPool() {\n         TestConfig config = new TestConfig();\n-        Collection<Object> failCases = new LinkedList<Object>();\n+        Collection<Object> failCases = new LinkedList<>();\n \n-        Map<String, Map<String, Integer>> passCase1 = new HashMap<String, Map<String, Integer>>();\n-        passCase1.put(\"jerry\", new HashMap<String, Integer>());\n-        passCase1.put(\"bobby\", new HashMap<String, Integer>());\n-        passCase1.put(\"derek\", new HashMap<String, Integer>());\n+        Map<String, Map<String, Integer>> passCase1 = new HashMap<>();\n+        passCase1.put(\"jerry\", new HashMap<>());\n+        passCase1.put(\"bobby\", new HashMap<>());\n+        passCase1.put(\"derek\", new HashMap<>());\n \n         passCase1.get(\"jerry\").put(\"cpu\", 10000);\n         passCase1.get(\"jerry\").put(\"memory\", 20148);\n@@ -836,13 +771,13 @@ public class TestConfigValidate {\n         passCase1.get(\"derek\").put(\"cpu\", 30000);\n         passCase1.get(\"derek\").put(\"memory\", 60148);\n \n-        config.put(TestConfig.TEST_MAP_CONFIG_7, (Object) passCase1);\n-        ConfigValidation.validateFields(config, Arrays.asList(TestConfig.class));\n+        config.put(TestConfig.TEST_MAP_CONFIG_7, passCase1);\n+        ConfigValidation.validateFields(config, Collections.singletonList(TestConfig.class));\n \n-        Map<String, Map<String, Integer>> failCase1 = new HashMap<String, Map<String, Integer>>();\n-        failCase1.put(\"jerry\", new HashMap<String, Integer>());\n-        failCase1.put(\"bobby\", new HashMap<String, Integer>());\n-        failCase1.put(\"derek\", new HashMap<String, Integer>());\n+        Map<String, Map<String, Integer>> failCase1 = new HashMap<>();\n+        failCase1.put(\"jerry\", new HashMap<>());\n+        failCase1.put(\"bobby\", new HashMap<>());\n+        failCase1.put(\"derek\", new HashMap<>());\n \n         failCase1.get(\"jerry\").put(\"cpu\", 10000);\n         failCase1.get(\"jerry\").put(\"memory\", 20148);\n@@ -851,11 +786,11 @@ public class TestConfigValidate {\n         //this will fail the test since user derek does not have an entry for memory\n         failCase1.get(\"derek\").put(\"cpu\", 30000);\n \n-        Map<String, Map<String, Integer>> failCase2 = new HashMap<String, Map<String, Integer>>();\n+        Map<String, Map<String, Integer>> failCase2 = new HashMap<>();\n         //this will fail since jerry doesn't have either cpu or memory entries\n-        failCase2.put(\"jerry\", new HashMap<String, Integer>());\n-        failCase2.put(\"bobby\", new HashMap<String, Integer>());\n-        failCase2.put(\"derek\", new HashMap<String, Integer>());\n+        failCase2.put(\"jerry\", new HashMap<>());\n+        failCase2.put(\"bobby\", new HashMap<>());\n+        failCase2.put(\"derek\", new HashMap<>());\n         failCase2.get(\"bobby\").put(\"cpu\", 20000);\n         failCase2.get(\"bobby\").put(\"memory\", 40148);\n         failCase2.get(\"derek\").put(\"cpu\", 30000);\n@@ -865,42 +800,34 @@ public class TestConfigValidate {\n         failCases.add(failCase2);\n \n         for (Object value : failCases) {\n-            try {\n-                config.put(TestConfig.TEST_MAP_CONFIG_7, value);\n-                ConfigValidation.validateFields(config, Arrays.asList(TestConfig.class));\n-                Assert.fail(\"Expected Exception not Thrown for value: \" + value);\n-            } catch (IllegalArgumentException Ex) {\n-            }\n+            config.put(TestConfig.TEST_MAP_CONFIG_7, value);\n+            assertThrows(IllegalArgumentException.class, () -> ConfigValidation.validateFields(config, Collections.singletonList(TestConfig.class)));\n         }\n     }\n \n     @Test\n     public void TestImplementsClassValidator() {\n         TestConfig config = new TestConfig();\n-        Collection<Object> passCases = new LinkedList<Object>();\n-        Collection<Object> failCases = new LinkedList<Object>();\n+        Collection<Object> passCases = new LinkedList<>();\n+        Collection<Object> failCases = new LinkedList<>();\n \n         passCases.add(\"org.apache.storm.networktopography.DefaultRackDNSToSwitchMapping\");\n \n         for (Object value : passCases) {\n             config.put(TestConfig.TEST_MAP_CONFIG_8, value);\n-            ConfigValidation.validateFields(config, Arrays.asList(TestConfig.class));\n+            ConfigValidation.validateFields(config, Collections.singletonList(TestConfig.class));\n         }\n         //will fail since org.apache.storm.nimbus.NimbusInfo doesn't implement or extend org.apache.storm.networktopography\n         // .DNSToSwitchMapping\n         failCases.add(\"org.apache.storm.nimbus.NimbusInfo\");\n         failCases.add(null);\n         for (Object value : failCases) {\n-            try {\n-                config.put(TestConfig.TEST_MAP_CONFIG_8, value);\n-                ConfigValidation.validateFields(config, Arrays.asList(TestConfig.class));\n-                Assert.fail(\"Expected Exception not Thrown for value: \" + value);\n-            } catch (IllegalArgumentException Ex) {\n-            }\n+            config.put(TestConfig.TEST_MAP_CONFIG_8, value);\n+            assertThrows(IllegalArgumentException.class, () -> ConfigValidation.validateFields(config, Collections.singletonList(TestConfig.class)));\n         }\n     }\n \n-    public class TestConfig extends HashMap<String, Object> {\n+    public static class TestConfig extends HashMap<String, Object> {\n         @IsMapEntryType(keyType = String.class, valueType = Integer.class)\n         public static final String TEST_MAP_CONFIG = \"test.map.config\";\n \n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -1,34 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version\n- * 2.0 (the \"License\"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions\n- * and limitations under the License.\n- */\n-\n-package org.apache.storm.hbase.trident.state;\n-\n-import java.util.Map;\n-import org.apache.storm.task.IMetricsContext;\n-import org.apache.storm.trident.state.State;\n-import org.apache.storm.trident.state.StateFactory;\n-\n-public class HBaseStateFactory implements StateFactory {\n-\n-    private HBaseState.Options options;\n-\n-    public HBaseStateFactory(HBaseState.Options options) {\n-        this.options = options;\n-    }\n-\n-    @Override\n-    public State makeState(Map<String, Object> map, IMetricsContext metricsContext, int partitionIndex, int numPartitions) {\n-        HBaseState state = new HBaseState(map, partitionIndex, numPartitions, options);\n-        state.prepare();\n-        return state;\n-    }\n-}\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -1,171 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version\n- * 2.0 (the \"License\"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions\n- * and limitations under the License.\n- */\n-\n-package org.apache.storm.hbase.trident.state;\n-\n-import com.google.common.collect.Lists;\n-import java.io.Serializable;\n-import java.util.Collections;\n-import java.util.HashMap;\n-import java.util.List;\n-import java.util.Map;\n-import org.apache.hadoop.conf.Configuration;\n-import org.apache.hadoop.hbase.HBaseConfiguration;\n-import org.apache.hadoop.hbase.client.Durability;\n-import org.apache.hadoop.hbase.client.Get;\n-import org.apache.hadoop.hbase.client.Mutation;\n-import org.apache.hadoop.hbase.client.Result;\n-import org.apache.storm.Config;\n-import org.apache.storm.hbase.bolt.mapper.HBaseProjectionCriteria;\n-import org.apache.storm.hbase.bolt.mapper.HBaseValueMapper;\n-import org.apache.storm.hbase.common.ColumnList;\n-import org.apache.storm.hbase.common.HBaseClient;\n-import org.apache.storm.hbase.trident.mapper.TridentHBaseMapper;\n-import org.apache.storm.topology.FailedException;\n-import org.apache.storm.trident.operation.TridentCollector;\n-import org.apache.storm.trident.state.State;\n-import org.apache.storm.trident.tuple.TridentTuple;\n-import org.apache.storm.tuple.Values;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-public class HBaseState implements State {\n-\n-    private static final Logger LOG = LoggerFactory.getLogger(HBaseState.class);\n-\n-    private Options options;\n-    @SuppressWarnings(\"checkstyle:MemberName\")\n-    private HBaseClient hBaseClient;\n-    private Map<String, Object> map;\n-    private int numPartitions;\n-    private int partitionIndex;\n-\n-    protected HBaseState(Map<String, Object> map, int partitionIndex, int numPartitions, Options options) {\n-        this.options = options;\n-        this.map = map;\n-        this.partitionIndex = partitionIndex;\n-        this.numPartitions = numPartitions;\n-    }\n-\n-    protected void prepare() {\n-        final Configuration hbConfig = HBaseConfiguration.create();\n-        Map<String, Object> conf = (Map<String, Object>) map.get(options.configKey);\n-        if (conf == null) {\n-            LOG.info(\"HBase configuration not found using key '\" + options.configKey + \"'\");\n-            LOG.info(\"Using HBase config from first hbase-site.xml found on classpath.\");\n-            conf = Collections.emptyMap();\n-        } else {\n-            if (conf.get(\"hbase.rootdir\") == null) {\n-                LOG.warn(\"No 'hbase.rootdir' value found in configuration! Using HBase defaults.\");\n-            }\n-            for (String key : conf.keySet()) {\n-                hbConfig.set(key, String.valueOf(conf.get(key)));\n-            }\n-        }\n-\n-        //heck for backward compatibility, we need to pass TOPOLOGY_AUTO_CREDENTIALS to hbase conf\n-        //the conf instance is instance of persistentMap so making a copy.\n-        Map<String, Object> hbaseConfMap = new HashMap<>(conf);\n-        hbaseConfMap.put(Config.TOPOLOGY_AUTO_CREDENTIALS, map.get(Config.TOPOLOGY_AUTO_CREDENTIALS));\n-\n-        this.hBaseClient = new HBaseClient(hbaseConfMap, hbConfig, options.tableName);\n-    }\n-\n-    @Override\n-    public void beginCommit(Long someLong) {\n-        LOG.debug(\"beginCommit is noop.\");\n-    }\n-\n-    @Override\n-    public void commit(Long someLong) {\n-        LOG.debug(\"commit is noop.\");\n-    }\n-\n-    public void updateState(List<TridentTuple> tuples, TridentCollector collector) {\n-        List<Mutation> mutations = Lists.newArrayList();\n-\n-        for (TridentTuple tuple : tuples) {\n-            byte[] rowKey = options.mapper.rowKey(tuple);\n-            ColumnList cols = options.mapper.columns(tuple);\n-            mutations.addAll(hBaseClient.constructMutationReq(rowKey, cols, options.durability));\n-        }\n-\n-        try {\n-            hBaseClient.batchMutate(mutations);\n-        } catch (Exception e) {\n-            collector.reportError(e);\n-            throw new FailedException(e);\n-        }\n-    }\n-\n-    public List<List<Values>> batchRetrieve(List<TridentTuple> tridentTuples) {\n-        List<List<Values>> batchRetrieveResult = Lists.newArrayList();\n-        List<Get> gets = Lists.newArrayList();\n-        for (TridentTuple tuple : tridentTuples) {\n-            byte[] rowKey = options.mapper.rowKey(tuple);\n-            gets.add(hBaseClient.constructGetRequests(rowKey, options.projectionCriteria));\n-        }\n-\n-        try {\n-            Result[] results = hBaseClient.batchGet(gets);\n-            for (int i = 0; i < results.length; i++) {\n-                Result result = results[i];\n-                TridentTuple tuple = tridentTuples.get(i);\n-                List<Values> values = options.rowToStormValueMapper.toValues(tuple, result);\n-                batchRetrieveResult.add(values);\n-            }\n-        } catch (Exception e) {\n-            LOG.warn(\"Batch get operation failed. Triggering replay.\", e);\n-            throw new FailedException(e);\n-        }\n-        return batchRetrieveResult;\n-    }\n-\n-    public static class Options implements Serializable {\n-        private TridentHBaseMapper mapper;\n-        private Durability durability = Durability.SKIP_WAL;\n-        private HBaseProjectionCriteria projectionCriteria;\n-        private HBaseValueMapper rowToStormValueMapper;\n-        private String configKey;\n-        private String tableName;\n-\n-        public Options withDurability(Durability durability) {\n-            this.durability = durability;\n-            return this;\n-        }\n-\n-        public Options withProjectionCriteria(HBaseProjectionCriteria projectionCriteria) {\n-            this.projectionCriteria = projectionCriteria;\n-            return this;\n-        }\n-\n-        public Options withConfigKey(String configKey) {\n-            this.configKey = configKey;\n-            return this;\n-        }\n-\n-        public Options withTableName(String tableName) {\n-            this.tableName = tableName;\n-            return this;\n-        }\n-\n-        public Options withRowToStormValueMapper(HBaseValueMapper rowToStormValueMapper) {\n-            this.rowToStormValueMapper = rowToStormValueMapper;\n-            return this;\n-        }\n-\n-        public Options withMapper(TridentHBaseMapper mapper) {\n-            this.mapper = mapper;\n-            return this;\n-        }\n-    }\n-}\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -61,6 +61,8 @@ import java.util.function.UnaryOperator;\n import java.util.stream.Collectors;\n import javax.security.auth.Subject;\n \n+import net.minidev.json.JSONValue;\n+\n import org.apache.storm.Config;\n import org.apache.storm.Constants;\n import org.apache.storm.DaemonConfig;\n@@ -225,7 +227,6 @@ import org.apache.storm.validation.ConfigValidation;\n import org.apache.storm.zookeeper.AclEnforcement;\n import org.apache.storm.zookeeper.ClientZookeeper;\n import org.apache.storm.zookeeper.Zookeeper;\n-import org.json.simple.JSONValue;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n@@ -436,6 +437,7 @@ public class Nimbus implements Iface, Shutdownable, DaemonCommon {\n     private final UptimeComputer uptime;\n     private final ITopologyValidator validator;\n     private final StormTimer timer;\n+    private final StormTimer cleanupTimer;\n     private final IScheduler scheduler;\n     private final IScheduler underlyingScheduler;\n     //Metrics related\n@@ -577,6 +579,10 @@ public class Nimbus implements Iface, Shutdownable, DaemonCommon {\n             LOG.error(\"Error while processing event\", e);\n             Utils.exitProcess(20, \"Error while processing event\");\n         });\n+        this.cleanupTimer = new StormTimer(\"nimbus:cleanupTimer\", (t, e) -> {\n+            LOG.error(\"Error in cleanupTimer while processing event\", e);\n+            Utils.exitProcess(20, \"Error in cleanupTimer while processing event\");\n+        });\n         this.underlyingScheduler = makeScheduler(conf, inimbus);\n         this.scheduler = wrapAsBlacklistScheduler(conf, underlyingScheduler, metricsRegistry);\n         this.zkClient = makeZKClient(conf);\n@@ -822,9 +828,15 @@ public class Nimbus implements Iface, Shutdownable, DaemonCommon {\n         return ret;\n     }\n \n+    /**\n+     * Check new assignments with existing assignments and determine difference is any.\n+     *\n+     * @param existingAssignments non-null map of topology-id to existing assignments.\n+     * @param newAssignments non-null map of topology-id to new assignments.\n+     * @return true if there is a change in assignments, false otherwise.\n+     */\n     private boolean auditAssignmentChanges(Map<String, Assignment> existingAssignments,\n                                            Map<String, Assignment> newAssignments) {\n-        assert existingAssignments != null && newAssignments != null;\n         boolean anyChanged = existingAssignments.isEmpty() ^ newAssignments.isEmpty();\n         long numRemovedExec = 0;\n         long numRemovedSlot = 0;\n@@ -985,6 +997,33 @@ public class Nimbus implements Iface, Shutdownable, DaemonCommon {\n         return isTopologyActive(state, topoName) || state.activeStorms().contains(topoName);\n     }\n \n+    /**\n+     * Returns the topologyId of the topology using this blob.\n+     * @param state the cluster state\n+     * @param topoCache the topology cache\n+     * @param key the blob key\n+     * @return null or id\n+     */\n+    private static String topologyUsingThisBlob(IStormClusterState state, TopoCache topoCache, String key) {\n+        for (String topologyId : state.activeStorms()) {\n+            Map<String, Object> topoConf = null;\n+            try {\n+                topoConf = readTopoConfAsNimbus(topologyId, topoCache);\n+            } catch (KeyNotFoundException | AuthorizationException | IOException e) {\n+                continue;\n+            }\n+            if (topoConf == null) {\n+                continue;\n+            }\n+            @SuppressWarnings(\"unchecked\")\n+            Map<String, Map<String, Object>> blobstoreMap = (Map<String, Map<String, Object>>) topoConf.get(Config.TOPOLOGY_BLOBSTORE_MAP);\n+            if (blobstoreMap != null && blobstoreMap.containsKey(key)) {\n+                return topologyId;\n+            }\n+        }\n+        return null;\n+    }\n+\n     private static Map<String, Object> tryReadTopoConf(String topoId, TopoCache tc)\n         throws NotAliveException, AuthorizationException, IOException {\n         try {\n@@ -1044,15 +1083,15 @@ public class Nimbus implements Iface, Shutdownable, DaemonCommon {\n \n     @VisibleForTesting\n     public static Set<String> topoIdsToClean(IStormClusterState state, BlobStore store, Map<String, Object> conf) {\n-        Set<String> ret = new HashSet<>();\n-        ret.addAll(Utils.OR(state.heartbeatStorms(), EMPTY_STRING_LIST));\n-        ret.addAll(Utils.OR(state.errorTopologies(), EMPTY_STRING_LIST));\n-        ret.addAll(Utils.OR(store.storedTopoIds(), EMPTY_STRING_SET));\n-        ret.addAll(Utils.OR(state.backpressureTopologies(), EMPTY_STRING_LIST));\n-        ret.addAll(Utils.OR(state.idsOfTopologiesWithPrivateWorkerKeys(), EMPTY_STRING_SET));\n-        ret = getExpiredTopologyIds(ret, conf);\n-        ret.removeAll(Utils.OR(state.activeStorms(), EMPTY_STRING_LIST));\n-        return ret;\n+        Set<String> cleanable = new HashSet<>();\n+        cleanable.addAll(Utils.OR(state.heartbeatStorms(), EMPTY_STRING_LIST));\n+        cleanable.addAll(Utils.OR(state.errorTopologies(), EMPTY_STRING_LIST));\n+        cleanable.addAll(Utils.OR(store.storedTopoIds(), EMPTY_STRING_SET));\n+        cleanable.addAll(Utils.OR(state.backpressureTopologies(), EMPTY_STRING_LIST));\n+        cleanable.addAll(Utils.OR(state.idsOfTopologiesWithPrivateWorkerKeys(), EMPTY_STRING_SET));\n+        Set<String> delayedCleanable = getExpiredTopologyIds(cleanable, conf);\n+        delayedCleanable.removeAll(Utils.OR(state.activeStorms(), EMPTY_STRING_LIST));\n+        return delayedCleanable;\n     }\n \n     private static String extractStatusStr(StormBase base) {\n@@ -1105,7 +1144,11 @@ public class Nimbus implements Iface, Shutdownable, DaemonCommon {\n      * @param topoConf initial topology conf\n      * @param topology  the Storm topology\n      */\n-    private static Map<String, Object> normalizeConf(Map<String, Object> conf, Map<String, Object> topoConf, StormTopology topology) {\n+    static Map<String, Object> normalizeConf(Map<String, Object> conf, Map<String, Object> topoConf, StormTopology topology) {\n+\n+        // clear any values from the topoConf that it should not be setting.\n+        topoConf.remove(Config.STORM_WORKERS_ARTIFACTS_DIR);\n+\n         //ensure that serializations are same for all tasks no matter what's on\n         // the supervisors. this also allows you to declare the serializations as a sequence\n         List<Map<String, Object>> allConfs = new ArrayList<>();\n@@ -1152,6 +1195,15 @@ public class Nimbus implements Iface, Shutdownable, DaemonCommon {\n             ret.put(Config.TOPOLOGY_METRICS_REPORTERS, mergedConf.get(Config.STORM_METRICS_REPORTERS));\n         }\n \n+        // add any system metrics reporters to the topology metrics reporters\n+        if (conf.containsKey(Config.STORM_TOPOLOGY_METRICS_SYSTEM_REPORTERS)) {\n+            List<Map<String, Object>> reporters = (List<Map<String, Object>>)\n+                    ret.computeIfAbsent(Config.TOPOLOGY_METRICS_REPORTERS, (key) -> new ArrayList<>());\n+            List<Map<String, Object>> systemReporters = (List<Map<String, Object>>)\n+                    conf.get(Config.STORM_TOPOLOGY_METRICS_SYSTEM_REPORTERS);\n+            reporters.addAll(systemReporters);\n+        }\n+\n         // Don't allow topoConf to override various cluster-specific properties.\n         // Specifically adding the cluster settings to the topoConf here will make sure these settings\n         // also override the subsequently generated conf picked up locally on the classpath.\n@@ -1386,12 +1438,15 @@ public class Nimbus implements Iface, Shutdownable, DaemonCommon {\n                         if (!doNotReassign) {\n                             mkAssignments();\n                         }\n-                        doCleanup();\n                     } catch (Exception e) {\n                         throw new RuntimeException(e);\n                     }\n                 });\n-\n+            // Schedule topology cleanup\n+            cleanupTimer.scheduleRecurring(0, ObjectReader.getInt(conf.get(DaemonConfig.NIMBUS_MONITOR_FREQ_SECS)),\n+                () -> {\n+                    cleanupTimer.schedule(0, () -> doCleanup());\n+                });\n             // Schedule Nimbus inbox cleaner\n             final int jarExpSecs = ObjectReader.getInt(conf.get(DaemonConfig.NIMBUS_INBOX_JAR_EXPIRATION_SECS));\n             timer.scheduleRecurring(0, ObjectReader.getInt(conf.get(DaemonConfig.NIMBUS_CLEANUP_INBOX_FREQ_SECS)),\n@@ -1427,6 +1482,18 @@ public class Nimbus implements Iface, Shutdownable, DaemonCommon {\n                     }\n                 });\n \n+            // Periodically make sure the blobstore update time is up to date.  This could have failed if Nimbus encountered\n+            // an exception updating the update time, or due to bugs causing a missed update of the blobstore mod time on a blob\n+            // update.\n+            timer.scheduleRecurring(30, ServerConfigUtils.getLocalizerUpdateBlobInterval(conf) * 5,\n+                () -> {\n+                    try {\n+                        blobStore.validateBlobUpdateTime();\n+                    } catch (IOException e) {\n+                        throw new RuntimeException(e);\n+                    }\n+                });\n+\n             metricsRegistry.registerGauge(\"nimbus:total-available-memory-non-negative\", () -> nodeIdToResources.get().values()\n                     .parallelStream()\n                     .mapToDouble(supervisorResources -> Math.max(supervisorResources.getAvailableMem(), 0))\n@@ -1657,42 +1724,6 @@ public class Nimbus implements Iface, Shutdownable, DaemonCommon {\n                                      basicSupervisorDetailsMap(clusterState), metricsRegistry);\n     }\n \n-    @VisibleForTesting\n-    static void validateTopologyWorkerMaxHeapSizeConfigs(\n-        Map<String, Object> stormConf, StormTopology topology, double defaultWorkerMaxHeapSizeMb) throws InvalidTopologyException {\n-        double largestMemReq = getMaxExecutorMemoryUsageForTopo(topology, stormConf);\n-        double topologyWorkerMaxHeapSize =\n-            ObjectReader.getDouble(stormConf.get(Config.TOPOLOGY_WORKER_MAX_HEAP_SIZE_MB), defaultWorkerMaxHeapSizeMb);\n-        if (topologyWorkerMaxHeapSize < largestMemReq) {\n-            throw new InvalidTopologyException(\n-                \"Topology will not be able to be successfully scheduled: Config \"\n-                + \"TOPOLOGY_WORKER_MAX_HEAP_SIZE_MB=\"\n-                + topologyWorkerMaxHeapSize\n-                + \" < \" + largestMemReq + \" (Largest memory requirement of a component in the topology).\"\n-                + \" Perhaps set TOPOLOGY_WORKER_MAX_HEAP_SIZE_MB to a larger amount\");\n-        }\n-    }\n-\n-    private static double getMaxExecutorMemoryUsageForTopo(\n-        StormTopology topology, Map<String, Object> topologyConf) {\n-        double largestMemoryOperator = 0.0;\n-        for (NormalizedResourceRequest entry :\n-            ResourceUtils.getBoltsResources(topology, topologyConf).values()) {\n-            double memoryRequirement = entry.getTotalMemoryMb();\n-            if (memoryRequirement > largestMemoryOperator) {\n-                largestMemoryOperator = memoryRequirement;\n-            }\n-        }\n-        for (NormalizedResourceRequest entry :\n-            ResourceUtils.getSpoutsResources(topology, topologyConf).values()) {\n-            double memoryRequirement = entry.getTotalMemoryMb();\n-            if (memoryRequirement > largestMemoryOperator) {\n-                largestMemoryOperator = memoryRequirement;\n-            }\n-        }\n-        return largestMemoryOperator;\n-    }\n-\n     Map<String, Object> getConf() {\n         return conf;\n     }\n@@ -1725,10 +1756,10 @@ public class Nimbus implements Iface, Shutdownable, DaemonCommon {\n \n     private Set<List<Integer>> getOrUpdateExecutors(String topoId, StormBase base, Map<String, Object> topoConf,\n                                                     StormTopology topology)\n-        throws IOException, AuthorizationException, InvalidTopologyException, KeyNotFoundException {\n+        throws InvalidTopologyException {\n         Set<List<Integer>> executors = idToExecutors.get().get(topoId);\n         if (null == executors) {\n-            executors = new HashSet<>(computeExecutors(topoId, base, topoConf, topology));\n+            executors = new HashSet<>(computeExecutors(base, topoConf, topology));\n             idToExecutors.getAndUpdate(new Assoc<>(topoId, executors));\n         }\n         return executors;\n@@ -1941,8 +1972,12 @@ public class Nimbus implements Iface, Shutdownable, DaemonCommon {\n \n     private TopologyDetails readTopologyDetails(String topoId, StormBase base) throws KeyNotFoundException,\n         AuthorizationException, IOException, InvalidTopologyException {\n-        assert (base != null);\n-        assert (topoId != null);\n+        if (base == null) {\n+            throw new InvalidTopologyException(\"Cannot readTopologyDetails: StormBase parameter value is null\");\n+        }\n+        if (topoId == null) {\n+            throw new InvalidTopologyException(\"Cannot readTopologyDetails: topoId parameter value is null\");\n+        }\n \n         Map<String, Object> topoConf = readTopoConfAsNimbus(topoId, topoCache);\n         StormTopology topo = readStormTopologyAsNimbus(topoId, topoCache);\n@@ -2038,10 +2073,13 @@ public class Nimbus implements Iface, Shutdownable, DaemonCommon {\n         return heartbeatsCache.getAliveExecutors(topoId, allExecutors, assignment, getTopologyLaunchHeartbeatTimeoutSec(topoId));\n     }\n \n-    private List<List<Integer>> computeExecutors(String topoId, StormBase base, Map<String, Object> topoConf,\n+    private List<List<Integer>> computeExecutors(StormBase base, Map<String, Object> topoConf,\n                                                  StormTopology topology)\n-        throws KeyNotFoundException, AuthorizationException, IOException, InvalidTopologyException {\n-        assert (base != null);\n+        throws InvalidTopologyException {\n+\n+        if (base == null) {\n+            throw new InvalidTopologyException(\"Cannot computeExecutors: StormBase parameter value is null\");\n+        }\n \n         Map<String, Integer> compToExecutors = base.get_component_executors();\n         List<List<Integer>> ret = new ArrayList<>();\n@@ -2049,11 +2087,12 @@ public class Nimbus implements Iface, Shutdownable, DaemonCommon {\n             Map<Integer, String> taskInfo = StormCommon.stormTaskInfo(topology, topoConf);\n             Map<String, List<Integer>> compToTaskList = Utils.reverseMap(taskInfo);\n             for (Entry<String, List<Integer>> entry : compToTaskList.entrySet()) {\n-                List<Integer> comps = entry.getValue();\n-                comps.sort(null);\n-                Integer numExecutors = compToExecutors.get(entry.getKey());\n+                String compId = entry.getKey();\n+                List<Integer> tasks = entry.getValue();\n+                tasks.sort(null);\n+                Integer numExecutors = compToExecutors.get(compId);\n                 if (numExecutors != null) {\n-                    List<List<Integer>> partitioned = Utils.partitionFixed(numExecutors, comps);\n+                    List<List<Integer>> partitioned = Utils.partitionFixed(numExecutors, tasks);\n                     for (List<Integer> partition : partitioned) {\n                         ret.add(Arrays.asList(partition.get(0), partition.get(partition.size() - 1)));\n                     }\n@@ -2065,7 +2104,7 @@ public class Nimbus implements Iface, Shutdownable, DaemonCommon {\n \n     private Map<List<Integer>, String> computeExecutorToComponent(String topoId, StormBase base,\n                                                                   Map<String, Object> topoConf, StormTopology topology)\n-        throws KeyNotFoundException, AuthorizationException, InvalidTopologyException, IOException {\n+        throws InvalidTopologyException {\n         List<List<Integer>> executors = new ArrayList<>(getOrUpdateExecutors(topoId, base, topoConf, topology));\n         Map<Integer, String> taskToComponent = StormCommon.stormTaskInfo(topology, topoConf);\n         Map<List<Integer>, String> ret = new HashMap<>();\n@@ -2303,10 +2342,10 @@ public class Nimbus implements Iface, Shutdownable, DaemonCommon {\n         scheduler.schedule(topologies, cluster);\n         //Get and set the start time before getting current time in order to avoid potential race with the longest-scheduling-time-ms gauge\n         final Long startTime = schedulingStartTimeNs.getAndSet(null);\n-        long elapsed = Time.nanoTime() - startTime;\n-        longestSchedulingTime.accumulateAndGet(elapsed, Math::max);\n-        schedulingDuration.update(elapsed, TimeUnit.NANOSECONDS);\n-        LOG.debug(\"Scheduling took {} ms for {} topologies\", elapsed, topologies.getTopologies().size());\n+        long elapsedNs = Time.nanoTime() - startTime;\n+        longestSchedulingTime.accumulateAndGet(elapsedNs, Math::max);\n+        schedulingDuration.update(elapsedNs, TimeUnit.NANOSECONDS);\n+        LOG.debug(\"Scheduling took {} ms for {} topologies\", TimeUnit.NANOSECONDS.toMillis(elapsedNs), topologies.getTopologies().size());\n \n         //merge with existing statuses\n         idToSchedStatus.set(Utils.merge(idToSchedStatus.get(), cluster.getStatusMap()));\n@@ -2634,9 +2673,12 @@ public class Nimbus implements Iface, Shutdownable, DaemonCommon {\n         try {\n             Map<String, Object> topoConf = tryReadTopoConf(topoId, topoCache);\n             return getTopologyHeartbeatTimeoutSecs(topoConf);\n+        } catch (NotAliveException e) {\n+            // no log here to avoid flooding nimbus logs\n+            return ObjectReader.getInt(conf.get(DaemonConfig.NIMBUS_TASK_TIMEOUT_SECS));\n         } catch (Exception e) {\n             // contain any exception\n-            LOG.warn(\"Exception when getting heartbeat timeout.\", e.getMessage());\n+            LOG.warn(\"Exception when getting heartbeat timeout\", e);\n             return ObjectReader.getInt(conf.get(DaemonConfig.NIMBUS_TASK_TIMEOUT_SECS));\n         }\n     }\n@@ -2649,8 +2691,10 @@ public class Nimbus implements Iface, Shutdownable, DaemonCommon {\n \n     private void startTopology(String topoName, String topoId, TopologyStatus initStatus, String owner,\n                                String principal, Map<String, Object> topoConf, StormTopology stormTopology)\n-        throws KeyNotFoundException, AuthorizationException, IOException, InvalidTopologyException {\n-        assert (TopologyStatus.ACTIVE == initStatus || TopologyStatus.INACTIVE == initStatus);\n+        throws InvalidTopologyException {\n+        if (TopologyStatus.ACTIVE != initStatus && TopologyStatus.INACTIVE != initStatus) {\n+            throw new InvalidTopologyException(\"Cannot startTopology: initStatus should be ACTIVE or INACTIVE, not \" + initStatus.name());\n+        }\n         Map<String, Integer> numExecutors = new HashMap<>();\n         StormTopology topology = StormCommon.systemTopology(topoConf, stormTopology);\n         for (Entry<String, Object> entry : StormCommon.allComponents(topology).entrySet()) {\n@@ -2672,7 +2716,7 @@ public class Nimbus implements Iface, Shutdownable, DaemonCommon {\n         IStormClusterState state = stormClusterState;\n         state.activateStorm(topoId, base, topoConf);\n         idToExecutors.getAndUpdate(new Assoc<>(topoId,\n-            new HashSet<>(computeExecutors(topoId, base, topoConf, stormTopology))));\n+            new HashSet<>(computeExecutors(base, topoConf, stormTopology))));\n         notifyTopologyActionListener(topoName, \"activate\");\n     }\n \n@@ -2812,18 +2856,21 @@ public class Nimbus implements Iface, Shutdownable, DaemonCommon {\n         Utils.forceDelete(ServerConfigUtils.masterStormDistRoot(conf, topoId));\n     }\n \n+    /**\n+     * Cleanup topologies and Jars.\n+     */\n     @VisibleForTesting\n-    public void doCleanup() throws Exception {\n-        if (!isLeader()) {\n-            LOG.info(\"not a leader, skipping cleanup\");\n-            return;\n-        }\n-        IStormClusterState state = stormClusterState;\n-        Set<String> toClean;\n-        synchronized (submitLock) {\n-            toClean = topoIdsToClean(state, blobStore, this.conf);\n-        }\n-        if (toClean != null) {\n+    public void doCleanup() {\n+        try {\n+            if (!isLeader()) {\n+                LOG.info(\"not a leader, skipping cleanup\");\n+                return;\n+            }\n+            IStormClusterState state = stormClusterState;\n+            long cleanupStartMs = Time.currentTimeMillis();\n+            Set<String> toClean = new HashSet<>(topoIdsToClean(state, blobStore, this.conf));\n+            long topoIdSelectionDurationMs = Time.deltaMs(cleanupStartMs);\n+\n             for (String topoId : toClean) {\n                 LOG.info(\"Cleaning up {}\", topoId);\n                 state.teardownHeartbeats(topoId);\n@@ -2836,6 +2883,14 @@ public class Nimbus implements Iface, Shutdownable, DaemonCommon {\n                 heartbeatsCache.removeTopo(topoId);\n                 idToExecutors.getAndUpdate(new Dissoc<>(topoId));\n             }\n+\n+            long cleanupDurationMs = Time.deltaMs(cleanupStartMs);\n+            if (cleanupDurationMs > 10000) {\n+                LOG.warn(\"doCleanup is taking too long, topoIdSelectionDurationMs={}, cleanupDurationMs={}\",\n+                    topoIdSelectionDurationMs, cleanupDurationMs);\n+            }\n+        } catch (Exception ex) {\n+            LOG.error(\"Ignoring error in doCleanup()\", ex);\n         }\n     }\n \n@@ -3157,7 +3212,9 @@ public class Nimbus implements Iface, Shutdownable, DaemonCommon {\n         try {\n             submitTopologyWithOptsCalls.mark();\n             assertIsLeader();\n-            assert (options != null);\n+            if (options == null) {\n+                throw new InvalidTopologyException(\"Cannot submitTopologyWithOpts: SubmitOptions parameter value is null\");\n+            }\n             validateTopologyName(topoName);\n             checkAuthorization(topoName, null, \"submitTopology\");\n             assertTopoActive(topoName, false);\n@@ -3177,7 +3234,7 @@ public class Nimbus implements Iface, Shutdownable, DaemonCommon {\n                                                        + Config.TOPOLOGY_BLOBSTORE_MAP + \" = \" + blobMap);\n                 }\n             }\n-            validateTopologyWorkerMaxHeapSizeConfigs(topoConf, topology,\n+            ServerUtils.validateTopologyWorkerMaxHeapSizeConfigs(topoConf, topology,\n                                                      ObjectReader.getDouble(conf.get(Config.TOPOLOGY_WORKER_MAX_HEAP_SIZE_MB)));\n             Utils.validateTopologyBlobStoreMap(topoConf, blobStore);\n             long uniqueNum = submittedCount.incrementAndGet();\n@@ -3240,14 +3297,15 @@ public class Nimbus implements Iface, Shutdownable, DaemonCommon {\n             // we might need to set the number of acker executors and eventlogger executors to be the estimated number of workers.\n             if (ServerUtils.isRas(conf)) {\n                 int estimatedNumWorker = ServerUtils.getEstimatedWorkerCountForRasTopo(totalConf, topology);\n-                int numAckerExecs = ObjectReader.getInt(totalConf.get(Config.TOPOLOGY_ACKER_EXECUTORS), estimatedNumWorker);\n-                int numEventLoggerExecs = ObjectReader.getInt(totalConf.get(Config.TOPOLOGY_EVENTLOGGER_EXECUTORS), estimatedNumWorker);\n \n-                totalConfToSave.put(Config.TOPOLOGY_ACKER_EXECUTORS, numAckerExecs);\n+                setUpAckerExecutorConfigs(topoName, totalConfToSave, totalConf, estimatedNumWorker);\n+                ServerUtils.validateTopologyAckerBundleResource(totalConfToSave, topology, topoName);\n+\n+                int numEventLoggerExecs = ObjectReader.getInt(totalConf.get(Config.TOPOLOGY_EVENTLOGGER_EXECUTORS), estimatedNumWorker);\n                 totalConfToSave.put(Config.TOPOLOGY_EVENTLOGGER_EXECUTORS, numEventLoggerExecs);\n+                LOG.debug(\"Config {} set to: {} for topology: {}\",\n+                    Config.TOPOLOGY_EVENTLOGGER_EXECUTORS, numEventLoggerExecs, topoName);\n \n-                LOG.debug(\"{} set to: {}\", Config.TOPOLOGY_ACKER_EXECUTORS, numAckerExecs);\n-                LOG.debug(\"{} set to: {}\", Config.TOPOLOGY_EVENTLOGGER_EXECUTORS, numEventLoggerExecs);\n             }\n \n             //Remove any configs that are specific to a host that might mess with the running topology.\n@@ -3320,6 +3378,36 @@ public class Nimbus implements Iface, Shutdownable, DaemonCommon {\n         }\n     }\n \n+    @VisibleForTesting\n+    public static void setUpAckerExecutorConfigs(String topoName, Map<String, Object> totalConfToSave,\n+                                                 Map<String, Object> totalConf, int estimatedNumWorker) {\n+\n+        int numAckerExecs;\n+        int numAckerExecsPerWorker;\n+\n+        if (totalConf.get(Config.TOPOLOGY_ACKER_EXECUTORS) == null) {\n+            numAckerExecsPerWorker = ObjectReader.getInt(\n+                totalConf.get(Config.TOPOLOGY_RAS_ACKER_EXECUTORS_PER_WORKER));\n+            numAckerExecs = estimatedNumWorker * numAckerExecsPerWorker;\n+        } else {\n+            numAckerExecs = ObjectReader.getInt(totalConf.get(Config.TOPOLOGY_ACKER_EXECUTORS));\n+            if (estimatedNumWorker == 0) {\n+                numAckerExecsPerWorker = 0;\n+            } else {\n+                numAckerExecsPerWorker = (int) Math.ceil((double) numAckerExecs / (double) estimatedNumWorker);\n+            }\n+        }\n+\n+        totalConfToSave.put(Config.TOPOLOGY_RAS_ACKER_EXECUTORS_PER_WORKER, numAckerExecsPerWorker);\n+        totalConfToSave.put(Config.TOPOLOGY_ACKER_EXECUTORS, numAckerExecs);\n+\n+        LOG.info(\"Config {} set to: {} for topology: {}\",\n+            Config.TOPOLOGY_RAS_ACKER_EXECUTORS_PER_WORKER, numAckerExecsPerWorker, topoName);\n+        LOG.info(\"Config {} set to: {} for topology: {}\",\n+            Config.TOPOLOGY_ACKER_EXECUTORS, numAckerExecs, topoName);\n+\n+    }\n+\n     @Override\n     public void killTopology(String name) throws NotAliveException, AuthorizationException, TException {\n         killTopologyCalls.mark();\n@@ -3602,12 +3690,14 @@ public class Nimbus implements Iface, Shutdownable, DaemonCommon {\n         try {\n             getComponentPendingProfileActionsCalls.mark();\n             CommonTopoInfo info = getCommonTopoInfo(id, \"getComponentPendingProfileActions\");\n-            Map<String, String> nodeToHost = info.assignment.get_node_host();\n             Map<List<? extends Number>, List<Object>> exec2hostPort = new HashMap<>();\n-            for (Entry<List<Long>, NodeInfo> entry : info.assignment.get_executor_node_port().entrySet()) {\n-                NodeInfo ni = entry.getValue();\n-                List<Object> hostPort = Arrays.asList(nodeToHost.get(ni.get_node()), ni.get_port_iterator().next().intValue());\n-                exec2hostPort.put(entry.getKey(), hostPort);\n+            if (info.assignment != null) {\n+                Map<String, String> nodeToHost = info.assignment.get_node_host();\n+                for (Entry<List<Long>, NodeInfo> entry : info.assignment.get_executor_node_port().entrySet()) {\n+                    NodeInfo ni = entry.getValue();\n+                    List<Object> hostPort = Arrays.asList(nodeToHost.get(ni.get_node()), ni.get_port_iterator().next().intValue());\n+                    exec2hostPort.put(entry.getKey(), hostPort);\n+                }\n             }\n             List<Map<String, Object>> nodeInfos =\n                 StatsUtil.extractNodeInfosFromHbForComp(exec2hostPort, info.taskToComponent, false, componentId);\n@@ -3768,6 +3858,7 @@ public class Nimbus implements Iface, Shutdownable, DaemonCommon {\n             os.close();\n             LOG.info(\"Finished uploading blob for session {}. Closing session.\", session);\n             blobUploaders.remove(session);\n+            blobStore.updateLastBlobUpdateTime();\n         } catch (Exception e) {\n             LOG.warn(\"finish blob upload exception.\", e);\n             if (e instanceof TException) {\n@@ -3815,6 +3906,7 @@ public class Nimbus implements Iface, Shutdownable, DaemonCommon {\n         throws AuthorizationException, KeyNotFoundException, TException {\n         try {\n             blobStore.setBlobMeta(key, meta, getSubject());\n+            blobStore.updateLastBlobUpdateTime();\n         } catch (Exception e) {\n             LOG.warn(\"set blob meta exception.\", e);\n             if (e instanceof TException) {\n@@ -3885,8 +3977,14 @@ public class Nimbus implements Iface, Shutdownable, DaemonCommon {\n                     throw new WrappedIllegalStateException(message);\n                 }\n             }\n+            String topoId = topologyUsingThisBlob(stormClusterState, topoCache,  key);\n+            if (topoId != null) {\n+                String message = \"Attempting to delete active blob \" + key + \" used by topology \" + topoId;\n+                LOG.warn(message);\n+                throw new WrappedIllegalStateException(message);\n+            }\n             blobStore.deleteBlob(key, getSubject());\n-            LOG.info(\"Deleted blob for key {}\", key);\n+            LOG.info(\"Deleted blob for key {} with {}\", key, ReqContext.context());\n         } catch (Exception e) {\n             LOG.warn(\"delete blob exception.\", e);\n             if (e instanceof TException) {\n@@ -3955,7 +4053,9 @@ public class Nimbus implements Iface, Shutdownable, DaemonCommon {\n     public int updateBlobReplication(String key, int replication)\n         throws AuthorizationException, KeyNotFoundException, TException {\n         try {\n-            return blobStore.updateBlobReplication(key, replication, getSubject());\n+            int result = blobStore.updateBlobReplication(key, replication, getSubject());\n+            blobStore.updateLastBlobUpdateTime();\n+            return result;\n         } catch (Exception e) {\n             LOG.warn(\"update blob replication exception.\", e);\n             if (e instanceof TException) {\n@@ -4038,6 +4138,7 @@ public class Nimbus implements Iface, Shutdownable, DaemonCommon {\n             channel.close();\n             LOG.info(\"Finished uploading file from client: {}\", location);\n             uploaders.remove(location);\n+            blobStore.updateLastBlobUpdateTime();\n         } catch (Exception e) {\n             LOG.warn(\"finish file upload exception.\", e);\n             if (e instanceof TException) {\n@@ -5019,6 +5120,7 @@ public class Nimbus implements Iface, Shutdownable, DaemonCommon {\n         try {\n             LOG.info(\"Shutting down master\");\n             timer.close();\n+            cleanupTimer.close();\n             stormClusterState.disconnect();\n             downloaders.cleanup();\n             uploaders.cleanup();\n@@ -5238,10 +5340,12 @@ public class Nimbus implements Iface, Shutdownable, DaemonCommon {\n         ClusterSummaryMetricSet(StormMetricsRegistry metricsRegistry) {\n             this.metricsRegistry = metricsRegistry;\n             //Break the code if out of sync to thrift protocol\n-            assert ClusterSummary._Fields.values().length == 3\n-                && ClusterSummary._Fields.findByName(\"supervisors\") == ClusterSummary._Fields.SUPERVISORS\n-                && ClusterSummary._Fields.findByName(\"topologies\") == ClusterSummary._Fields.TOPOLOGIES\n-                && ClusterSummary._Fields.findByName(\"nimbuses\") == ClusterSummary._Fields.NIMBUSES;\n+            if (ClusterSummary._Fields.values().length != 3\n+                    || ClusterSummary._Fields.findByName(\"supervisors\") != ClusterSummary._Fields.SUPERVISORS\n+                    || ClusterSummary._Fields.findByName(\"topologies\") != ClusterSummary._Fields.TOPOLOGIES\n+                    || ClusterSummary._Fields.findByName(\"nimbuses\") != ClusterSummary._Fields.NIMBUSES) {\n+                throw new AssertionError(\"Out of sync with thrift protocol\");\n+            }\n \n             final CachedGauge<ClusterSummary> cachedSummary = new CachedGauge<ClusterSummary>(CACHING_WINDOW, TimeUnit.SECONDS) {\n                 @Override\n",
            "security_relevancy": "potentially_security_relevant"
        },
        {
            "diff": "@@ -12,6 +12,11 @@\n \n package org.apache.storm.security.auth.authorizer;\n \n+import java.io.BufferedWriter;\n+import java.io.File;\n+import java.io.FileWriter;\n+import java.io.IOException;\n+import java.nio.file.Files;\n import java.util.HashMap;\n import java.util.Map;\n import org.apache.storm.Config;\n@@ -20,11 +25,15 @@ import org.apache.storm.security.auth.KerberosPrincipalToLocal;\n import org.apache.storm.security.auth.ReqContext;\n import org.apache.storm.security.auth.SingleUserPrincipal;\n import org.apache.storm.shade.com.google.common.collect.ImmutableMap;\n-import org.junit.Assert;\n-import org.junit.BeforeClass;\n-import org.junit.Test;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Test;\n import org.mockito.Mockito;\n \n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+\n public class DRPCSimpleACLAuthorizerTest {\n \n     private static final String function = \"jump\";\n@@ -38,7 +47,7 @@ public class DRPCSimpleACLAuthorizerTest {\n     private static IAuthorizer strictHandler;\n     private static IAuthorizer permissiveHandler;\n \n-    @BeforeClass\n+    @BeforeAll\n     public static void setup() {\n         strictHandler = new DRPCSimpleACLAuthorizer();\n         strictHandler.prepare(ImmutableMap\n@@ -60,102 +69,143 @@ public class DRPCSimpleACLAuthorizerTest {\n     @Test\n     public void test_partial_authorization() {\n \n-        Assert.assertFalse(\"Deny execute to unauthroized user\",\n-                           isPermitted(strictHandler, ReqContext.context(), \"execute\", partialFunction));\n+        assertFalse(isPermitted(strictHandler, ReqContext.context(), \"execute\", partialFunction),\n+            \"Did not deny execute to unauthorized user\");\n \n-        Assert.assertTrue(\"Allow execute to authorized kerb user for correct function\",\n-                          isPermitted(strictHandler, aliceKerbContext, \"execute\", partialFunction));\n+        assertTrue(isPermitted(strictHandler, aliceKerbContext, \"execute\", partialFunction),\n+            \"Did not allow execute to authorized kerb user for correct function\");\n \n-        Assert.assertFalse(\"Deny fetchRequest to unauthorized user for correct function\",\n-                           isPermitted(strictHandler, aliceKerbContext, \"fetchRequest\", partialFunction));\n+        assertFalse(isPermitted(strictHandler, aliceKerbContext, \"fetchRequest\", partialFunction),\n+            \"Did not deny fetchRequest to unauthorized user for correct function\");\n     }\n \n     @Test\n     public void test_client_authorization_strict() {\n \n-        Assert.assertFalse(\"Deny execute to unauthroized user\",\n-                           isPermitted(strictHandler, ReqContext.context(), \"execute\", function));\n+        assertFalse(isPermitted(strictHandler, ReqContext.context(), \"execute\", function),\n+            \"Did not deny execute to unauthorized user\");\n \n-        Assert.assertFalse(\"Deny execute to valid user for incorrect function\",\n-                           isPermitted(strictHandler, aliceContext, \"execute\", wrongFunction));\n+        assertFalse(isPermitted(strictHandler, aliceContext, \"execute\", wrongFunction),\n+            \"Did not deny execute to valid user for incorrect function\");\n \n-        Assert.assertTrue(\"Allow execute to authorized kerb user for correct function\",\n-                          isPermitted(strictHandler, aliceKerbContext, \"execute\", function));\n+        assertTrue(isPermitted(strictHandler, aliceKerbContext, \"execute\", function),\n+            \"Did not allow execute to authorized kerb user for correct function\");\n \n-        Assert.assertTrue(\"Allow execute to authorized user for correct function\",\n-                          isPermitted(strictHandler, aliceContext, \"execute\", function));\n+        assertTrue(isPermitted(strictHandler, aliceContext, \"execute\", function),\n+            \"Did not allow execute to authorized user for correct function\");\n     }\n \n     @Test\n     public void test_client_authorization_permissive() {\n \n-        Assert.assertFalse(\"deny execute to unauthorized user for correct function\",\n-                           isPermitted(permissiveHandler, ReqContext.context(), \"execute\", function));\n+        assertFalse(isPermitted(permissiveHandler, ReqContext.context(), \"execute\", function),\n+            \"Did not deny execute to unauthorized user for correct function\");\n \n-        Assert.assertTrue(\"allow execute for user for incorrect function when permissive\",\n-                          isPermitted(permissiveHandler, aliceContext, \"execute\", wrongFunction));\n+        assertTrue(isPermitted(permissiveHandler, aliceContext, \"execute\", wrongFunction),\n+            \"Did not allow execute for user for incorrect function when permissive\");\n \n-        Assert.assertTrue(\"allow execute for user for incorrect function when permissive\",\n-                          isPermitted(permissiveHandler, aliceKerbContext, \"execute\", wrongFunction));\n+        assertTrue(isPermitted(permissiveHandler, aliceKerbContext, \"execute\", wrongFunction),\n+            \"Did not allow execute for user for incorrect function when permissive\");\n \n-        Assert.assertTrue(\"allow execute to authorized user for correct function\",\n-                          isPermitted(permissiveHandler, bobContext, \"execute\", function));\n+        assertTrue(isPermitted(permissiveHandler, bobContext, \"execute\", function),\n+            \"Did not allow execute to authorized user for correct function\");\n     }\n \n     @Test\n     public void test_invocation_authorization_strict() {\n         for (String operation : new String[]{ \"fetchRequest\", \"failRequest\", \"result\" }) {\n-            Assert.assertFalse(\"Deny \" + operation + \" to unauthorized user for correct function\",\n-                               isPermitted(strictHandler, aliceContext, operation, function));\n+            assertFalse(isPermitted(strictHandler, aliceContext, operation, function),\n+                \"Did not deny \" + operation + \" to unauthorized user for correct function\");\n \n-            Assert.assertFalse(\"Deny \" + operation + \" to user for incorrect function when strict\",\n-                               isPermitted(strictHandler, charlieContext, operation, wrongFunction));\n+            assertFalse(isPermitted(strictHandler, charlieContext, operation, wrongFunction),\n+                \"Did not deny \" + operation + \" to user for incorrect function when strict\");\n \n-            Assert.assertTrue(\"allow \" + operation + \" to authorized user for correct function\",\n-                              isPermitted(strictHandler, charlieContext, operation, function));\n+            assertTrue(isPermitted(strictHandler, charlieContext, operation, function),\n+                \"Did not allow \" + operation + \" to authorized user for correct function\");\n         }\n     }\n \n     @Test\n     public void test_invocation_authorization_permissive() {\n         for (String operation : new String[]{ \"fetchRequest\", \"failRequest\", \"result\" }) {\n-            Assert.assertFalse(\"Deny \" + operation + \" to unauthorized user for correct function\",\n-                               isPermitted(permissiveHandler, bobContext, operation, function));\n+            assertFalse(isPermitted(permissiveHandler, bobContext, operation, function),\n+                \"Did not deny \" + operation + \" to unauthorized user for correct function\");\n \n-            Assert.assertTrue(\"Allow \" + operation + \" to user for incorrect function when permissive\",\n-                              isPermitted(permissiveHandler, charlieContext, operation, wrongFunction));\n+            assertTrue(isPermitted(permissiveHandler, charlieContext, operation, wrongFunction),\n+                \"Did not allow \" + operation + \" to user for incorrect function when permissive\");\n \n-            Assert.assertTrue(\"allow \" + operation + \" to authorized user\",\n-                              isPermitted(permissiveHandler, charlieContext, operation, function));\n+            assertTrue(isPermitted(permissiveHandler, charlieContext, operation, function),\n+                \"Did not allow \" + operation + \" to authorized user\");\n         }\n     }\n \n     @Test\n     public void test_deny_when_no_function_given() {\n-        Assert.assertFalse(strictHandler.permit(aliceContext, \"execute\", new HashMap()));\n+        assertFalse(strictHandler.permit(aliceContext, \"execute\", new HashMap<>()));\n \n-        Assert.assertFalse(isPermitted(strictHandler, aliceContext, \"execute\", null));\n+        assertFalse(isPermitted(strictHandler, aliceContext, \"execute\", null));\n \n-        Assert.assertFalse(permissiveHandler.permit(bobContext, \"execute\", new HashMap()));\n+        assertFalse(permissiveHandler.permit(bobContext, \"execute\", new HashMap<>()));\n \n-        Assert.assertFalse(isPermitted(permissiveHandler, bobContext, \"execute\", null));\n+        assertFalse(isPermitted(permissiveHandler, bobContext, \"execute\", null));\n     }\n \n     @Test\n     public void test_deny_when_invalid_user_given() {\n-        Assert.assertFalse(isPermitted(strictHandler, Mockito.mock(ReqContext.class), \"execute\", function));\n+        assertFalse(isPermitted(strictHandler, Mockito.mock(ReqContext.class), \"execute\", function));\n \n-        Assert.assertFalse(isPermitted(strictHandler, null, \"execute\", function));\n+        assertFalse(isPermitted(strictHandler, null, \"execute\", function));\n \n-        Assert.assertFalse(isPermitted(permissiveHandler, Mockito.mock(ReqContext.class), \"execute\", function));\n+        assertFalse(isPermitted(permissiveHandler, Mockito.mock(ReqContext.class), \"execute\", function));\n \n-        Assert.assertFalse(isPermitted(permissiveHandler, null, \"execute\", function));\n+        assertFalse(isPermitted(permissiveHandler, null, \"execute\", function));\n \n     }\n \n     private boolean isPermitted(IAuthorizer authorizer, ReqContext context, String operation, String function) {\n-        Map<String, Object> config = new HashMap();\n+        Map<String, Object> config = new HashMap<>();\n         config.put(DRPCSimpleACLAuthorizer.FUNCTION_KEY, function);\n         return authorizer.permit(context, operation, config);\n     }\n+\n+    /**\n+     * {@link DRPCSimpleACLAuthorizer} should still work even if {@link Config#DRPC_AUTHORIZER_ACL} has no values.\n+     * @throws IOException if there is any issue with creating or writing the temp file.\n+     */\n+    @Test\n+    public void test_read_acl_no_values() throws IOException {\n+        DRPCSimpleACLAuthorizer authorizer = new DRPCSimpleACLAuthorizer();\n+\n+        File tempFile = Files.createTempFile(\"drpcacl\", \".yaml\").toFile();\n+        tempFile.deleteOnExit();\n+        BufferedWriter writer = new BufferedWriter(new FileWriter(tempFile));\n+        writer.write(\"drpc.authorizer.acl:\");\n+        writer.close();\n+\n+        authorizer.prepare(ImmutableMap\n+                .of(Config.DRPC_AUTHORIZER_ACL_STRICT, true, Config.DRPC_AUTHORIZER_ACL_FILENAME, tempFile.toString(),\n+                        Config.STORM_PRINCIPAL_TO_LOCAL_PLUGIN, KerberosPrincipalToLocal.class.getName()));\n+\n+        Map<String, DRPCSimpleACLAuthorizer.AclFunctionEntry> acl = authorizer.readAclFromConfig();\n+        assertEquals(0, acl.size());\n+    }\n+\n+    /**\n+     * The file of {@link Config#DRPC_AUTHORIZER_ACL_FILENAME} can not be empty.\n+     * @throws IOException if there is any issue with creating the temp file.\n+     */\n+    @Test\n+    public void test_read_acl_empty_file() throws IOException {\n+        DRPCSimpleACLAuthorizer authorizer = new DRPCSimpleACLAuthorizer();\n+\n+        File tempFile = Files.createTempFile(\"drpcacl\", \".yaml\").toFile();\n+        tempFile.deleteOnExit();\n+\n+        authorizer.prepare(ImmutableMap\n+                .of(Config.DRPC_AUTHORIZER_ACL_STRICT, true, Config.DRPC_AUTHORIZER_ACL_FILENAME, tempFile.toString(),\n+                        Config.STORM_PRINCIPAL_TO_LOCAL_PLUGIN, KerberosPrincipalToLocal.class.getName()));\n+\n+        Exception exception = assertThrows(RuntimeException.class, authorizer::readAclFromConfig);\n+        assertTrue(exception.getMessage().contains(\"doesn't have any valid storm configs\"));\n+    }\n }\n",
            "security_relevancy": "not_security_relevant"
        },
        {
            "diff": "@@ -1,87 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.storm.mongodb.trident;\n-\n-import org.apache.storm.Config;\n-import org.apache.storm.StormSubmitter;\n-import org.apache.storm.generated.StormTopology;\n-import org.apache.storm.mongodb.common.mapper.MongoMapper;\n-import org.apache.storm.mongodb.common.mapper.SimpleMongoMapper;\n-import org.apache.storm.mongodb.trident.state.MongoState;\n-import org.apache.storm.mongodb.trident.state.MongoStateFactory;\n-import org.apache.storm.mongodb.trident.state.MongoStateQuery;\n-import org.apache.storm.mongodb.trident.state.MongoStateUpdater;\n-import org.apache.storm.trident.Stream;\n-import org.apache.storm.trident.TridentState;\n-import org.apache.storm.trident.TridentTopology;\n-import org.apache.storm.trident.state.StateFactory;\n-import org.apache.storm.trident.testing.FixedBatchSpout;\n-import org.apache.storm.tuple.Fields;\n-import org.apache.storm.tuple.Values;\n-\n-public class WordCountTrident {\n-\n-    public static StormTopology buildTopology(String url, String collectionName) {\n-        Fields fields = new Fields(\"word\", \"count\");\n-        FixedBatchSpout spout = new FixedBatchSpout(fields, 4,\n-                new Values(\"storm\", 1),\n-                new Values(\"trident\", 1),\n-                new Values(\"needs\", 1),\n-                new Values(\"javadoc\", 1)\n-        );\n-        spout.setCycle(true);\n-\n-        MongoMapper mapper = new SimpleMongoMapper()\n-                .withFields(\"word\", \"count\");\n-\n-        MongoState.Options options = new MongoState.Options()\n-                .withUrl(url)\n-                .withCollectionName(collectionName)\n-                .withMapper(mapper);\n-\n-        StateFactory factory = new MongoStateFactory(options);\n-\n-        TridentTopology topology = new TridentTopology();\n-        Stream stream = topology.newStream(\"spout1\", spout);\n-\n-        stream.partitionPersist(factory, fields,\n-                new MongoStateUpdater(), new Fields());\n-\n-        TridentState state = topology.newStaticState(factory);\n-        stream = stream.stateQuery(state, new Fields(\"word\"),\n-                new MongoStateQuery(), new Fields(\"columnName\", \"columnValue\"));\n-        stream.each(new Fields(\"word\", \"columnValue\"), new PrintFunction(), new Fields());\n-        return topology.build();\n-    }\n-\n-    public static void main(String[] args) throws Exception {\n-        Config conf = new Config();\n-        conf.setMaxSpoutPending(5);\n-        String topoName = \"wordCounter\";\n-        if (args.length == 3) {\n-            topoName = args[2];\n-        } else if (args.length > 3 || args.length < 2) {\n-            System.out.println(\"Usage: WordCountTrident <mongodb url> <mongodb collection> [topology name]\");\n-            return;\n-        }\n-        conf.setNumWorkers(3);\n-        StormSubmitter.submitTopology(topoName, conf, buildTopology(args[0], args[1]));\n-    }\n-\n-}\n",
            "security_relevancy": ""
        },
        {
            "diff": "@@ -16,15 +16,15 @@\n  * limitations under the License.\n  */\n /**\n- * Autogenerated by Thrift Compiler (0.13.0)\n+ * Autogenerated by Thrift Compiler (0.18.1)\n  *\n  * DO NOT EDIT UNLESS YOU ARE SURE THAT YOU KNOW WHAT YOU ARE DOING\n  *  @generated\n  */\n package org.apache.storm.generated;\n \n+@javax.annotation.Generated(value = \"Autogenerated by Thrift Compiler (0.18.1)\")\n @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n-@javax.annotation.Generated(value = \"Autogenerated by Thrift Compiler (0.13.0)\")\n public class Nimbus {\n \n   public interface Iface {\n@@ -300,9 +300,11 @@ public class Nimbus {\n   public static class Client extends org.apache.storm.thrift.TServiceClient implements Iface {\n     public static class Factory implements org.apache.storm.thrift.TServiceClientFactory<Client> {\n       public Factory() {}\n+      @Override\n       public Client getClient(org.apache.storm.thrift.protocol.TProtocol prot) {\n         return new Client(prot);\n       }\n+      @Override\n       public Client getClient(org.apache.storm.thrift.protocol.TProtocol iprot, org.apache.storm.thrift.protocol.TProtocol oprot) {\n         return new Client(iprot, oprot);\n       }\n@@ -317,6 +319,7 @@ public class Nimbus {\n       super(iprot, oprot);\n     }\n \n+    @Override\n     public void submitTopology(java.lang.String name, java.lang.String uploadedJarLocation, java.lang.String jsonConf, StormTopology topology) throws AlreadyAliveException, InvalidTopologyException, AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_submitTopology(name, uploadedJarLocation, jsonConf, topology);\n@@ -349,6 +352,7 @@ public class Nimbus {\n       return;\n     }\n \n+    @Override\n     public void submitTopologyWithOpts(java.lang.String name, java.lang.String uploadedJarLocation, java.lang.String jsonConf, StormTopology topology, SubmitOptions options) throws AlreadyAliveException, InvalidTopologyException, AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_submitTopologyWithOpts(name, uploadedJarLocation, jsonConf, topology, options);\n@@ -382,6 +386,7 @@ public class Nimbus {\n       return;\n     }\n \n+    @Override\n     public void killTopology(java.lang.String name) throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_killTopology(name);\n@@ -408,6 +413,7 @@ public class Nimbus {\n       return;\n     }\n \n+    @Override\n     public void killTopologyWithOpts(java.lang.String name, KillOptions options) throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_killTopologyWithOpts(name, options);\n@@ -435,6 +441,7 @@ public class Nimbus {\n       return;\n     }\n \n+    @Override\n     public void activate(java.lang.String name) throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_activate(name);\n@@ -461,6 +468,7 @@ public class Nimbus {\n       return;\n     }\n \n+    @Override\n     public void deactivate(java.lang.String name) throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_deactivate(name);\n@@ -487,6 +495,7 @@ public class Nimbus {\n       return;\n     }\n \n+    @Override\n     public void rebalance(java.lang.String name, RebalanceOptions options) throws NotAliveException, InvalidTopologyException, AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_rebalance(name, options);\n@@ -517,6 +526,7 @@ public class Nimbus {\n       return;\n     }\n \n+    @Override\n     public void setLogConfig(java.lang.String name, LogConfig config) throws org.apache.storm.thrift.TException\n     {\n       send_setLogConfig(name, config);\n@@ -538,6 +548,7 @@ public class Nimbus {\n       return;\n     }\n \n+    @Override\n     public LogConfig getLogConfig(java.lang.String name) throws org.apache.storm.thrift.TException\n     {\n       send_getLogConfig(name);\n@@ -561,6 +572,7 @@ public class Nimbus {\n       throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getLogConfig failed: unknown result\");\n     }\n \n+    @Override\n     public void debug(java.lang.String name, java.lang.String component, boolean enable, double samplingPercentage) throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_debug(name, component, enable, samplingPercentage);\n@@ -590,6 +602,7 @@ public class Nimbus {\n       return;\n     }\n \n+    @Override\n     public void setWorkerProfiler(java.lang.String id, ProfileRequest profileRequest) throws org.apache.storm.thrift.TException\n     {\n       send_setWorkerProfiler(id, profileRequest);\n@@ -611,6 +624,7 @@ public class Nimbus {\n       return;\n     }\n \n+    @Override\n     public java.util.List<ProfileRequest> getComponentPendingProfileActions(java.lang.String id, java.lang.String component_id, ProfileAction action) throws org.apache.storm.thrift.TException\n     {\n       send_getComponentPendingProfileActions(id, component_id, action);\n@@ -636,6 +650,7 @@ public class Nimbus {\n       throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getComponentPendingProfileActions failed: unknown result\");\n     }\n \n+    @Override\n     public void uploadNewCredentials(java.lang.String name, Credentials creds) throws NotAliveException, InvalidTopologyException, AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_uploadNewCredentials(name, creds);\n@@ -666,6 +681,7 @@ public class Nimbus {\n       return;\n     }\n \n+    @Override\n     public java.lang.String beginCreateBlob(java.lang.String key, SettableBlobMeta meta) throws AuthorizationException, KeyAlreadyExistsException, org.apache.storm.thrift.TException\n     {\n       send_beginCreateBlob(key, meta);\n@@ -696,6 +712,7 @@ public class Nimbus {\n       throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"beginCreateBlob failed: unknown result\");\n     }\n \n+    @Override\n     public java.lang.String beginUpdateBlob(java.lang.String key) throws AuthorizationException, KeyNotFoundException, org.apache.storm.thrift.TException\n     {\n       send_beginUpdateBlob(key);\n@@ -725,6 +742,7 @@ public class Nimbus {\n       throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"beginUpdateBlob failed: unknown result\");\n     }\n \n+    @Override\n     public void uploadBlobChunk(java.lang.String session, java.nio.ByteBuffer chunk) throws AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_uploadBlobChunk(session, chunk);\n@@ -749,6 +767,7 @@ public class Nimbus {\n       return;\n     }\n \n+    @Override\n     public void finishBlobUpload(java.lang.String session) throws AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_finishBlobUpload(session);\n@@ -772,6 +791,7 @@ public class Nimbus {\n       return;\n     }\n \n+    @Override\n     public void cancelBlobUpload(java.lang.String session) throws AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_cancelBlobUpload(session);\n@@ -795,6 +815,7 @@ public class Nimbus {\n       return;\n     }\n \n+    @Override\n     public ReadableBlobMeta getBlobMeta(java.lang.String key) throws AuthorizationException, KeyNotFoundException, org.apache.storm.thrift.TException\n     {\n       send_getBlobMeta(key);\n@@ -824,6 +845,7 @@ public class Nimbus {\n       throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getBlobMeta failed: unknown result\");\n     }\n \n+    @Override\n     public void setBlobMeta(java.lang.String key, SettableBlobMeta meta) throws AuthorizationException, KeyNotFoundException, org.apache.storm.thrift.TException\n     {\n       send_setBlobMeta(key, meta);\n@@ -851,6 +873,7 @@ public class Nimbus {\n       return;\n     }\n \n+    @Override\n     public BeginDownloadResult beginBlobDownload(java.lang.String key) throws AuthorizationException, KeyNotFoundException, org.apache.storm.thrift.TException\n     {\n       send_beginBlobDownload(key);\n@@ -880,6 +903,7 @@ public class Nimbus {\n       throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"beginBlobDownload failed: unknown result\");\n     }\n \n+    @Override\n     public java.nio.ByteBuffer downloadBlobChunk(java.lang.String session) throws AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_downloadBlobChunk(session);\n@@ -906,6 +930,7 @@ public class Nimbus {\n       throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"downloadBlobChunk failed: unknown result\");\n     }\n \n+    @Override\n     public void deleteBlob(java.lang.String key) throws AuthorizationException, KeyNotFoundException, IllegalStateException, org.apache.storm.thrift.TException\n     {\n       send_deleteBlob(key);\n@@ -935,6 +960,7 @@ public class Nimbus {\n       return;\n     }\n \n+    @Override\n     public ListBlobsResult listBlobs(java.lang.String session) throws org.apache.storm.thrift.TException\n     {\n       send_listBlobs(session);\n@@ -958,6 +984,7 @@ public class Nimbus {\n       throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"listBlobs failed: unknown result\");\n     }\n \n+    @Override\n     public int getBlobReplication(java.lang.String key) throws AuthorizationException, KeyNotFoundException, org.apache.storm.thrift.TException\n     {\n       send_getBlobReplication(key);\n@@ -987,6 +1014,7 @@ public class Nimbus {\n       throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getBlobReplication failed: unknown result\");\n     }\n \n+    @Override\n     public int updateBlobReplication(java.lang.String key, int replication) throws AuthorizationException, KeyNotFoundException, org.apache.storm.thrift.TException\n     {\n       send_updateBlobReplication(key, replication);\n@@ -1017,6 +1045,7 @@ public class Nimbus {\n       throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"updateBlobReplication failed: unknown result\");\n     }\n \n+    @Override\n     public void createStateInZookeeper(java.lang.String key) throws org.apache.storm.thrift.TException\n     {\n       send_createStateInZookeeper(key);\n@@ -1037,6 +1066,7 @@ public class Nimbus {\n       return;\n     }\n \n+    @Override\n     public java.lang.String beginFileUpload() throws AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_beginFileUpload();\n@@ -1062,6 +1092,7 @@ public class Nimbus {\n       throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"beginFileUpload failed: unknown result\");\n     }\n \n+    @Override\n     public void uploadChunk(java.lang.String location, java.nio.ByteBuffer chunk) throws AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_uploadChunk(location, chunk);\n@@ -1086,6 +1117,7 @@ public class Nimbus {\n       return;\n     }\n \n+    @Override\n     public void finishFileUpload(java.lang.String location) throws AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_finishFileUpload(location);\n@@ -1109,6 +1141,7 @@ public class Nimbus {\n       return;\n     }\n \n+    @Override\n     public java.nio.ByteBuffer downloadChunk(java.lang.String id) throws AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_downloadChunk(id);\n@@ -1135,6 +1168,7 @@ public class Nimbus {\n       throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"downloadChunk failed: unknown result\");\n     }\n \n+    @Override\n     public java.lang.String getNimbusConf() throws AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_getNimbusConf();\n@@ -1160,6 +1194,7 @@ public class Nimbus {\n       throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getNimbusConf failed: unknown result\");\n     }\n \n+    @Override\n     public ClusterSummary getClusterInfo() throws AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_getClusterInfo();\n@@ -1185,6 +1220,7 @@ public class Nimbus {\n       throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getClusterInfo failed: unknown result\");\n     }\n \n+    @Override\n     public java.util.List<TopologySummary> getTopologySummaries() throws AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_getTopologySummaries();\n@@ -1210,6 +1246,7 @@ public class Nimbus {\n       throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopologySummaries failed: unknown result\");\n     }\n \n+    @Override\n     public TopologySummary getTopologySummaryByName(java.lang.String name) throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_getTopologySummaryByName(name);\n@@ -1239,6 +1276,7 @@ public class Nimbus {\n       throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopologySummaryByName failed: unknown result\");\n     }\n \n+    @Override\n     public TopologySummary getTopologySummary(java.lang.String id) throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_getTopologySummary(id);\n@@ -1268,6 +1306,7 @@ public class Nimbus {\n       throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopologySummary failed: unknown result\");\n     }\n \n+    @Override\n     public NimbusSummary getLeader() throws AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_getLeader();\n@@ -1293,6 +1332,7 @@ public class Nimbus {\n       throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getLeader failed: unknown result\");\n     }\n \n+    @Override\n     public boolean isTopologyNameAllowed(java.lang.String name) throws AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_isTopologyNameAllowed(name);\n@@ -1319,6 +1359,7 @@ public class Nimbus {\n       throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"isTopologyNameAllowed failed: unknown result\");\n     }\n \n+    @Override\n     public TopologyInfo getTopologyInfoByName(java.lang.String name) throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_getTopologyInfoByName(name);\n@@ -1348,6 +1389,7 @@ public class Nimbus {\n       throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopologyInfoByName failed: unknown result\");\n     }\n \n+    @Override\n     public TopologyInfo getTopologyInfo(java.lang.String id) throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_getTopologyInfo(id);\n@@ -1377,6 +1419,7 @@ public class Nimbus {\n       throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopologyInfo failed: unknown result\");\n     }\n \n+    @Override\n     public TopologyInfo getTopologyInfoByNameWithOpts(java.lang.String name, GetInfoOptions options) throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_getTopologyInfoByNameWithOpts(name, options);\n@@ -1407,6 +1450,7 @@ public class Nimbus {\n       throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopologyInfoByNameWithOpts failed: unknown result\");\n     }\n \n+    @Override\n     public TopologyInfo getTopologyInfoWithOpts(java.lang.String id, GetInfoOptions options) throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_getTopologyInfoWithOpts(id, options);\n@@ -1437,6 +1481,7 @@ public class Nimbus {\n       throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopologyInfoWithOpts failed: unknown result\");\n     }\n \n+    @Override\n     public TopologyPageInfo getTopologyPageInfo(java.lang.String id, java.lang.String window, boolean is_include_sys) throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_getTopologyPageInfo(id, window, is_include_sys);\n@@ -1468,6 +1513,7 @@ public class Nimbus {\n       throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopologyPageInfo failed: unknown result\");\n     }\n \n+    @Override\n     public SupervisorPageInfo getSupervisorPageInfo(java.lang.String id, java.lang.String host, boolean is_include_sys) throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_getSupervisorPageInfo(id, host, is_include_sys);\n@@ -1499,6 +1545,7 @@ public class Nimbus {\n       throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getSupervisorPageInfo failed: unknown result\");\n     }\n \n+    @Override\n     public ComponentPageInfo getComponentPageInfo(java.lang.String topology_id, java.lang.String component_id, java.lang.String window, boolean is_include_sys) throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_getComponentPageInfo(topology_id, component_id, window, is_include_sys);\n@@ -1531,6 +1578,7 @@ public class Nimbus {\n       throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getComponentPageInfo failed: unknown result\");\n     }\n \n+    @Override\n     public java.lang.String getTopologyConf(java.lang.String id) throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_getTopologyConf(id);\n@@ -1560,6 +1608,7 @@ public class Nimbus {\n       throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopologyConf failed: unknown result\");\n     }\n \n+    @Override\n     public StormTopology getTopology(java.lang.String id) throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_getTopology(id);\n@@ -1589,6 +1638,7 @@ public class Nimbus {\n       throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopology failed: unknown result\");\n     }\n \n+    @Override\n     public StormTopology getUserTopology(java.lang.String id) throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_getUserTopology(id);\n@@ -1618,6 +1668,7 @@ public class Nimbus {\n       throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getUserTopology failed: unknown result\");\n     }\n \n+    @Override\n     public TopologyHistoryInfo getTopologyHistory(java.lang.String user) throws AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_getTopologyHistory(user);\n@@ -1644,6 +1695,7 @@ public class Nimbus {\n       throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopologyHistory failed: unknown result\");\n     }\n \n+    @Override\n     public java.util.List<OwnerResourceSummary> getOwnerResourceSummaries(java.lang.String owner) throws AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_getOwnerResourceSummaries(owner);\n@@ -1670,6 +1722,7 @@ public class Nimbus {\n       throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getOwnerResourceSummaries failed: unknown result\");\n     }\n \n+    @Override\n     public SupervisorAssignments getSupervisorAssignments(java.lang.String node) throws AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_getSupervisorAssignments(node);\n@@ -1696,6 +1749,7 @@ public class Nimbus {\n       throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getSupervisorAssignments failed: unknown result\");\n     }\n \n+    @Override\n     public void sendSupervisorWorkerHeartbeats(SupervisorWorkerHeartbeats heartbeats) throws AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_sendSupervisorWorkerHeartbeats(heartbeats);\n@@ -1719,6 +1773,7 @@ public class Nimbus {\n       return;\n     }\n \n+    @Override\n     public void sendSupervisorWorkerHeartbeat(SupervisorWorkerHeartbeat heatbeat) throws AuthorizationException, NotAliveException, org.apache.storm.thrift.TException\n     {\n       send_sendSupervisorWorkerHeartbeat(heatbeat);\n@@ -1745,6 +1800,7 @@ public class Nimbus {\n       return;\n     }\n \n+    @Override\n     public void processWorkerMetrics(WorkerMetrics metrics) throws org.apache.storm.thrift.TException\n     {\n       send_processWorkerMetrics(metrics);\n@@ -1765,6 +1821,7 @@ public class Nimbus {\n       return;\n     }\n \n+    @Override\n     public boolean isRemoteBlobExists(java.lang.String blobKey) throws AuthorizationException, org.apache.storm.thrift.TException\n     {\n       send_isRemoteBlobExists(blobKey);\n@@ -1800,6 +1857,7 @@ public class Nimbus {\n         this.clientManager = clientManager;\n         this.protocolFactory = protocolFactory;\n       }\n+    @Override\n       public AsyncClient getAsyncClient(org.apache.storm.thrift.transport.TNonblockingTransport transport) {\n         return new AsyncClient(protocolFactory, clientManager, transport);\n       }\n@@ -1809,6 +1867,7 @@ public class Nimbus {\n       super(protocolFactory, clientManager, transport);\n     }\n \n+    @Override\n     public void submitTopology(java.lang.String name, java.lang.String uploadedJarLocation, java.lang.String jsonConf, StormTopology topology, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       submitTopology_call method_call = new submitTopology_call(name, uploadedJarLocation, jsonConf, topology, resultHandler, this, ___protocolFactory, ___transport);\n@@ -1829,6 +1888,7 @@ public class Nimbus {\n         this.topology = topology;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"submitTopology\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         submitTopology_args args = new submitTopology_args();\n@@ -1840,16 +1900,19 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public Void getResult() throws AlreadyAliveException, InvalidTopologyException, AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n         }\n         org.apache.storm.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.storm.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());\n         org.apache.storm.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);\n+        (new Client(prot)).recv_submitTopology();\n         return null;\n       }\n     }\n \n+    @Override\n     public void submitTopologyWithOpts(java.lang.String name, java.lang.String uploadedJarLocation, java.lang.String jsonConf, StormTopology topology, SubmitOptions options, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       submitTopologyWithOpts_call method_call = new submitTopologyWithOpts_call(name, uploadedJarLocation, jsonConf, topology, options, resultHandler, this, ___protocolFactory, ___transport);\n@@ -1872,6 +1935,7 @@ public class Nimbus {\n         this.options = options;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"submitTopologyWithOpts\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         submitTopologyWithOpts_args args = new submitTopologyWithOpts_args();\n@@ -1884,16 +1948,19 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public Void getResult() throws AlreadyAliveException, InvalidTopologyException, AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n         }\n         org.apache.storm.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.storm.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());\n         org.apache.storm.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);\n+        (new Client(prot)).recv_submitTopologyWithOpts();\n         return null;\n       }\n     }\n \n+    @Override\n     public void killTopology(java.lang.String name, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       killTopology_call method_call = new killTopology_call(name, resultHandler, this, ___protocolFactory, ___transport);\n@@ -1908,6 +1975,7 @@ public class Nimbus {\n         this.name = name;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"killTopology\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         killTopology_args args = new killTopology_args();\n@@ -1916,16 +1984,19 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public Void getResult() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n         }\n         org.apache.storm.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.storm.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());\n         org.apache.storm.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);\n+        (new Client(prot)).recv_killTopology();\n         return null;\n       }\n     }\n \n+    @Override\n     public void killTopologyWithOpts(java.lang.String name, KillOptions options, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       killTopologyWithOpts_call method_call = new killTopologyWithOpts_call(name, options, resultHandler, this, ___protocolFactory, ___transport);\n@@ -1942,6 +2013,7 @@ public class Nimbus {\n         this.options = options;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"killTopologyWithOpts\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         killTopologyWithOpts_args args = new killTopologyWithOpts_args();\n@@ -1951,16 +2023,19 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public Void getResult() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n         }\n         org.apache.storm.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.storm.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());\n         org.apache.storm.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);\n+        (new Client(prot)).recv_killTopologyWithOpts();\n         return null;\n       }\n     }\n \n+    @Override\n     public void activate(java.lang.String name, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       activate_call method_call = new activate_call(name, resultHandler, this, ___protocolFactory, ___transport);\n@@ -1975,6 +2050,7 @@ public class Nimbus {\n         this.name = name;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"activate\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         activate_args args = new activate_args();\n@@ -1983,16 +2059,19 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public Void getResult() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n         }\n         org.apache.storm.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.storm.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());\n         org.apache.storm.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);\n+        (new Client(prot)).recv_activate();\n         return null;\n       }\n     }\n \n+    @Override\n     public void deactivate(java.lang.String name, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       deactivate_call method_call = new deactivate_call(name, resultHandler, this, ___protocolFactory, ___transport);\n@@ -2007,6 +2086,7 @@ public class Nimbus {\n         this.name = name;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"deactivate\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         deactivate_args args = new deactivate_args();\n@@ -2015,16 +2095,19 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public Void getResult() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n         }\n         org.apache.storm.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.storm.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());\n         org.apache.storm.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);\n+        (new Client(prot)).recv_deactivate();\n         return null;\n       }\n     }\n \n+    @Override\n     public void rebalance(java.lang.String name, RebalanceOptions options, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       rebalance_call method_call = new rebalance_call(name, options, resultHandler, this, ___protocolFactory, ___transport);\n@@ -2041,6 +2124,7 @@ public class Nimbus {\n         this.options = options;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"rebalance\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         rebalance_args args = new rebalance_args();\n@@ -2050,16 +2134,19 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public Void getResult() throws NotAliveException, InvalidTopologyException, AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n         }\n         org.apache.storm.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.storm.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());\n         org.apache.storm.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);\n+        (new Client(prot)).recv_rebalance();\n         return null;\n       }\n     }\n \n+    @Override\n     public void setLogConfig(java.lang.String name, LogConfig config, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       setLogConfig_call method_call = new setLogConfig_call(name, config, resultHandler, this, ___protocolFactory, ___transport);\n@@ -2076,6 +2163,7 @@ public class Nimbus {\n         this.config = config;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"setLogConfig\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         setLogConfig_args args = new setLogConfig_args();\n@@ -2085,16 +2173,19 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public Void getResult() throws org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n         }\n         org.apache.storm.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.storm.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());\n         org.apache.storm.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);\n+        (new Client(prot)).recv_setLogConfig();\n         return null;\n       }\n     }\n \n+    @Override\n     public void getLogConfig(java.lang.String name, org.apache.storm.thrift.async.AsyncMethodCallback<LogConfig> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       getLogConfig_call method_call = new getLogConfig_call(name, resultHandler, this, ___protocolFactory, ___transport);\n@@ -2109,6 +2200,7 @@ public class Nimbus {\n         this.name = name;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"getLogConfig\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         getLogConfig_args args = new getLogConfig_args();\n@@ -2117,6 +2209,7 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public LogConfig getResult() throws org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n@@ -2127,6 +2220,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void debug(java.lang.String name, java.lang.String component, boolean enable, double samplingPercentage, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       debug_call method_call = new debug_call(name, component, enable, samplingPercentage, resultHandler, this, ___protocolFactory, ___transport);\n@@ -2147,6 +2241,7 @@ public class Nimbus {\n         this.samplingPercentage = samplingPercentage;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"debug\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         debug_args args = new debug_args();\n@@ -2158,16 +2253,19 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public Void getResult() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n         }\n         org.apache.storm.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.storm.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());\n         org.apache.storm.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);\n+        (new Client(prot)).recv_debug();\n         return null;\n       }\n     }\n \n+    @Override\n     public void setWorkerProfiler(java.lang.String id, ProfileRequest profileRequest, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       setWorkerProfiler_call method_call = new setWorkerProfiler_call(id, profileRequest, resultHandler, this, ___protocolFactory, ___transport);\n@@ -2184,6 +2282,7 @@ public class Nimbus {\n         this.profileRequest = profileRequest;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"setWorkerProfiler\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         setWorkerProfiler_args args = new setWorkerProfiler_args();\n@@ -2193,16 +2292,19 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public Void getResult() throws org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n         }\n         org.apache.storm.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.storm.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());\n         org.apache.storm.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);\n+        (new Client(prot)).recv_setWorkerProfiler();\n         return null;\n       }\n     }\n \n+    @Override\n     public void getComponentPendingProfileActions(java.lang.String id, java.lang.String component_id, ProfileAction action, org.apache.storm.thrift.async.AsyncMethodCallback<java.util.List<ProfileRequest>> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       getComponentPendingProfileActions_call method_call = new getComponentPendingProfileActions_call(id, component_id, action, resultHandler, this, ___protocolFactory, ___transport);\n@@ -2221,6 +2323,7 @@ public class Nimbus {\n         this.action = action;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"getComponentPendingProfileActions\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         getComponentPendingProfileActions_args args = new getComponentPendingProfileActions_args();\n@@ -2231,6 +2334,7 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public java.util.List<ProfileRequest> getResult() throws org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n@@ -2241,6 +2345,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void uploadNewCredentials(java.lang.String name, Credentials creds, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       uploadNewCredentials_call method_call = new uploadNewCredentials_call(name, creds, resultHandler, this, ___protocolFactory, ___transport);\n@@ -2257,6 +2362,7 @@ public class Nimbus {\n         this.creds = creds;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"uploadNewCredentials\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         uploadNewCredentials_args args = new uploadNewCredentials_args();\n@@ -2266,16 +2372,19 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public Void getResult() throws NotAliveException, InvalidTopologyException, AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n         }\n         org.apache.storm.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.storm.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());\n         org.apache.storm.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);\n+        (new Client(prot)).recv_uploadNewCredentials();\n         return null;\n       }\n     }\n \n+    @Override\n     public void beginCreateBlob(java.lang.String key, SettableBlobMeta meta, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       beginCreateBlob_call method_call = new beginCreateBlob_call(key, meta, resultHandler, this, ___protocolFactory, ___transport);\n@@ -2292,6 +2401,7 @@ public class Nimbus {\n         this.meta = meta;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"beginCreateBlob\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         beginCreateBlob_args args = new beginCreateBlob_args();\n@@ -2301,6 +2411,7 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public java.lang.String getResult() throws AuthorizationException, KeyAlreadyExistsException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n@@ -2311,6 +2422,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void beginUpdateBlob(java.lang.String key, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       beginUpdateBlob_call method_call = new beginUpdateBlob_call(key, resultHandler, this, ___protocolFactory, ___transport);\n@@ -2325,6 +2437,7 @@ public class Nimbus {\n         this.key = key;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"beginUpdateBlob\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         beginUpdateBlob_args args = new beginUpdateBlob_args();\n@@ -2333,6 +2446,7 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public java.lang.String getResult() throws AuthorizationException, KeyNotFoundException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n@@ -2343,6 +2457,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void uploadBlobChunk(java.lang.String session, java.nio.ByteBuffer chunk, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       uploadBlobChunk_call method_call = new uploadBlobChunk_call(session, chunk, resultHandler, this, ___protocolFactory, ___transport);\n@@ -2359,6 +2474,7 @@ public class Nimbus {\n         this.chunk = chunk;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"uploadBlobChunk\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         uploadBlobChunk_args args = new uploadBlobChunk_args();\n@@ -2368,16 +2484,19 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public Void getResult() throws AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n         }\n         org.apache.storm.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.storm.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());\n         org.apache.storm.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);\n+        (new Client(prot)).recv_uploadBlobChunk();\n         return null;\n       }\n     }\n \n+    @Override\n     public void finishBlobUpload(java.lang.String session, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       finishBlobUpload_call method_call = new finishBlobUpload_call(session, resultHandler, this, ___protocolFactory, ___transport);\n@@ -2392,6 +2511,7 @@ public class Nimbus {\n         this.session = session;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"finishBlobUpload\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         finishBlobUpload_args args = new finishBlobUpload_args();\n@@ -2400,16 +2520,19 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public Void getResult() throws AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n         }\n         org.apache.storm.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.storm.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());\n         org.apache.storm.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);\n+        (new Client(prot)).recv_finishBlobUpload();\n         return null;\n       }\n     }\n \n+    @Override\n     public void cancelBlobUpload(java.lang.String session, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       cancelBlobUpload_call method_call = new cancelBlobUpload_call(session, resultHandler, this, ___protocolFactory, ___transport);\n@@ -2424,6 +2547,7 @@ public class Nimbus {\n         this.session = session;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"cancelBlobUpload\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         cancelBlobUpload_args args = new cancelBlobUpload_args();\n@@ -2432,16 +2556,19 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public Void getResult() throws AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n         }\n         org.apache.storm.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.storm.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());\n         org.apache.storm.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);\n+        (new Client(prot)).recv_cancelBlobUpload();\n         return null;\n       }\n     }\n \n+    @Override\n     public void getBlobMeta(java.lang.String key, org.apache.storm.thrift.async.AsyncMethodCallback<ReadableBlobMeta> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       getBlobMeta_call method_call = new getBlobMeta_call(key, resultHandler, this, ___protocolFactory, ___transport);\n@@ -2456,6 +2583,7 @@ public class Nimbus {\n         this.key = key;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"getBlobMeta\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         getBlobMeta_args args = new getBlobMeta_args();\n@@ -2464,6 +2592,7 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public ReadableBlobMeta getResult() throws AuthorizationException, KeyNotFoundException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n@@ -2474,6 +2603,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setBlobMeta(java.lang.String key, SettableBlobMeta meta, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       setBlobMeta_call method_call = new setBlobMeta_call(key, meta, resultHandler, this, ___protocolFactory, ___transport);\n@@ -2490,6 +2620,7 @@ public class Nimbus {\n         this.meta = meta;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"setBlobMeta\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         setBlobMeta_args args = new setBlobMeta_args();\n@@ -2499,16 +2630,19 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public Void getResult() throws AuthorizationException, KeyNotFoundException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n         }\n         org.apache.storm.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.storm.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());\n         org.apache.storm.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);\n+        (new Client(prot)).recv_setBlobMeta();\n         return null;\n       }\n     }\n \n+    @Override\n     public void beginBlobDownload(java.lang.String key, org.apache.storm.thrift.async.AsyncMethodCallback<BeginDownloadResult> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       beginBlobDownload_call method_call = new beginBlobDownload_call(key, resultHandler, this, ___protocolFactory, ___transport);\n@@ -2523,6 +2657,7 @@ public class Nimbus {\n         this.key = key;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"beginBlobDownload\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         beginBlobDownload_args args = new beginBlobDownload_args();\n@@ -2531,6 +2666,7 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public BeginDownloadResult getResult() throws AuthorizationException, KeyNotFoundException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n@@ -2541,6 +2677,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void downloadBlobChunk(java.lang.String session, org.apache.storm.thrift.async.AsyncMethodCallback<java.nio.ByteBuffer> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       downloadBlobChunk_call method_call = new downloadBlobChunk_call(session, resultHandler, this, ___protocolFactory, ___transport);\n@@ -2555,6 +2692,7 @@ public class Nimbus {\n         this.session = session;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"downloadBlobChunk\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         downloadBlobChunk_args args = new downloadBlobChunk_args();\n@@ -2563,6 +2701,7 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public java.nio.ByteBuffer getResult() throws AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n@@ -2573,6 +2712,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void deleteBlob(java.lang.String key, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       deleteBlob_call method_call = new deleteBlob_call(key, resultHandler, this, ___protocolFactory, ___transport);\n@@ -2587,6 +2727,7 @@ public class Nimbus {\n         this.key = key;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"deleteBlob\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         deleteBlob_args args = new deleteBlob_args();\n@@ -2595,16 +2736,19 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public Void getResult() throws AuthorizationException, KeyNotFoundException, IllegalStateException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n         }\n         org.apache.storm.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.storm.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());\n         org.apache.storm.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);\n+        (new Client(prot)).recv_deleteBlob();\n         return null;\n       }\n     }\n \n+    @Override\n     public void listBlobs(java.lang.String session, org.apache.storm.thrift.async.AsyncMethodCallback<ListBlobsResult> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       listBlobs_call method_call = new listBlobs_call(session, resultHandler, this, ___protocolFactory, ___transport);\n@@ -2619,6 +2763,7 @@ public class Nimbus {\n         this.session = session;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"listBlobs\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         listBlobs_args args = new listBlobs_args();\n@@ -2627,6 +2772,7 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public ListBlobsResult getResult() throws org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n@@ -2637,6 +2783,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void getBlobReplication(java.lang.String key, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.Integer> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       getBlobReplication_call method_call = new getBlobReplication_call(key, resultHandler, this, ___protocolFactory, ___transport);\n@@ -2651,6 +2798,7 @@ public class Nimbus {\n         this.key = key;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"getBlobReplication\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         getBlobReplication_args args = new getBlobReplication_args();\n@@ -2659,6 +2807,7 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public java.lang.Integer getResult() throws AuthorizationException, KeyNotFoundException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n@@ -2669,6 +2818,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void updateBlobReplication(java.lang.String key, int replication, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.Integer> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       updateBlobReplication_call method_call = new updateBlobReplication_call(key, replication, resultHandler, this, ___protocolFactory, ___transport);\n@@ -2685,6 +2835,7 @@ public class Nimbus {\n         this.replication = replication;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"updateBlobReplication\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         updateBlobReplication_args args = new updateBlobReplication_args();\n@@ -2694,6 +2845,7 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public java.lang.Integer getResult() throws AuthorizationException, KeyNotFoundException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n@@ -2704,6 +2856,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void createStateInZookeeper(java.lang.String key, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       createStateInZookeeper_call method_call = new createStateInZookeeper_call(key, resultHandler, this, ___protocolFactory, ___transport);\n@@ -2718,6 +2871,7 @@ public class Nimbus {\n         this.key = key;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"createStateInZookeeper\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         createStateInZookeeper_args args = new createStateInZookeeper_args();\n@@ -2726,16 +2880,19 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public Void getResult() throws org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n         }\n         org.apache.storm.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.storm.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());\n         org.apache.storm.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);\n+        (new Client(prot)).recv_createStateInZookeeper();\n         return null;\n       }\n     }\n \n+    @Override\n     public void beginFileUpload(org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       beginFileUpload_call method_call = new beginFileUpload_call(resultHandler, this, ___protocolFactory, ___transport);\n@@ -2748,6 +2905,7 @@ public class Nimbus {\n         super(client, protocolFactory, transport, resultHandler, false);\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"beginFileUpload\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         beginFileUpload_args args = new beginFileUpload_args();\n@@ -2755,6 +2913,7 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public java.lang.String getResult() throws AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n@@ -2765,6 +2924,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void uploadChunk(java.lang.String location, java.nio.ByteBuffer chunk, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       uploadChunk_call method_call = new uploadChunk_call(location, chunk, resultHandler, this, ___protocolFactory, ___transport);\n@@ -2781,6 +2941,7 @@ public class Nimbus {\n         this.chunk = chunk;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"uploadChunk\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         uploadChunk_args args = new uploadChunk_args();\n@@ -2790,16 +2951,19 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public Void getResult() throws AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n         }\n         org.apache.storm.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.storm.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());\n         org.apache.storm.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);\n+        (new Client(prot)).recv_uploadChunk();\n         return null;\n       }\n     }\n \n+    @Override\n     public void finishFileUpload(java.lang.String location, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       finishFileUpload_call method_call = new finishFileUpload_call(location, resultHandler, this, ___protocolFactory, ___transport);\n@@ -2814,6 +2978,7 @@ public class Nimbus {\n         this.location = location;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"finishFileUpload\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         finishFileUpload_args args = new finishFileUpload_args();\n@@ -2822,16 +2987,19 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public Void getResult() throws AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n         }\n         org.apache.storm.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.storm.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());\n         org.apache.storm.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);\n+        (new Client(prot)).recv_finishFileUpload();\n         return null;\n       }\n     }\n \n+    @Override\n     public void downloadChunk(java.lang.String id, org.apache.storm.thrift.async.AsyncMethodCallback<java.nio.ByteBuffer> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       downloadChunk_call method_call = new downloadChunk_call(id, resultHandler, this, ___protocolFactory, ___transport);\n@@ -2846,6 +3014,7 @@ public class Nimbus {\n         this.id = id;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"downloadChunk\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         downloadChunk_args args = new downloadChunk_args();\n@@ -2854,6 +3023,7 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public java.nio.ByteBuffer getResult() throws AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n@@ -2864,6 +3034,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void getNimbusConf(org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       getNimbusConf_call method_call = new getNimbusConf_call(resultHandler, this, ___protocolFactory, ___transport);\n@@ -2876,6 +3047,7 @@ public class Nimbus {\n         super(client, protocolFactory, transport, resultHandler, false);\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"getNimbusConf\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         getNimbusConf_args args = new getNimbusConf_args();\n@@ -2883,6 +3055,7 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public java.lang.String getResult() throws AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n@@ -2893,6 +3066,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void getClusterInfo(org.apache.storm.thrift.async.AsyncMethodCallback<ClusterSummary> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       getClusterInfo_call method_call = new getClusterInfo_call(resultHandler, this, ___protocolFactory, ___transport);\n@@ -2905,6 +3079,7 @@ public class Nimbus {\n         super(client, protocolFactory, transport, resultHandler, false);\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"getClusterInfo\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         getClusterInfo_args args = new getClusterInfo_args();\n@@ -2912,6 +3087,7 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public ClusterSummary getResult() throws AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n@@ -2922,6 +3098,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void getTopologySummaries(org.apache.storm.thrift.async.AsyncMethodCallback<java.util.List<TopologySummary>> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       getTopologySummaries_call method_call = new getTopologySummaries_call(resultHandler, this, ___protocolFactory, ___transport);\n@@ -2934,6 +3111,7 @@ public class Nimbus {\n         super(client, protocolFactory, transport, resultHandler, false);\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"getTopologySummaries\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         getTopologySummaries_args args = new getTopologySummaries_args();\n@@ -2941,6 +3119,7 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public java.util.List<TopologySummary> getResult() throws AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n@@ -2951,6 +3130,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void getTopologySummaryByName(java.lang.String name, org.apache.storm.thrift.async.AsyncMethodCallback<TopologySummary> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       getTopologySummaryByName_call method_call = new getTopologySummaryByName_call(name, resultHandler, this, ___protocolFactory, ___transport);\n@@ -2965,6 +3145,7 @@ public class Nimbus {\n         this.name = name;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"getTopologySummaryByName\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         getTopologySummaryByName_args args = new getTopologySummaryByName_args();\n@@ -2973,6 +3154,7 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public TopologySummary getResult() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n@@ -2983,6 +3165,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void getTopologySummary(java.lang.String id, org.apache.storm.thrift.async.AsyncMethodCallback<TopologySummary> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       getTopologySummary_call method_call = new getTopologySummary_call(id, resultHandler, this, ___protocolFactory, ___transport);\n@@ -2997,6 +3180,7 @@ public class Nimbus {\n         this.id = id;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"getTopologySummary\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         getTopologySummary_args args = new getTopologySummary_args();\n@@ -3005,6 +3189,7 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public TopologySummary getResult() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n@@ -3015,6 +3200,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void getLeader(org.apache.storm.thrift.async.AsyncMethodCallback<NimbusSummary> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       getLeader_call method_call = new getLeader_call(resultHandler, this, ___protocolFactory, ___transport);\n@@ -3027,6 +3213,7 @@ public class Nimbus {\n         super(client, protocolFactory, transport, resultHandler, false);\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"getLeader\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         getLeader_args args = new getLeader_args();\n@@ -3034,6 +3221,7 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public NimbusSummary getResult() throws AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n@@ -3044,6 +3232,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void isTopologyNameAllowed(java.lang.String name, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.Boolean> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       isTopologyNameAllowed_call method_call = new isTopologyNameAllowed_call(name, resultHandler, this, ___protocolFactory, ___transport);\n@@ -3058,6 +3247,7 @@ public class Nimbus {\n         this.name = name;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"isTopologyNameAllowed\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         isTopologyNameAllowed_args args = new isTopologyNameAllowed_args();\n@@ -3066,6 +3256,7 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public java.lang.Boolean getResult() throws AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n@@ -3076,6 +3267,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void getTopologyInfoByName(java.lang.String name, org.apache.storm.thrift.async.AsyncMethodCallback<TopologyInfo> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       getTopologyInfoByName_call method_call = new getTopologyInfoByName_call(name, resultHandler, this, ___protocolFactory, ___transport);\n@@ -3090,6 +3282,7 @@ public class Nimbus {\n         this.name = name;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"getTopologyInfoByName\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         getTopologyInfoByName_args args = new getTopologyInfoByName_args();\n@@ -3098,6 +3291,7 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public TopologyInfo getResult() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n@@ -3108,6 +3302,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void getTopologyInfo(java.lang.String id, org.apache.storm.thrift.async.AsyncMethodCallback<TopologyInfo> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       getTopologyInfo_call method_call = new getTopologyInfo_call(id, resultHandler, this, ___protocolFactory, ___transport);\n@@ -3122,6 +3317,7 @@ public class Nimbus {\n         this.id = id;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"getTopologyInfo\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         getTopologyInfo_args args = new getTopologyInfo_args();\n@@ -3130,6 +3326,7 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public TopologyInfo getResult() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n@@ -3140,6 +3337,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void getTopologyInfoByNameWithOpts(java.lang.String name, GetInfoOptions options, org.apache.storm.thrift.async.AsyncMethodCallback<TopologyInfo> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       getTopologyInfoByNameWithOpts_call method_call = new getTopologyInfoByNameWithOpts_call(name, options, resultHandler, this, ___protocolFactory, ___transport);\n@@ -3156,6 +3354,7 @@ public class Nimbus {\n         this.options = options;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"getTopologyInfoByNameWithOpts\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         getTopologyInfoByNameWithOpts_args args = new getTopologyInfoByNameWithOpts_args();\n@@ -3165,6 +3364,7 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public TopologyInfo getResult() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n@@ -3175,6 +3375,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void getTopologyInfoWithOpts(java.lang.String id, GetInfoOptions options, org.apache.storm.thrift.async.AsyncMethodCallback<TopologyInfo> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       getTopologyInfoWithOpts_call method_call = new getTopologyInfoWithOpts_call(id, options, resultHandler, this, ___protocolFactory, ___transport);\n@@ -3191,6 +3392,7 @@ public class Nimbus {\n         this.options = options;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"getTopologyInfoWithOpts\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         getTopologyInfoWithOpts_args args = new getTopologyInfoWithOpts_args();\n@@ -3200,6 +3402,7 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public TopologyInfo getResult() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n@@ -3210,6 +3413,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void getTopologyPageInfo(java.lang.String id, java.lang.String window, boolean is_include_sys, org.apache.storm.thrift.async.AsyncMethodCallback<TopologyPageInfo> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       getTopologyPageInfo_call method_call = new getTopologyPageInfo_call(id, window, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n@@ -3228,6 +3432,7 @@ public class Nimbus {\n         this.is_include_sys = is_include_sys;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"getTopologyPageInfo\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         getTopologyPageInfo_args args = new getTopologyPageInfo_args();\n@@ -3238,6 +3443,7 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public TopologyPageInfo getResult() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n@@ -3248,6 +3454,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void getSupervisorPageInfo(java.lang.String id, java.lang.String host, boolean is_include_sys, org.apache.storm.thrift.async.AsyncMethodCallback<SupervisorPageInfo> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       getSupervisorPageInfo_call method_call = new getSupervisorPageInfo_call(id, host, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n@@ -3266,6 +3473,7 @@ public class Nimbus {\n         this.is_include_sys = is_include_sys;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"getSupervisorPageInfo\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         getSupervisorPageInfo_args args = new getSupervisorPageInfo_args();\n@@ -3276,6 +3484,7 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public SupervisorPageInfo getResult() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n@@ -3286,6 +3495,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void getComponentPageInfo(java.lang.String topology_id, java.lang.String component_id, java.lang.String window, boolean is_include_sys, org.apache.storm.thrift.async.AsyncMethodCallback<ComponentPageInfo> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       getComponentPageInfo_call method_call = new getComponentPageInfo_call(topology_id, component_id, window, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n@@ -3306,6 +3516,7 @@ public class Nimbus {\n         this.is_include_sys = is_include_sys;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"getComponentPageInfo\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         getComponentPageInfo_args args = new getComponentPageInfo_args();\n@@ -3317,6 +3528,7 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public ComponentPageInfo getResult() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n@@ -3327,6 +3539,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void getTopologyConf(java.lang.String id, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       getTopologyConf_call method_call = new getTopologyConf_call(id, resultHandler, this, ___protocolFactory, ___transport);\n@@ -3341,6 +3554,7 @@ public class Nimbus {\n         this.id = id;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"getTopologyConf\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         getTopologyConf_args args = new getTopologyConf_args();\n@@ -3349,6 +3563,7 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public java.lang.String getResult() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n@@ -3359,6 +3574,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void getTopology(java.lang.String id, org.apache.storm.thrift.async.AsyncMethodCallback<StormTopology> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       getTopology_call method_call = new getTopology_call(id, resultHandler, this, ___protocolFactory, ___transport);\n@@ -3373,6 +3589,7 @@ public class Nimbus {\n         this.id = id;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"getTopology\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         getTopology_args args = new getTopology_args();\n@@ -3381,6 +3598,7 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public StormTopology getResult() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n@@ -3391,6 +3609,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void getUserTopology(java.lang.String id, org.apache.storm.thrift.async.AsyncMethodCallback<StormTopology> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       getUserTopology_call method_call = new getUserTopology_call(id, resultHandler, this, ___protocolFactory, ___transport);\n@@ -3405,6 +3624,7 @@ public class Nimbus {\n         this.id = id;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"getUserTopology\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         getUserTopology_args args = new getUserTopology_args();\n@@ -3413,6 +3633,7 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public StormTopology getResult() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n@@ -3423,6 +3644,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void getTopologyHistory(java.lang.String user, org.apache.storm.thrift.async.AsyncMethodCallback<TopologyHistoryInfo> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       getTopologyHistory_call method_call = new getTopologyHistory_call(user, resultHandler, this, ___protocolFactory, ___transport);\n@@ -3437,6 +3659,7 @@ public class Nimbus {\n         this.user = user;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"getTopologyHistory\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         getTopologyHistory_args args = new getTopologyHistory_args();\n@@ -3445,6 +3668,7 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public TopologyHistoryInfo getResult() throws AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n@@ -3455,6 +3679,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void getOwnerResourceSummaries(java.lang.String owner, org.apache.storm.thrift.async.AsyncMethodCallback<java.util.List<OwnerResourceSummary>> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       getOwnerResourceSummaries_call method_call = new getOwnerResourceSummaries_call(owner, resultHandler, this, ___protocolFactory, ___transport);\n@@ -3469,6 +3694,7 @@ public class Nimbus {\n         this.owner = owner;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"getOwnerResourceSummaries\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         getOwnerResourceSummaries_args args = new getOwnerResourceSummaries_args();\n@@ -3477,6 +3703,7 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public java.util.List<OwnerResourceSummary> getResult() throws AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n@@ -3487,6 +3714,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void getSupervisorAssignments(java.lang.String node, org.apache.storm.thrift.async.AsyncMethodCallback<SupervisorAssignments> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       getSupervisorAssignments_call method_call = new getSupervisorAssignments_call(node, resultHandler, this, ___protocolFactory, ___transport);\n@@ -3501,6 +3729,7 @@ public class Nimbus {\n         this.node = node;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"getSupervisorAssignments\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         getSupervisorAssignments_args args = new getSupervisorAssignments_args();\n@@ -3509,6 +3738,7 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public SupervisorAssignments getResult() throws AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n@@ -3519,6 +3749,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void sendSupervisorWorkerHeartbeats(SupervisorWorkerHeartbeats heartbeats, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       sendSupervisorWorkerHeartbeats_call method_call = new sendSupervisorWorkerHeartbeats_call(heartbeats, resultHandler, this, ___protocolFactory, ___transport);\n@@ -3533,6 +3764,7 @@ public class Nimbus {\n         this.heartbeats = heartbeats;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"sendSupervisorWorkerHeartbeats\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         sendSupervisorWorkerHeartbeats_args args = new sendSupervisorWorkerHeartbeats_args();\n@@ -3541,16 +3773,19 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public Void getResult() throws AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n         }\n         org.apache.storm.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.storm.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());\n         org.apache.storm.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);\n+        (new Client(prot)).recv_sendSupervisorWorkerHeartbeats();\n         return null;\n       }\n     }\n \n+    @Override\n     public void sendSupervisorWorkerHeartbeat(SupervisorWorkerHeartbeat heatbeat, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       sendSupervisorWorkerHeartbeat_call method_call = new sendSupervisorWorkerHeartbeat_call(heatbeat, resultHandler, this, ___protocolFactory, ___transport);\n@@ -3565,6 +3800,7 @@ public class Nimbus {\n         this.heatbeat = heatbeat;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"sendSupervisorWorkerHeartbeat\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         sendSupervisorWorkerHeartbeat_args args = new sendSupervisorWorkerHeartbeat_args();\n@@ -3573,16 +3809,19 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public Void getResult() throws AuthorizationException, NotAliveException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n         }\n         org.apache.storm.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.storm.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());\n         org.apache.storm.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);\n+        (new Client(prot)).recv_sendSupervisorWorkerHeartbeat();\n         return null;\n       }\n     }\n \n+    @Override\n     public void processWorkerMetrics(WorkerMetrics metrics, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       processWorkerMetrics_call method_call = new processWorkerMetrics_call(metrics, resultHandler, this, ___protocolFactory, ___transport);\n@@ -3597,6 +3836,7 @@ public class Nimbus {\n         this.metrics = metrics;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"processWorkerMetrics\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         processWorkerMetrics_args args = new processWorkerMetrics_args();\n@@ -3605,16 +3845,19 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public Void getResult() throws org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n         }\n         org.apache.storm.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.storm.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());\n         org.apache.storm.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);\n+        (new Client(prot)).recv_processWorkerMetrics();\n         return null;\n       }\n     }\n \n+    @Override\n     public void isRemoteBlobExists(java.lang.String blobKey, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.Boolean> resultHandler) throws org.apache.storm.thrift.TException {\n       checkReady();\n       isRemoteBlobExists_call method_call = new isRemoteBlobExists_call(blobKey, resultHandler, this, ___protocolFactory, ___transport);\n@@ -3629,6 +3872,7 @@ public class Nimbus {\n         this.blobKey = blobKey;\n       }\n \n+      @Override\n       public void write_args(org.apache.storm.thrift.protocol.TProtocol prot) throws org.apache.storm.thrift.TException {\n         prot.writeMessageBegin(new org.apache.storm.thrift.protocol.TMessage(\"isRemoteBlobExists\", org.apache.storm.thrift.protocol.TMessageType.CALL, 0));\n         isRemoteBlobExists_args args = new isRemoteBlobExists_args();\n@@ -3637,6 +3881,7 @@ public class Nimbus {\n         prot.writeMessageEnd();\n       }\n \n+      @Override\n       public java.lang.Boolean getResult() throws AuthorizationException, org.apache.storm.thrift.TException {\n         if (getState() != org.apache.storm.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {\n           throw new java.lang.IllegalStateException(\"Method call not finished!\");\n@@ -3723,10 +3968,12 @@ public class Nimbus {\n         super(\"submitTopology\");\n       }\n \n+      @Override\n       public submitTopology_args getEmptyArgsInstance() {\n         return new submitTopology_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -3736,6 +3983,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public submitTopology_result getResult(I iface, submitTopology_args args) throws org.apache.storm.thrift.TException {\n         submitTopology_result result = new submitTopology_result();\n         try {\n@@ -3756,10 +4004,12 @@ public class Nimbus {\n         super(\"submitTopologyWithOpts\");\n       }\n \n+      @Override\n       public submitTopologyWithOpts_args getEmptyArgsInstance() {\n         return new submitTopologyWithOpts_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -3769,6 +4019,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public submitTopologyWithOpts_result getResult(I iface, submitTopologyWithOpts_args args) throws org.apache.storm.thrift.TException {\n         submitTopologyWithOpts_result result = new submitTopologyWithOpts_result();\n         try {\n@@ -3789,10 +4040,12 @@ public class Nimbus {\n         super(\"killTopology\");\n       }\n \n+      @Override\n       public killTopology_args getEmptyArgsInstance() {\n         return new killTopology_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -3802,6 +4055,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public killTopology_result getResult(I iface, killTopology_args args) throws org.apache.storm.thrift.TException {\n         killTopology_result result = new killTopology_result();\n         try {\n@@ -3820,10 +4074,12 @@ public class Nimbus {\n         super(\"killTopologyWithOpts\");\n       }\n \n+      @Override\n       public killTopologyWithOpts_args getEmptyArgsInstance() {\n         return new killTopologyWithOpts_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -3833,6 +4089,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public killTopologyWithOpts_result getResult(I iface, killTopologyWithOpts_args args) throws org.apache.storm.thrift.TException {\n         killTopologyWithOpts_result result = new killTopologyWithOpts_result();\n         try {\n@@ -3851,10 +4108,12 @@ public class Nimbus {\n         super(\"activate\");\n       }\n \n+      @Override\n       public activate_args getEmptyArgsInstance() {\n         return new activate_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -3864,6 +4123,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public activate_result getResult(I iface, activate_args args) throws org.apache.storm.thrift.TException {\n         activate_result result = new activate_result();\n         try {\n@@ -3882,10 +4142,12 @@ public class Nimbus {\n         super(\"deactivate\");\n       }\n \n+      @Override\n       public deactivate_args getEmptyArgsInstance() {\n         return new deactivate_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -3895,6 +4157,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public deactivate_result getResult(I iface, deactivate_args args) throws org.apache.storm.thrift.TException {\n         deactivate_result result = new deactivate_result();\n         try {\n@@ -3913,10 +4176,12 @@ public class Nimbus {\n         super(\"rebalance\");\n       }\n \n+      @Override\n       public rebalance_args getEmptyArgsInstance() {\n         return new rebalance_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -3926,6 +4191,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public rebalance_result getResult(I iface, rebalance_args args) throws org.apache.storm.thrift.TException {\n         rebalance_result result = new rebalance_result();\n         try {\n@@ -3946,10 +4212,12 @@ public class Nimbus {\n         super(\"setLogConfig\");\n       }\n \n+      @Override\n       public setLogConfig_args getEmptyArgsInstance() {\n         return new setLogConfig_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -3959,6 +4227,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public setLogConfig_result getResult(I iface, setLogConfig_args args) throws org.apache.storm.thrift.TException {\n         setLogConfig_result result = new setLogConfig_result();\n         iface.setLogConfig(args.name, args.config);\n@@ -3971,10 +4240,12 @@ public class Nimbus {\n         super(\"getLogConfig\");\n       }\n \n+      @Override\n       public getLogConfig_args getEmptyArgsInstance() {\n         return new getLogConfig_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -3984,6 +4255,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public getLogConfig_result getResult(I iface, getLogConfig_args args) throws org.apache.storm.thrift.TException {\n         getLogConfig_result result = new getLogConfig_result();\n         result.success = iface.getLogConfig(args.name);\n@@ -3996,10 +4268,12 @@ public class Nimbus {\n         super(\"debug\");\n       }\n \n+      @Override\n       public debug_args getEmptyArgsInstance() {\n         return new debug_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -4009,6 +4283,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public debug_result getResult(I iface, debug_args args) throws org.apache.storm.thrift.TException {\n         debug_result result = new debug_result();\n         try {\n@@ -4027,10 +4302,12 @@ public class Nimbus {\n         super(\"setWorkerProfiler\");\n       }\n \n+      @Override\n       public setWorkerProfiler_args getEmptyArgsInstance() {\n         return new setWorkerProfiler_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -4040,6 +4317,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public setWorkerProfiler_result getResult(I iface, setWorkerProfiler_args args) throws org.apache.storm.thrift.TException {\n         setWorkerProfiler_result result = new setWorkerProfiler_result();\n         iface.setWorkerProfiler(args.id, args.profileRequest);\n@@ -4052,10 +4330,12 @@ public class Nimbus {\n         super(\"getComponentPendingProfileActions\");\n       }\n \n+      @Override\n       public getComponentPendingProfileActions_args getEmptyArgsInstance() {\n         return new getComponentPendingProfileActions_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -4065,6 +4345,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public getComponentPendingProfileActions_result getResult(I iface, getComponentPendingProfileActions_args args) throws org.apache.storm.thrift.TException {\n         getComponentPendingProfileActions_result result = new getComponentPendingProfileActions_result();\n         result.success = iface.getComponentPendingProfileActions(args.id, args.component_id, args.action);\n@@ -4077,10 +4358,12 @@ public class Nimbus {\n         super(\"uploadNewCredentials\");\n       }\n \n+      @Override\n       public uploadNewCredentials_args getEmptyArgsInstance() {\n         return new uploadNewCredentials_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -4090,6 +4373,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public uploadNewCredentials_result getResult(I iface, uploadNewCredentials_args args) throws org.apache.storm.thrift.TException {\n         uploadNewCredentials_result result = new uploadNewCredentials_result();\n         try {\n@@ -4110,10 +4394,12 @@ public class Nimbus {\n         super(\"beginCreateBlob\");\n       }\n \n+      @Override\n       public beginCreateBlob_args getEmptyArgsInstance() {\n         return new beginCreateBlob_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -4123,6 +4409,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public beginCreateBlob_result getResult(I iface, beginCreateBlob_args args) throws org.apache.storm.thrift.TException {\n         beginCreateBlob_result result = new beginCreateBlob_result();\n         try {\n@@ -4141,10 +4428,12 @@ public class Nimbus {\n         super(\"beginUpdateBlob\");\n       }\n \n+      @Override\n       public beginUpdateBlob_args getEmptyArgsInstance() {\n         return new beginUpdateBlob_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -4154,6 +4443,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public beginUpdateBlob_result getResult(I iface, beginUpdateBlob_args args) throws org.apache.storm.thrift.TException {\n         beginUpdateBlob_result result = new beginUpdateBlob_result();\n         try {\n@@ -4172,10 +4462,12 @@ public class Nimbus {\n         super(\"uploadBlobChunk\");\n       }\n \n+      @Override\n       public uploadBlobChunk_args getEmptyArgsInstance() {\n         return new uploadBlobChunk_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -4185,6 +4477,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public uploadBlobChunk_result getResult(I iface, uploadBlobChunk_args args) throws org.apache.storm.thrift.TException {\n         uploadBlobChunk_result result = new uploadBlobChunk_result();\n         try {\n@@ -4201,10 +4494,12 @@ public class Nimbus {\n         super(\"finishBlobUpload\");\n       }\n \n+      @Override\n       public finishBlobUpload_args getEmptyArgsInstance() {\n         return new finishBlobUpload_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -4214,6 +4509,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public finishBlobUpload_result getResult(I iface, finishBlobUpload_args args) throws org.apache.storm.thrift.TException {\n         finishBlobUpload_result result = new finishBlobUpload_result();\n         try {\n@@ -4230,10 +4526,12 @@ public class Nimbus {\n         super(\"cancelBlobUpload\");\n       }\n \n+      @Override\n       public cancelBlobUpload_args getEmptyArgsInstance() {\n         return new cancelBlobUpload_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -4243,6 +4541,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public cancelBlobUpload_result getResult(I iface, cancelBlobUpload_args args) throws org.apache.storm.thrift.TException {\n         cancelBlobUpload_result result = new cancelBlobUpload_result();\n         try {\n@@ -4259,10 +4558,12 @@ public class Nimbus {\n         super(\"getBlobMeta\");\n       }\n \n+      @Override\n       public getBlobMeta_args getEmptyArgsInstance() {\n         return new getBlobMeta_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -4272,6 +4573,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public getBlobMeta_result getResult(I iface, getBlobMeta_args args) throws org.apache.storm.thrift.TException {\n         getBlobMeta_result result = new getBlobMeta_result();\n         try {\n@@ -4290,10 +4592,12 @@ public class Nimbus {\n         super(\"setBlobMeta\");\n       }\n \n+      @Override\n       public setBlobMeta_args getEmptyArgsInstance() {\n         return new setBlobMeta_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -4303,6 +4607,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public setBlobMeta_result getResult(I iface, setBlobMeta_args args) throws org.apache.storm.thrift.TException {\n         setBlobMeta_result result = new setBlobMeta_result();\n         try {\n@@ -4321,10 +4626,12 @@ public class Nimbus {\n         super(\"beginBlobDownload\");\n       }\n \n+      @Override\n       public beginBlobDownload_args getEmptyArgsInstance() {\n         return new beginBlobDownload_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -4334,6 +4641,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public beginBlobDownload_result getResult(I iface, beginBlobDownload_args args) throws org.apache.storm.thrift.TException {\n         beginBlobDownload_result result = new beginBlobDownload_result();\n         try {\n@@ -4352,10 +4660,12 @@ public class Nimbus {\n         super(\"downloadBlobChunk\");\n       }\n \n+      @Override\n       public downloadBlobChunk_args getEmptyArgsInstance() {\n         return new downloadBlobChunk_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -4365,6 +4675,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public downloadBlobChunk_result getResult(I iface, downloadBlobChunk_args args) throws org.apache.storm.thrift.TException {\n         downloadBlobChunk_result result = new downloadBlobChunk_result();\n         try {\n@@ -4381,10 +4692,12 @@ public class Nimbus {\n         super(\"deleteBlob\");\n       }\n \n+      @Override\n       public deleteBlob_args getEmptyArgsInstance() {\n         return new deleteBlob_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -4394,6 +4707,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public deleteBlob_result getResult(I iface, deleteBlob_args args) throws org.apache.storm.thrift.TException {\n         deleteBlob_result result = new deleteBlob_result();\n         try {\n@@ -4414,10 +4728,12 @@ public class Nimbus {\n         super(\"listBlobs\");\n       }\n \n+      @Override\n       public listBlobs_args getEmptyArgsInstance() {\n         return new listBlobs_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -4427,6 +4743,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public listBlobs_result getResult(I iface, listBlobs_args args) throws org.apache.storm.thrift.TException {\n         listBlobs_result result = new listBlobs_result();\n         result.success = iface.listBlobs(args.session);\n@@ -4439,10 +4756,12 @@ public class Nimbus {\n         super(\"getBlobReplication\");\n       }\n \n+      @Override\n       public getBlobReplication_args getEmptyArgsInstance() {\n         return new getBlobReplication_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -4452,6 +4771,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public getBlobReplication_result getResult(I iface, getBlobReplication_args args) throws org.apache.storm.thrift.TException {\n         getBlobReplication_result result = new getBlobReplication_result();\n         try {\n@@ -4471,10 +4791,12 @@ public class Nimbus {\n         super(\"updateBlobReplication\");\n       }\n \n+      @Override\n       public updateBlobReplication_args getEmptyArgsInstance() {\n         return new updateBlobReplication_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -4484,6 +4806,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public updateBlobReplication_result getResult(I iface, updateBlobReplication_args args) throws org.apache.storm.thrift.TException {\n         updateBlobReplication_result result = new updateBlobReplication_result();\n         try {\n@@ -4503,10 +4826,12 @@ public class Nimbus {\n         super(\"createStateInZookeeper\");\n       }\n \n+      @Override\n       public createStateInZookeeper_args getEmptyArgsInstance() {\n         return new createStateInZookeeper_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -4516,6 +4841,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public createStateInZookeeper_result getResult(I iface, createStateInZookeeper_args args) throws org.apache.storm.thrift.TException {\n         createStateInZookeeper_result result = new createStateInZookeeper_result();\n         iface.createStateInZookeeper(args.key);\n@@ -4528,10 +4854,12 @@ public class Nimbus {\n         super(\"beginFileUpload\");\n       }\n \n+      @Override\n       public beginFileUpload_args getEmptyArgsInstance() {\n         return new beginFileUpload_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -4541,6 +4869,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public beginFileUpload_result getResult(I iface, beginFileUpload_args args) throws org.apache.storm.thrift.TException {\n         beginFileUpload_result result = new beginFileUpload_result();\n         try {\n@@ -4557,10 +4886,12 @@ public class Nimbus {\n         super(\"uploadChunk\");\n       }\n \n+      @Override\n       public uploadChunk_args getEmptyArgsInstance() {\n         return new uploadChunk_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -4570,6 +4901,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public uploadChunk_result getResult(I iface, uploadChunk_args args) throws org.apache.storm.thrift.TException {\n         uploadChunk_result result = new uploadChunk_result();\n         try {\n@@ -4586,10 +4918,12 @@ public class Nimbus {\n         super(\"finishFileUpload\");\n       }\n \n+      @Override\n       public finishFileUpload_args getEmptyArgsInstance() {\n         return new finishFileUpload_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -4599,6 +4933,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public finishFileUpload_result getResult(I iface, finishFileUpload_args args) throws org.apache.storm.thrift.TException {\n         finishFileUpload_result result = new finishFileUpload_result();\n         try {\n@@ -4615,10 +4950,12 @@ public class Nimbus {\n         super(\"downloadChunk\");\n       }\n \n+      @Override\n       public downloadChunk_args getEmptyArgsInstance() {\n         return new downloadChunk_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -4628,6 +4965,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public downloadChunk_result getResult(I iface, downloadChunk_args args) throws org.apache.storm.thrift.TException {\n         downloadChunk_result result = new downloadChunk_result();\n         try {\n@@ -4644,10 +4982,12 @@ public class Nimbus {\n         super(\"getNimbusConf\");\n       }\n \n+      @Override\n       public getNimbusConf_args getEmptyArgsInstance() {\n         return new getNimbusConf_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -4657,6 +4997,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public getNimbusConf_result getResult(I iface, getNimbusConf_args args) throws org.apache.storm.thrift.TException {\n         getNimbusConf_result result = new getNimbusConf_result();\n         try {\n@@ -4673,10 +5014,12 @@ public class Nimbus {\n         super(\"getClusterInfo\");\n       }\n \n+      @Override\n       public getClusterInfo_args getEmptyArgsInstance() {\n         return new getClusterInfo_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -4686,6 +5029,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public getClusterInfo_result getResult(I iface, getClusterInfo_args args) throws org.apache.storm.thrift.TException {\n         getClusterInfo_result result = new getClusterInfo_result();\n         try {\n@@ -4702,10 +5046,12 @@ public class Nimbus {\n         super(\"getTopologySummaries\");\n       }\n \n+      @Override\n       public getTopologySummaries_args getEmptyArgsInstance() {\n         return new getTopologySummaries_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -4715,6 +5061,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public getTopologySummaries_result getResult(I iface, getTopologySummaries_args args) throws org.apache.storm.thrift.TException {\n         getTopologySummaries_result result = new getTopologySummaries_result();\n         try {\n@@ -4731,10 +5078,12 @@ public class Nimbus {\n         super(\"getTopologySummaryByName\");\n       }\n \n+      @Override\n       public getTopologySummaryByName_args getEmptyArgsInstance() {\n         return new getTopologySummaryByName_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -4744,6 +5093,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public getTopologySummaryByName_result getResult(I iface, getTopologySummaryByName_args args) throws org.apache.storm.thrift.TException {\n         getTopologySummaryByName_result result = new getTopologySummaryByName_result();\n         try {\n@@ -4762,10 +5112,12 @@ public class Nimbus {\n         super(\"getTopologySummary\");\n       }\n \n+      @Override\n       public getTopologySummary_args getEmptyArgsInstance() {\n         return new getTopologySummary_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -4775,6 +5127,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public getTopologySummary_result getResult(I iface, getTopologySummary_args args) throws org.apache.storm.thrift.TException {\n         getTopologySummary_result result = new getTopologySummary_result();\n         try {\n@@ -4793,10 +5146,12 @@ public class Nimbus {\n         super(\"getLeader\");\n       }\n \n+      @Override\n       public getLeader_args getEmptyArgsInstance() {\n         return new getLeader_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -4806,6 +5161,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public getLeader_result getResult(I iface, getLeader_args args) throws org.apache.storm.thrift.TException {\n         getLeader_result result = new getLeader_result();\n         try {\n@@ -4822,10 +5178,12 @@ public class Nimbus {\n         super(\"isTopologyNameAllowed\");\n       }\n \n+      @Override\n       public isTopologyNameAllowed_args getEmptyArgsInstance() {\n         return new isTopologyNameAllowed_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -4835,6 +5193,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public isTopologyNameAllowed_result getResult(I iface, isTopologyNameAllowed_args args) throws org.apache.storm.thrift.TException {\n         isTopologyNameAllowed_result result = new isTopologyNameAllowed_result();\n         try {\n@@ -4852,10 +5211,12 @@ public class Nimbus {\n         super(\"getTopologyInfoByName\");\n       }\n \n+      @Override\n       public getTopologyInfoByName_args getEmptyArgsInstance() {\n         return new getTopologyInfoByName_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -4865,6 +5226,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public getTopologyInfoByName_result getResult(I iface, getTopologyInfoByName_args args) throws org.apache.storm.thrift.TException {\n         getTopologyInfoByName_result result = new getTopologyInfoByName_result();\n         try {\n@@ -4883,10 +5245,12 @@ public class Nimbus {\n         super(\"getTopologyInfo\");\n       }\n \n+      @Override\n       public getTopologyInfo_args getEmptyArgsInstance() {\n         return new getTopologyInfo_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -4896,6 +5260,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public getTopologyInfo_result getResult(I iface, getTopologyInfo_args args) throws org.apache.storm.thrift.TException {\n         getTopologyInfo_result result = new getTopologyInfo_result();\n         try {\n@@ -4914,10 +5279,12 @@ public class Nimbus {\n         super(\"getTopologyInfoByNameWithOpts\");\n       }\n \n+      @Override\n       public getTopologyInfoByNameWithOpts_args getEmptyArgsInstance() {\n         return new getTopologyInfoByNameWithOpts_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -4927,6 +5294,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public getTopologyInfoByNameWithOpts_result getResult(I iface, getTopologyInfoByNameWithOpts_args args) throws org.apache.storm.thrift.TException {\n         getTopologyInfoByNameWithOpts_result result = new getTopologyInfoByNameWithOpts_result();\n         try {\n@@ -4945,10 +5313,12 @@ public class Nimbus {\n         super(\"getTopologyInfoWithOpts\");\n       }\n \n+      @Override\n       public getTopologyInfoWithOpts_args getEmptyArgsInstance() {\n         return new getTopologyInfoWithOpts_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -4958,6 +5328,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public getTopologyInfoWithOpts_result getResult(I iface, getTopologyInfoWithOpts_args args) throws org.apache.storm.thrift.TException {\n         getTopologyInfoWithOpts_result result = new getTopologyInfoWithOpts_result();\n         try {\n@@ -4976,10 +5347,12 @@ public class Nimbus {\n         super(\"getTopologyPageInfo\");\n       }\n \n+      @Override\n       public getTopologyPageInfo_args getEmptyArgsInstance() {\n         return new getTopologyPageInfo_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -4989,6 +5362,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public getTopologyPageInfo_result getResult(I iface, getTopologyPageInfo_args args) throws org.apache.storm.thrift.TException {\n         getTopologyPageInfo_result result = new getTopologyPageInfo_result();\n         try {\n@@ -5007,10 +5381,12 @@ public class Nimbus {\n         super(\"getSupervisorPageInfo\");\n       }\n \n+      @Override\n       public getSupervisorPageInfo_args getEmptyArgsInstance() {\n         return new getSupervisorPageInfo_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -5020,6 +5396,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public getSupervisorPageInfo_result getResult(I iface, getSupervisorPageInfo_args args) throws org.apache.storm.thrift.TException {\n         getSupervisorPageInfo_result result = new getSupervisorPageInfo_result();\n         try {\n@@ -5038,10 +5415,12 @@ public class Nimbus {\n         super(\"getComponentPageInfo\");\n       }\n \n+      @Override\n       public getComponentPageInfo_args getEmptyArgsInstance() {\n         return new getComponentPageInfo_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -5051,6 +5430,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public getComponentPageInfo_result getResult(I iface, getComponentPageInfo_args args) throws org.apache.storm.thrift.TException {\n         getComponentPageInfo_result result = new getComponentPageInfo_result();\n         try {\n@@ -5069,10 +5449,12 @@ public class Nimbus {\n         super(\"getTopologyConf\");\n       }\n \n+      @Override\n       public getTopologyConf_args getEmptyArgsInstance() {\n         return new getTopologyConf_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -5082,6 +5464,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public getTopologyConf_result getResult(I iface, getTopologyConf_args args) throws org.apache.storm.thrift.TException {\n         getTopologyConf_result result = new getTopologyConf_result();\n         try {\n@@ -5100,10 +5483,12 @@ public class Nimbus {\n         super(\"getTopology\");\n       }\n \n+      @Override\n       public getTopology_args getEmptyArgsInstance() {\n         return new getTopology_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -5113,6 +5498,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public getTopology_result getResult(I iface, getTopology_args args) throws org.apache.storm.thrift.TException {\n         getTopology_result result = new getTopology_result();\n         try {\n@@ -5131,10 +5517,12 @@ public class Nimbus {\n         super(\"getUserTopology\");\n       }\n \n+      @Override\n       public getUserTopology_args getEmptyArgsInstance() {\n         return new getUserTopology_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -5144,6 +5532,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public getUserTopology_result getResult(I iface, getUserTopology_args args) throws org.apache.storm.thrift.TException {\n         getUserTopology_result result = new getUserTopology_result();\n         try {\n@@ -5162,10 +5551,12 @@ public class Nimbus {\n         super(\"getTopologyHistory\");\n       }\n \n+      @Override\n       public getTopologyHistory_args getEmptyArgsInstance() {\n         return new getTopologyHistory_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -5175,6 +5566,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public getTopologyHistory_result getResult(I iface, getTopologyHistory_args args) throws org.apache.storm.thrift.TException {\n         getTopologyHistory_result result = new getTopologyHistory_result();\n         try {\n@@ -5191,10 +5583,12 @@ public class Nimbus {\n         super(\"getOwnerResourceSummaries\");\n       }\n \n+      @Override\n       public getOwnerResourceSummaries_args getEmptyArgsInstance() {\n         return new getOwnerResourceSummaries_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -5204,6 +5598,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public getOwnerResourceSummaries_result getResult(I iface, getOwnerResourceSummaries_args args) throws org.apache.storm.thrift.TException {\n         getOwnerResourceSummaries_result result = new getOwnerResourceSummaries_result();\n         try {\n@@ -5220,10 +5615,12 @@ public class Nimbus {\n         super(\"getSupervisorAssignments\");\n       }\n \n+      @Override\n       public getSupervisorAssignments_args getEmptyArgsInstance() {\n         return new getSupervisorAssignments_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -5233,6 +5630,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public getSupervisorAssignments_result getResult(I iface, getSupervisorAssignments_args args) throws org.apache.storm.thrift.TException {\n         getSupervisorAssignments_result result = new getSupervisorAssignments_result();\n         try {\n@@ -5249,10 +5647,12 @@ public class Nimbus {\n         super(\"sendSupervisorWorkerHeartbeats\");\n       }\n \n+      @Override\n       public sendSupervisorWorkerHeartbeats_args getEmptyArgsInstance() {\n         return new sendSupervisorWorkerHeartbeats_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -5262,6 +5662,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public sendSupervisorWorkerHeartbeats_result getResult(I iface, sendSupervisorWorkerHeartbeats_args args) throws org.apache.storm.thrift.TException {\n         sendSupervisorWorkerHeartbeats_result result = new sendSupervisorWorkerHeartbeats_result();\n         try {\n@@ -5278,10 +5679,12 @@ public class Nimbus {\n         super(\"sendSupervisorWorkerHeartbeat\");\n       }\n \n+      @Override\n       public sendSupervisorWorkerHeartbeat_args getEmptyArgsInstance() {\n         return new sendSupervisorWorkerHeartbeat_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -5291,6 +5694,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public sendSupervisorWorkerHeartbeat_result getResult(I iface, sendSupervisorWorkerHeartbeat_args args) throws org.apache.storm.thrift.TException {\n         sendSupervisorWorkerHeartbeat_result result = new sendSupervisorWorkerHeartbeat_result();\n         try {\n@@ -5309,10 +5713,12 @@ public class Nimbus {\n         super(\"processWorkerMetrics\");\n       }\n \n+      @Override\n       public processWorkerMetrics_args getEmptyArgsInstance() {\n         return new processWorkerMetrics_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -5322,6 +5728,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public processWorkerMetrics_result getResult(I iface, processWorkerMetrics_args args) throws org.apache.storm.thrift.TException {\n         processWorkerMetrics_result result = new processWorkerMetrics_result();\n         iface.processWorkerMetrics(args.metrics);\n@@ -5334,10 +5741,12 @@ public class Nimbus {\n         super(\"isRemoteBlobExists\");\n       }\n \n+      @Override\n       public isRemoteBlobExists_args getEmptyArgsInstance() {\n         return new isRemoteBlobExists_args();\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n@@ -5347,6 +5756,7 @@ public class Nimbus {\n         return false;\n       }\n \n+      @Override\n       public isRemoteBlobExists_result getResult(I iface, isRemoteBlobExists_args args) throws org.apache.storm.thrift.TException {\n         isRemoteBlobExists_result result = new isRemoteBlobExists_result();\n         try {\n@@ -5435,13 +5845,16 @@ public class Nimbus {\n         super(\"submitTopology\");\n       }\n \n+      @Override\n       public submitTopology_args getEmptyArgsInstance() {\n         return new submitTopology_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<Void> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<Void>() { \n+          @Override\n           public void onComplete(Void o) {\n             submitTopology_result result = new submitTopology_result();\n             try {\n@@ -5454,6 +5867,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -5493,10 +5907,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, submitTopology_args args, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.submitTopology(args.name, args.uploadedJarLocation, args.jsonConf, args.topology,resultHandler);\n       }\n@@ -5507,13 +5923,16 @@ public class Nimbus {\n         super(\"submitTopologyWithOpts\");\n       }\n \n+      @Override\n       public submitTopologyWithOpts_args getEmptyArgsInstance() {\n         return new submitTopologyWithOpts_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<Void> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<Void>() { \n+          @Override\n           public void onComplete(Void o) {\n             submitTopologyWithOpts_result result = new submitTopologyWithOpts_result();\n             try {\n@@ -5526,6 +5945,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -5565,10 +5985,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, submitTopologyWithOpts_args args, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.submitTopologyWithOpts(args.name, args.uploadedJarLocation, args.jsonConf, args.topology, args.options,resultHandler);\n       }\n@@ -5579,13 +6001,16 @@ public class Nimbus {\n         super(\"killTopology\");\n       }\n \n+      @Override\n       public killTopology_args getEmptyArgsInstance() {\n         return new killTopology_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<Void> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<Void>() { \n+          @Override\n           public void onComplete(Void o) {\n             killTopology_result result = new killTopology_result();\n             try {\n@@ -5598,6 +6023,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -5633,10 +6059,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, killTopology_args args, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.killTopology(args.name,resultHandler);\n       }\n@@ -5647,13 +6075,16 @@ public class Nimbus {\n         super(\"killTopologyWithOpts\");\n       }\n \n+      @Override\n       public killTopologyWithOpts_args getEmptyArgsInstance() {\n         return new killTopologyWithOpts_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<Void> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<Void>() { \n+          @Override\n           public void onComplete(Void o) {\n             killTopologyWithOpts_result result = new killTopologyWithOpts_result();\n             try {\n@@ -5666,6 +6097,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -5701,10 +6133,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, killTopologyWithOpts_args args, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.killTopologyWithOpts(args.name, args.options,resultHandler);\n       }\n@@ -5715,13 +6149,16 @@ public class Nimbus {\n         super(\"activate\");\n       }\n \n+      @Override\n       public activate_args getEmptyArgsInstance() {\n         return new activate_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<Void> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<Void>() { \n+          @Override\n           public void onComplete(Void o) {\n             activate_result result = new activate_result();\n             try {\n@@ -5734,6 +6171,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -5769,10 +6207,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, activate_args args, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.activate(args.name,resultHandler);\n       }\n@@ -5783,13 +6223,16 @@ public class Nimbus {\n         super(\"deactivate\");\n       }\n \n+      @Override\n       public deactivate_args getEmptyArgsInstance() {\n         return new deactivate_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<Void> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<Void>() { \n+          @Override\n           public void onComplete(Void o) {\n             deactivate_result result = new deactivate_result();\n             try {\n@@ -5802,6 +6245,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -5837,10 +6281,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, deactivate_args args, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.deactivate(args.name,resultHandler);\n       }\n@@ -5851,13 +6297,16 @@ public class Nimbus {\n         super(\"rebalance\");\n       }\n \n+      @Override\n       public rebalance_args getEmptyArgsInstance() {\n         return new rebalance_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<Void> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<Void>() { \n+          @Override\n           public void onComplete(Void o) {\n             rebalance_result result = new rebalance_result();\n             try {\n@@ -5870,6 +6319,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -5909,10 +6359,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, rebalance_args args, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.rebalance(args.name, args.options,resultHandler);\n       }\n@@ -5923,13 +6375,16 @@ public class Nimbus {\n         super(\"setLogConfig\");\n       }\n \n+      @Override\n       public setLogConfig_args getEmptyArgsInstance() {\n         return new setLogConfig_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<Void> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<Void>() { \n+          @Override\n           public void onComplete(Void o) {\n             setLogConfig_result result = new setLogConfig_result();\n             try {\n@@ -5942,6 +6397,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -5969,10 +6425,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, setLogConfig_args args, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.setLogConfig(args.name, args.config,resultHandler);\n       }\n@@ -5983,13 +6441,16 @@ public class Nimbus {\n         super(\"getLogConfig\");\n       }\n \n+      @Override\n       public getLogConfig_args getEmptyArgsInstance() {\n         return new getLogConfig_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<LogConfig> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<LogConfig>() { \n+          @Override\n           public void onComplete(LogConfig o) {\n             getLogConfig_result result = new getLogConfig_result();\n             result.success = o;\n@@ -6003,6 +6464,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -6030,10 +6492,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, getLogConfig_args args, org.apache.storm.thrift.async.AsyncMethodCallback<LogConfig> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.getLogConfig(args.name,resultHandler);\n       }\n@@ -6044,13 +6508,16 @@ public class Nimbus {\n         super(\"debug\");\n       }\n \n+      @Override\n       public debug_args getEmptyArgsInstance() {\n         return new debug_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<Void> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<Void>() { \n+          @Override\n           public void onComplete(Void o) {\n             debug_result result = new debug_result();\n             try {\n@@ -6063,6 +6530,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -6098,10 +6566,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, debug_args args, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.debug(args.name, args.component, args.enable, args.samplingPercentage,resultHandler);\n       }\n@@ -6112,13 +6582,16 @@ public class Nimbus {\n         super(\"setWorkerProfiler\");\n       }\n \n+      @Override\n       public setWorkerProfiler_args getEmptyArgsInstance() {\n         return new setWorkerProfiler_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<Void> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<Void>() { \n+          @Override\n           public void onComplete(Void o) {\n             setWorkerProfiler_result result = new setWorkerProfiler_result();\n             try {\n@@ -6131,6 +6604,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -6158,10 +6632,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, setWorkerProfiler_args args, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.setWorkerProfiler(args.id, args.profileRequest,resultHandler);\n       }\n@@ -6172,13 +6648,16 @@ public class Nimbus {\n         super(\"getComponentPendingProfileActions\");\n       }\n \n+      @Override\n       public getComponentPendingProfileActions_args getEmptyArgsInstance() {\n         return new getComponentPendingProfileActions_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<java.util.List<ProfileRequest>> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<java.util.List<ProfileRequest>>() { \n+          @Override\n           public void onComplete(java.util.List<ProfileRequest> o) {\n             getComponentPendingProfileActions_result result = new getComponentPendingProfileActions_result();\n             result.success = o;\n@@ -6192,6 +6671,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -6219,10 +6699,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, getComponentPendingProfileActions_args args, org.apache.storm.thrift.async.AsyncMethodCallback<java.util.List<ProfileRequest>> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.getComponentPendingProfileActions(args.id, args.component_id, args.action,resultHandler);\n       }\n@@ -6233,13 +6715,16 @@ public class Nimbus {\n         super(\"uploadNewCredentials\");\n       }\n \n+      @Override\n       public uploadNewCredentials_args getEmptyArgsInstance() {\n         return new uploadNewCredentials_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<Void> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<Void>() { \n+          @Override\n           public void onComplete(Void o) {\n             uploadNewCredentials_result result = new uploadNewCredentials_result();\n             try {\n@@ -6252,6 +6737,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -6291,10 +6777,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, uploadNewCredentials_args args, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.uploadNewCredentials(args.name, args.creds,resultHandler);\n       }\n@@ -6305,13 +6793,16 @@ public class Nimbus {\n         super(\"beginCreateBlob\");\n       }\n \n+      @Override\n       public beginCreateBlob_args getEmptyArgsInstance() {\n         return new beginCreateBlob_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String>() { \n+          @Override\n           public void onComplete(java.lang.String o) {\n             beginCreateBlob_result result = new beginCreateBlob_result();\n             result.success = o;\n@@ -6325,6 +6816,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -6360,10 +6852,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, beginCreateBlob_args args, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.beginCreateBlob(args.key, args.meta,resultHandler);\n       }\n@@ -6374,13 +6868,16 @@ public class Nimbus {\n         super(\"beginUpdateBlob\");\n       }\n \n+      @Override\n       public beginUpdateBlob_args getEmptyArgsInstance() {\n         return new beginUpdateBlob_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String>() { \n+          @Override\n           public void onComplete(java.lang.String o) {\n             beginUpdateBlob_result result = new beginUpdateBlob_result();\n             result.success = o;\n@@ -6394,6 +6891,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -6429,10 +6927,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, beginUpdateBlob_args args, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.beginUpdateBlob(args.key,resultHandler);\n       }\n@@ -6443,13 +6943,16 @@ public class Nimbus {\n         super(\"uploadBlobChunk\");\n       }\n \n+      @Override\n       public uploadBlobChunk_args getEmptyArgsInstance() {\n         return new uploadBlobChunk_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<Void> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<Void>() { \n+          @Override\n           public void onComplete(Void o) {\n             uploadBlobChunk_result result = new uploadBlobChunk_result();\n             try {\n@@ -6462,6 +6965,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -6493,10 +6997,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, uploadBlobChunk_args args, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.uploadBlobChunk(args.session, args.chunk,resultHandler);\n       }\n@@ -6507,13 +7013,16 @@ public class Nimbus {\n         super(\"finishBlobUpload\");\n       }\n \n+      @Override\n       public finishBlobUpload_args getEmptyArgsInstance() {\n         return new finishBlobUpload_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<Void> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<Void>() { \n+          @Override\n           public void onComplete(Void o) {\n             finishBlobUpload_result result = new finishBlobUpload_result();\n             try {\n@@ -6526,6 +7035,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -6557,10 +7067,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, finishBlobUpload_args args, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.finishBlobUpload(args.session,resultHandler);\n       }\n@@ -6571,13 +7083,16 @@ public class Nimbus {\n         super(\"cancelBlobUpload\");\n       }\n \n+      @Override\n       public cancelBlobUpload_args getEmptyArgsInstance() {\n         return new cancelBlobUpload_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<Void> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<Void>() { \n+          @Override\n           public void onComplete(Void o) {\n             cancelBlobUpload_result result = new cancelBlobUpload_result();\n             try {\n@@ -6590,6 +7105,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -6621,10 +7137,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, cancelBlobUpload_args args, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.cancelBlobUpload(args.session,resultHandler);\n       }\n@@ -6635,13 +7153,16 @@ public class Nimbus {\n         super(\"getBlobMeta\");\n       }\n \n+      @Override\n       public getBlobMeta_args getEmptyArgsInstance() {\n         return new getBlobMeta_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<ReadableBlobMeta> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<ReadableBlobMeta>() { \n+          @Override\n           public void onComplete(ReadableBlobMeta o) {\n             getBlobMeta_result result = new getBlobMeta_result();\n             result.success = o;\n@@ -6655,6 +7176,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -6690,10 +7212,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, getBlobMeta_args args, org.apache.storm.thrift.async.AsyncMethodCallback<ReadableBlobMeta> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.getBlobMeta(args.key,resultHandler);\n       }\n@@ -6704,13 +7228,16 @@ public class Nimbus {\n         super(\"setBlobMeta\");\n       }\n \n+      @Override\n       public setBlobMeta_args getEmptyArgsInstance() {\n         return new setBlobMeta_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<Void> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<Void>() { \n+          @Override\n           public void onComplete(Void o) {\n             setBlobMeta_result result = new setBlobMeta_result();\n             try {\n@@ -6723,6 +7250,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -6758,10 +7286,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, setBlobMeta_args args, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.setBlobMeta(args.key, args.meta,resultHandler);\n       }\n@@ -6772,13 +7302,16 @@ public class Nimbus {\n         super(\"beginBlobDownload\");\n       }\n \n+      @Override\n       public beginBlobDownload_args getEmptyArgsInstance() {\n         return new beginBlobDownload_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<BeginDownloadResult> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<BeginDownloadResult>() { \n+          @Override\n           public void onComplete(BeginDownloadResult o) {\n             beginBlobDownload_result result = new beginBlobDownload_result();\n             result.success = o;\n@@ -6792,6 +7325,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -6827,10 +7361,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, beginBlobDownload_args args, org.apache.storm.thrift.async.AsyncMethodCallback<BeginDownloadResult> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.beginBlobDownload(args.key,resultHandler);\n       }\n@@ -6841,13 +7377,16 @@ public class Nimbus {\n         super(\"downloadBlobChunk\");\n       }\n \n+      @Override\n       public downloadBlobChunk_args getEmptyArgsInstance() {\n         return new downloadBlobChunk_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<java.nio.ByteBuffer> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<java.nio.ByteBuffer>() { \n+          @Override\n           public void onComplete(java.nio.ByteBuffer o) {\n             downloadBlobChunk_result result = new downloadBlobChunk_result();\n             result.success = o;\n@@ -6861,6 +7400,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -6892,10 +7432,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, downloadBlobChunk_args args, org.apache.storm.thrift.async.AsyncMethodCallback<java.nio.ByteBuffer> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.downloadBlobChunk(args.session,resultHandler);\n       }\n@@ -6906,13 +7448,16 @@ public class Nimbus {\n         super(\"deleteBlob\");\n       }\n \n+      @Override\n       public deleteBlob_args getEmptyArgsInstance() {\n         return new deleteBlob_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<Void> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<Void>() { \n+          @Override\n           public void onComplete(Void o) {\n             deleteBlob_result result = new deleteBlob_result();\n             try {\n@@ -6925,6 +7470,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -6964,10 +7510,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, deleteBlob_args args, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.deleteBlob(args.key,resultHandler);\n       }\n@@ -6978,13 +7526,16 @@ public class Nimbus {\n         super(\"listBlobs\");\n       }\n \n+      @Override\n       public listBlobs_args getEmptyArgsInstance() {\n         return new listBlobs_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<ListBlobsResult> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<ListBlobsResult>() { \n+          @Override\n           public void onComplete(ListBlobsResult o) {\n             listBlobs_result result = new listBlobs_result();\n             result.success = o;\n@@ -6998,6 +7549,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -7025,10 +7577,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, listBlobs_args args, org.apache.storm.thrift.async.AsyncMethodCallback<ListBlobsResult> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.listBlobs(args.session,resultHandler);\n       }\n@@ -7039,13 +7593,16 @@ public class Nimbus {\n         super(\"getBlobReplication\");\n       }\n \n+      @Override\n       public getBlobReplication_args getEmptyArgsInstance() {\n         return new getBlobReplication_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.Integer> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.Integer>() { \n+          @Override\n           public void onComplete(java.lang.Integer o) {\n             getBlobReplication_result result = new getBlobReplication_result();\n             result.success = o;\n@@ -7060,6 +7617,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -7095,10 +7653,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, getBlobReplication_args args, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.Integer> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.getBlobReplication(args.key,resultHandler);\n       }\n@@ -7109,13 +7669,16 @@ public class Nimbus {\n         super(\"updateBlobReplication\");\n       }\n \n+      @Override\n       public updateBlobReplication_args getEmptyArgsInstance() {\n         return new updateBlobReplication_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.Integer> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.Integer>() { \n+          @Override\n           public void onComplete(java.lang.Integer o) {\n             updateBlobReplication_result result = new updateBlobReplication_result();\n             result.success = o;\n@@ -7130,6 +7693,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -7165,10 +7729,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, updateBlobReplication_args args, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.Integer> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.updateBlobReplication(args.key, args.replication,resultHandler);\n       }\n@@ -7179,13 +7745,16 @@ public class Nimbus {\n         super(\"createStateInZookeeper\");\n       }\n \n+      @Override\n       public createStateInZookeeper_args getEmptyArgsInstance() {\n         return new createStateInZookeeper_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<Void> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<Void>() { \n+          @Override\n           public void onComplete(Void o) {\n             createStateInZookeeper_result result = new createStateInZookeeper_result();\n             try {\n@@ -7198,6 +7767,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -7225,10 +7795,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, createStateInZookeeper_args args, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.createStateInZookeeper(args.key,resultHandler);\n       }\n@@ -7239,13 +7811,16 @@ public class Nimbus {\n         super(\"beginFileUpload\");\n       }\n \n+      @Override\n       public beginFileUpload_args getEmptyArgsInstance() {\n         return new beginFileUpload_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String>() { \n+          @Override\n           public void onComplete(java.lang.String o) {\n             beginFileUpload_result result = new beginFileUpload_result();\n             result.success = o;\n@@ -7259,6 +7834,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -7290,10 +7866,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, beginFileUpload_args args, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.beginFileUpload(resultHandler);\n       }\n@@ -7304,13 +7882,16 @@ public class Nimbus {\n         super(\"uploadChunk\");\n       }\n \n+      @Override\n       public uploadChunk_args getEmptyArgsInstance() {\n         return new uploadChunk_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<Void> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<Void>() { \n+          @Override\n           public void onComplete(Void o) {\n             uploadChunk_result result = new uploadChunk_result();\n             try {\n@@ -7323,6 +7904,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -7354,10 +7936,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, uploadChunk_args args, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.uploadChunk(args.location, args.chunk,resultHandler);\n       }\n@@ -7368,13 +7952,16 @@ public class Nimbus {\n         super(\"finishFileUpload\");\n       }\n \n+      @Override\n       public finishFileUpload_args getEmptyArgsInstance() {\n         return new finishFileUpload_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<Void> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<Void>() { \n+          @Override\n           public void onComplete(Void o) {\n             finishFileUpload_result result = new finishFileUpload_result();\n             try {\n@@ -7387,6 +7974,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -7418,10 +8006,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, finishFileUpload_args args, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.finishFileUpload(args.location,resultHandler);\n       }\n@@ -7432,13 +8022,16 @@ public class Nimbus {\n         super(\"downloadChunk\");\n       }\n \n+      @Override\n       public downloadChunk_args getEmptyArgsInstance() {\n         return new downloadChunk_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<java.nio.ByteBuffer> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<java.nio.ByteBuffer>() { \n+          @Override\n           public void onComplete(java.nio.ByteBuffer o) {\n             downloadChunk_result result = new downloadChunk_result();\n             result.success = o;\n@@ -7452,6 +8045,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -7483,10 +8077,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, downloadChunk_args args, org.apache.storm.thrift.async.AsyncMethodCallback<java.nio.ByteBuffer> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.downloadChunk(args.id,resultHandler);\n       }\n@@ -7497,13 +8093,16 @@ public class Nimbus {\n         super(\"getNimbusConf\");\n       }\n \n+      @Override\n       public getNimbusConf_args getEmptyArgsInstance() {\n         return new getNimbusConf_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String>() { \n+          @Override\n           public void onComplete(java.lang.String o) {\n             getNimbusConf_result result = new getNimbusConf_result();\n             result.success = o;\n@@ -7517,6 +8116,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -7548,10 +8148,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, getNimbusConf_args args, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.getNimbusConf(resultHandler);\n       }\n@@ -7562,13 +8164,16 @@ public class Nimbus {\n         super(\"getClusterInfo\");\n       }\n \n+      @Override\n       public getClusterInfo_args getEmptyArgsInstance() {\n         return new getClusterInfo_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<ClusterSummary> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<ClusterSummary>() { \n+          @Override\n           public void onComplete(ClusterSummary o) {\n             getClusterInfo_result result = new getClusterInfo_result();\n             result.success = o;\n@@ -7582,6 +8187,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -7613,10 +8219,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, getClusterInfo_args args, org.apache.storm.thrift.async.AsyncMethodCallback<ClusterSummary> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.getClusterInfo(resultHandler);\n       }\n@@ -7627,13 +8235,16 @@ public class Nimbus {\n         super(\"getTopologySummaries\");\n       }\n \n+      @Override\n       public getTopologySummaries_args getEmptyArgsInstance() {\n         return new getTopologySummaries_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<java.util.List<TopologySummary>> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<java.util.List<TopologySummary>>() { \n+          @Override\n           public void onComplete(java.util.List<TopologySummary> o) {\n             getTopologySummaries_result result = new getTopologySummaries_result();\n             result.success = o;\n@@ -7647,6 +8258,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -7678,10 +8290,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, getTopologySummaries_args args, org.apache.storm.thrift.async.AsyncMethodCallback<java.util.List<TopologySummary>> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.getTopologySummaries(resultHandler);\n       }\n@@ -7692,13 +8306,16 @@ public class Nimbus {\n         super(\"getTopologySummaryByName\");\n       }\n \n+      @Override\n       public getTopologySummaryByName_args getEmptyArgsInstance() {\n         return new getTopologySummaryByName_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<TopologySummary> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<TopologySummary>() { \n+          @Override\n           public void onComplete(TopologySummary o) {\n             getTopologySummaryByName_result result = new getTopologySummaryByName_result();\n             result.success = o;\n@@ -7712,6 +8329,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -7747,10 +8365,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, getTopologySummaryByName_args args, org.apache.storm.thrift.async.AsyncMethodCallback<TopologySummary> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.getTopologySummaryByName(args.name,resultHandler);\n       }\n@@ -7761,13 +8381,16 @@ public class Nimbus {\n         super(\"getTopologySummary\");\n       }\n \n+      @Override\n       public getTopologySummary_args getEmptyArgsInstance() {\n         return new getTopologySummary_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<TopologySummary> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<TopologySummary>() { \n+          @Override\n           public void onComplete(TopologySummary o) {\n             getTopologySummary_result result = new getTopologySummary_result();\n             result.success = o;\n@@ -7781,6 +8404,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -7816,10 +8440,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, getTopologySummary_args args, org.apache.storm.thrift.async.AsyncMethodCallback<TopologySummary> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.getTopologySummary(args.id,resultHandler);\n       }\n@@ -7830,13 +8456,16 @@ public class Nimbus {\n         super(\"getLeader\");\n       }\n \n+      @Override\n       public getLeader_args getEmptyArgsInstance() {\n         return new getLeader_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<NimbusSummary> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<NimbusSummary>() { \n+          @Override\n           public void onComplete(NimbusSummary o) {\n             getLeader_result result = new getLeader_result();\n             result.success = o;\n@@ -7850,6 +8479,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -7881,10 +8511,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, getLeader_args args, org.apache.storm.thrift.async.AsyncMethodCallback<NimbusSummary> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.getLeader(resultHandler);\n       }\n@@ -7895,13 +8527,16 @@ public class Nimbus {\n         super(\"isTopologyNameAllowed\");\n       }\n \n+      @Override\n       public isTopologyNameAllowed_args getEmptyArgsInstance() {\n         return new isTopologyNameAllowed_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.Boolean> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.Boolean>() { \n+          @Override\n           public void onComplete(java.lang.Boolean o) {\n             isTopologyNameAllowed_result result = new isTopologyNameAllowed_result();\n             result.success = o;\n@@ -7916,6 +8551,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -7947,10 +8583,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, isTopologyNameAllowed_args args, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.Boolean> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.isTopologyNameAllowed(args.name,resultHandler);\n       }\n@@ -7961,13 +8599,16 @@ public class Nimbus {\n         super(\"getTopologyInfoByName\");\n       }\n \n+      @Override\n       public getTopologyInfoByName_args getEmptyArgsInstance() {\n         return new getTopologyInfoByName_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<TopologyInfo> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<TopologyInfo>() { \n+          @Override\n           public void onComplete(TopologyInfo o) {\n             getTopologyInfoByName_result result = new getTopologyInfoByName_result();\n             result.success = o;\n@@ -7981,6 +8622,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -8016,10 +8658,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, getTopologyInfoByName_args args, org.apache.storm.thrift.async.AsyncMethodCallback<TopologyInfo> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.getTopologyInfoByName(args.name,resultHandler);\n       }\n@@ -8030,13 +8674,16 @@ public class Nimbus {\n         super(\"getTopologyInfo\");\n       }\n \n+      @Override\n       public getTopologyInfo_args getEmptyArgsInstance() {\n         return new getTopologyInfo_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<TopologyInfo> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<TopologyInfo>() { \n+          @Override\n           public void onComplete(TopologyInfo o) {\n             getTopologyInfo_result result = new getTopologyInfo_result();\n             result.success = o;\n@@ -8050,6 +8697,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -8085,10 +8733,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, getTopologyInfo_args args, org.apache.storm.thrift.async.AsyncMethodCallback<TopologyInfo> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.getTopologyInfo(args.id,resultHandler);\n       }\n@@ -8099,13 +8749,16 @@ public class Nimbus {\n         super(\"getTopologyInfoByNameWithOpts\");\n       }\n \n+      @Override\n       public getTopologyInfoByNameWithOpts_args getEmptyArgsInstance() {\n         return new getTopologyInfoByNameWithOpts_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<TopologyInfo> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<TopologyInfo>() { \n+          @Override\n           public void onComplete(TopologyInfo o) {\n             getTopologyInfoByNameWithOpts_result result = new getTopologyInfoByNameWithOpts_result();\n             result.success = o;\n@@ -8119,6 +8772,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -8154,10 +8808,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, getTopologyInfoByNameWithOpts_args args, org.apache.storm.thrift.async.AsyncMethodCallback<TopologyInfo> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.getTopologyInfoByNameWithOpts(args.name, args.options,resultHandler);\n       }\n@@ -8168,13 +8824,16 @@ public class Nimbus {\n         super(\"getTopologyInfoWithOpts\");\n       }\n \n+      @Override\n       public getTopologyInfoWithOpts_args getEmptyArgsInstance() {\n         return new getTopologyInfoWithOpts_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<TopologyInfo> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<TopologyInfo>() { \n+          @Override\n           public void onComplete(TopologyInfo o) {\n             getTopologyInfoWithOpts_result result = new getTopologyInfoWithOpts_result();\n             result.success = o;\n@@ -8188,6 +8847,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -8223,10 +8883,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, getTopologyInfoWithOpts_args args, org.apache.storm.thrift.async.AsyncMethodCallback<TopologyInfo> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.getTopologyInfoWithOpts(args.id, args.options,resultHandler);\n       }\n@@ -8237,13 +8899,16 @@ public class Nimbus {\n         super(\"getTopologyPageInfo\");\n       }\n \n+      @Override\n       public getTopologyPageInfo_args getEmptyArgsInstance() {\n         return new getTopologyPageInfo_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<TopologyPageInfo> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<TopologyPageInfo>() { \n+          @Override\n           public void onComplete(TopologyPageInfo o) {\n             getTopologyPageInfo_result result = new getTopologyPageInfo_result();\n             result.success = o;\n@@ -8257,6 +8922,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -8292,10 +8958,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, getTopologyPageInfo_args args, org.apache.storm.thrift.async.AsyncMethodCallback<TopologyPageInfo> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.getTopologyPageInfo(args.id, args.window, args.is_include_sys,resultHandler);\n       }\n@@ -8306,13 +8974,16 @@ public class Nimbus {\n         super(\"getSupervisorPageInfo\");\n       }\n \n+      @Override\n       public getSupervisorPageInfo_args getEmptyArgsInstance() {\n         return new getSupervisorPageInfo_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<SupervisorPageInfo> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<SupervisorPageInfo>() { \n+          @Override\n           public void onComplete(SupervisorPageInfo o) {\n             getSupervisorPageInfo_result result = new getSupervisorPageInfo_result();\n             result.success = o;\n@@ -8326,6 +8997,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -8361,10 +9033,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, getSupervisorPageInfo_args args, org.apache.storm.thrift.async.AsyncMethodCallback<SupervisorPageInfo> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.getSupervisorPageInfo(args.id, args.host, args.is_include_sys,resultHandler);\n       }\n@@ -8375,13 +9049,16 @@ public class Nimbus {\n         super(\"getComponentPageInfo\");\n       }\n \n+      @Override\n       public getComponentPageInfo_args getEmptyArgsInstance() {\n         return new getComponentPageInfo_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<ComponentPageInfo> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<ComponentPageInfo>() { \n+          @Override\n           public void onComplete(ComponentPageInfo o) {\n             getComponentPageInfo_result result = new getComponentPageInfo_result();\n             result.success = o;\n@@ -8395,6 +9072,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -8430,10 +9108,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, getComponentPageInfo_args args, org.apache.storm.thrift.async.AsyncMethodCallback<ComponentPageInfo> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.getComponentPageInfo(args.topology_id, args.component_id, args.window, args.is_include_sys,resultHandler);\n       }\n@@ -8444,13 +9124,16 @@ public class Nimbus {\n         super(\"getTopologyConf\");\n       }\n \n+      @Override\n       public getTopologyConf_args getEmptyArgsInstance() {\n         return new getTopologyConf_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String>() { \n+          @Override\n           public void onComplete(java.lang.String o) {\n             getTopologyConf_result result = new getTopologyConf_result();\n             result.success = o;\n@@ -8464,6 +9147,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -8499,10 +9183,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, getTopologyConf_args args, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.getTopologyConf(args.id,resultHandler);\n       }\n@@ -8513,13 +9199,16 @@ public class Nimbus {\n         super(\"getTopology\");\n       }\n \n+      @Override\n       public getTopology_args getEmptyArgsInstance() {\n         return new getTopology_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<StormTopology> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<StormTopology>() { \n+          @Override\n           public void onComplete(StormTopology o) {\n             getTopology_result result = new getTopology_result();\n             result.success = o;\n@@ -8533,6 +9222,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -8568,10 +9258,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, getTopology_args args, org.apache.storm.thrift.async.AsyncMethodCallback<StormTopology> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.getTopology(args.id,resultHandler);\n       }\n@@ -8582,13 +9274,16 @@ public class Nimbus {\n         super(\"getUserTopology\");\n       }\n \n+      @Override\n       public getUserTopology_args getEmptyArgsInstance() {\n         return new getUserTopology_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<StormTopology> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<StormTopology>() { \n+          @Override\n           public void onComplete(StormTopology o) {\n             getUserTopology_result result = new getUserTopology_result();\n             result.success = o;\n@@ -8602,6 +9297,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -8637,10 +9333,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, getUserTopology_args args, org.apache.storm.thrift.async.AsyncMethodCallback<StormTopology> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.getUserTopology(args.id,resultHandler);\n       }\n@@ -8651,13 +9349,16 @@ public class Nimbus {\n         super(\"getTopologyHistory\");\n       }\n \n+      @Override\n       public getTopologyHistory_args getEmptyArgsInstance() {\n         return new getTopologyHistory_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<TopologyHistoryInfo> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<TopologyHistoryInfo>() { \n+          @Override\n           public void onComplete(TopologyHistoryInfo o) {\n             getTopologyHistory_result result = new getTopologyHistory_result();\n             result.success = o;\n@@ -8671,6 +9372,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -8702,10 +9404,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, getTopologyHistory_args args, org.apache.storm.thrift.async.AsyncMethodCallback<TopologyHistoryInfo> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.getTopologyHistory(args.user,resultHandler);\n       }\n@@ -8716,13 +9420,16 @@ public class Nimbus {\n         super(\"getOwnerResourceSummaries\");\n       }\n \n+      @Override\n       public getOwnerResourceSummaries_args getEmptyArgsInstance() {\n         return new getOwnerResourceSummaries_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<java.util.List<OwnerResourceSummary>> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<java.util.List<OwnerResourceSummary>>() { \n+          @Override\n           public void onComplete(java.util.List<OwnerResourceSummary> o) {\n             getOwnerResourceSummaries_result result = new getOwnerResourceSummaries_result();\n             result.success = o;\n@@ -8736,6 +9443,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -8767,10 +9475,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, getOwnerResourceSummaries_args args, org.apache.storm.thrift.async.AsyncMethodCallback<java.util.List<OwnerResourceSummary>> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.getOwnerResourceSummaries(args.owner,resultHandler);\n       }\n@@ -8781,13 +9491,16 @@ public class Nimbus {\n         super(\"getSupervisorAssignments\");\n       }\n \n+      @Override\n       public getSupervisorAssignments_args getEmptyArgsInstance() {\n         return new getSupervisorAssignments_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<SupervisorAssignments> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<SupervisorAssignments>() { \n+          @Override\n           public void onComplete(SupervisorAssignments o) {\n             getSupervisorAssignments_result result = new getSupervisorAssignments_result();\n             result.success = o;\n@@ -8801,6 +9514,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -8832,10 +9546,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, getSupervisorAssignments_args args, org.apache.storm.thrift.async.AsyncMethodCallback<SupervisorAssignments> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.getSupervisorAssignments(args.node,resultHandler);\n       }\n@@ -8846,13 +9562,16 @@ public class Nimbus {\n         super(\"sendSupervisorWorkerHeartbeats\");\n       }\n \n+      @Override\n       public sendSupervisorWorkerHeartbeats_args getEmptyArgsInstance() {\n         return new sendSupervisorWorkerHeartbeats_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<Void> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<Void>() { \n+          @Override\n           public void onComplete(Void o) {\n             sendSupervisorWorkerHeartbeats_result result = new sendSupervisorWorkerHeartbeats_result();\n             try {\n@@ -8865,6 +9584,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -8896,10 +9616,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, sendSupervisorWorkerHeartbeats_args args, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.sendSupervisorWorkerHeartbeats(args.heartbeats,resultHandler);\n       }\n@@ -8910,13 +9632,16 @@ public class Nimbus {\n         super(\"sendSupervisorWorkerHeartbeat\");\n       }\n \n+      @Override\n       public sendSupervisorWorkerHeartbeat_args getEmptyArgsInstance() {\n         return new sendSupervisorWorkerHeartbeat_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<Void> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<Void>() { \n+          @Override\n           public void onComplete(Void o) {\n             sendSupervisorWorkerHeartbeat_result result = new sendSupervisorWorkerHeartbeat_result();\n             try {\n@@ -8929,6 +9654,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -8964,10 +9690,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, sendSupervisorWorkerHeartbeat_args args, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.sendSupervisorWorkerHeartbeat(args.heatbeat,resultHandler);\n       }\n@@ -8978,13 +9706,16 @@ public class Nimbus {\n         super(\"processWorkerMetrics\");\n       }\n \n+      @Override\n       public processWorkerMetrics_args getEmptyArgsInstance() {\n         return new processWorkerMetrics_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<Void> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<Void>() { \n+          @Override\n           public void onComplete(Void o) {\n             processWorkerMetrics_result result = new processWorkerMetrics_result();\n             try {\n@@ -8997,6 +9728,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -9024,10 +9756,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, processWorkerMetrics_args args, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.processWorkerMetrics(args.metrics,resultHandler);\n       }\n@@ -9038,13 +9772,16 @@ public class Nimbus {\n         super(\"isRemoteBlobExists\");\n       }\n \n+      @Override\n       public isRemoteBlobExists_args getEmptyArgsInstance() {\n         return new isRemoteBlobExists_args();\n       }\n \n+      @Override\n       public org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.Boolean> getResultHandler(final org.apache.storm.thrift.server.AbstractNonblockingServer.AsyncFrameBuffer fb, final int seqid) {\n         final org.apache.storm.thrift.AsyncProcessFunction fcall = this;\n         return new org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.Boolean>() { \n+          @Override\n           public void onComplete(java.lang.Boolean o) {\n             isRemoteBlobExists_result result = new isRemoteBlobExists_result();\n             result.success = o;\n@@ -9059,6 +9796,7 @@ public class Nimbus {\n               onError(e);\n             }\n           }\n+          @Override\n           public void onError(java.lang.Exception e) {\n             byte msgType = org.apache.storm.thrift.protocol.TMessageType.REPLY;\n             org.apache.storm.thrift.TSerializable msg;\n@@ -9090,10 +9828,12 @@ public class Nimbus {\n         };\n       }\n \n+      @Override\n       protected boolean isOneway() {\n         return false;\n       }\n \n+      @Override\n       public void start(I iface, isRemoteBlobExists_args args, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.Boolean> resultHandler) throws org.apache.storm.thrift.TException {\n         iface.isRemoteBlobExists(args.blobKey,resultHandler);\n       }\n@@ -9101,6 +9841,7 @@ public class Nimbus {\n \n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class submitTopology_args implements org.apache.storm.thrift.TBase<submitTopology_args, submitTopology_args._Fields>, java.io.Serializable, Cloneable, Comparable<submitTopology_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"submitTopology_args\");\n \n@@ -9177,10 +9918,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -9236,6 +9979,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public submitTopology_args deepCopy() {\n       return new submitTopology_args(this);\n     }\n@@ -9344,6 +10088,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case NAME:\n@@ -9382,6 +10127,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case NAME:\n@@ -9401,6 +10147,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -9421,8 +10168,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof submitTopology_args)\n         return this.equals((submitTopology_args)that);\n       return false;\n@@ -9504,7 +10249,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_name()).compareTo(other.is_set_name());\n+      lastComparison = java.lang.Boolean.compare(is_set_name(), other.is_set_name());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -9514,7 +10259,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_uploadedJarLocation()).compareTo(other.is_set_uploadedJarLocation());\n+      lastComparison = java.lang.Boolean.compare(is_set_uploadedJarLocation(), other.is_set_uploadedJarLocation());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -9524,7 +10269,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_jsonConf()).compareTo(other.is_set_jsonConf());\n+      lastComparison = java.lang.Boolean.compare(is_set_jsonConf(), other.is_set_jsonConf());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -9534,7 +10279,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_topology()).compareTo(other.is_set_topology());\n+      lastComparison = java.lang.Boolean.compare(is_set_topology(), other.is_set_topology());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -9548,14 +10293,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -9625,6 +10373,7 @@ public class Nimbus {\n     }\n \n     private static class submitTopology_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public submitTopology_argsStandardScheme getScheme() {\n         return new submitTopology_argsStandardScheme();\n       }\n@@ -9632,6 +10381,7 @@ public class Nimbus {\n \n     private static class submitTopology_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<submitTopology_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, submitTopology_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -9684,6 +10434,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, submitTopology_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -9715,6 +10466,7 @@ public class Nimbus {\n     }\n \n     private static class submitTopology_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public submitTopology_argsTupleScheme getScheme() {\n         return new submitTopology_argsTupleScheme();\n       }\n@@ -9782,6 +10534,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class submitTopology_result implements org.apache.storm.thrift.TBase<submitTopology_result, submitTopology_result._Fields>, java.io.Serializable, Cloneable, Comparable<submitTopology_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"submitTopology_result\");\n \n@@ -9853,10 +10606,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -9905,6 +10660,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public submitTopology_result deepCopy() {\n       return new submitTopology_result(this);\n     }\n@@ -9988,6 +10744,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case E:\n@@ -10018,6 +10775,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case E:\n@@ -10034,6 +10792,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -10052,8 +10811,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof submitTopology_result)\n         return this.equals((submitTopology_result)that);\n       return false;\n@@ -10122,7 +10879,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_e()).compareTo(other.is_set_e());\n+      lastComparison = java.lang.Boolean.compare(is_set_e(), other.is_set_e());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -10132,7 +10889,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_ite()).compareTo(other.is_set_ite());\n+      lastComparison = java.lang.Boolean.compare(is_set_ite(), other.is_set_ite());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -10142,7 +10899,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -10156,10 +10913,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -10222,6 +10981,7 @@ public class Nimbus {\n     }\n \n     private static class submitTopology_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public submitTopology_resultStandardScheme getScheme() {\n         return new submitTopology_resultStandardScheme();\n       }\n@@ -10229,6 +10989,7 @@ public class Nimbus {\n \n     private static class submitTopology_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<submitTopology_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, submitTopology_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -10275,6 +11036,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, submitTopology_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -10301,6 +11063,7 @@ public class Nimbus {\n     }\n \n     private static class submitTopology_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public submitTopology_resultTupleScheme getScheme() {\n         return new submitTopology_resultTupleScheme();\n       }\n@@ -10360,6 +11123,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class submitTopologyWithOpts_args implements org.apache.storm.thrift.TBase<submitTopologyWithOpts_args, submitTopologyWithOpts_args._Fields>, java.io.Serializable, Cloneable, Comparable<submitTopologyWithOpts_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"submitTopologyWithOpts_args\");\n \n@@ -10441,10 +11205,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -10507,6 +11273,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public submitTopologyWithOpts_args deepCopy() {\n       return new submitTopologyWithOpts_args(this);\n     }\n@@ -10640,6 +11407,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case NAME:\n@@ -10686,6 +11454,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case NAME:\n@@ -10708,6 +11477,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -10730,8 +11500,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof submitTopologyWithOpts_args)\n         return this.equals((submitTopologyWithOpts_args)that);\n       return false;\n@@ -10826,7 +11594,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_name()).compareTo(other.is_set_name());\n+      lastComparison = java.lang.Boolean.compare(is_set_name(), other.is_set_name());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -10836,7 +11604,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_uploadedJarLocation()).compareTo(other.is_set_uploadedJarLocation());\n+      lastComparison = java.lang.Boolean.compare(is_set_uploadedJarLocation(), other.is_set_uploadedJarLocation());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -10846,7 +11614,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_jsonConf()).compareTo(other.is_set_jsonConf());\n+      lastComparison = java.lang.Boolean.compare(is_set_jsonConf(), other.is_set_jsonConf());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -10856,7 +11624,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_topology()).compareTo(other.is_set_topology());\n+      lastComparison = java.lang.Boolean.compare(is_set_topology(), other.is_set_topology());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -10866,7 +11634,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_options()).compareTo(other.is_set_options());\n+      lastComparison = java.lang.Boolean.compare(is_set_options(), other.is_set_options());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -10880,14 +11648,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -10968,6 +11739,7 @@ public class Nimbus {\n     }\n \n     private static class submitTopologyWithOpts_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public submitTopologyWithOpts_argsStandardScheme getScheme() {\n         return new submitTopologyWithOpts_argsStandardScheme();\n       }\n@@ -10975,6 +11747,7 @@ public class Nimbus {\n \n     private static class submitTopologyWithOpts_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<submitTopologyWithOpts_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, submitTopologyWithOpts_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -11036,6 +11809,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, submitTopologyWithOpts_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -11072,6 +11846,7 @@ public class Nimbus {\n     }\n \n     private static class submitTopologyWithOpts_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public submitTopologyWithOpts_argsTupleScheme getScheme() {\n         return new submitTopologyWithOpts_argsTupleScheme();\n       }\n@@ -11150,6 +11925,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class submitTopologyWithOpts_result implements org.apache.storm.thrift.TBase<submitTopologyWithOpts_result, submitTopologyWithOpts_result._Fields>, java.io.Serializable, Cloneable, Comparable<submitTopologyWithOpts_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"submitTopologyWithOpts_result\");\n \n@@ -11221,10 +11997,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -11273,6 +12051,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public submitTopologyWithOpts_result deepCopy() {\n       return new submitTopologyWithOpts_result(this);\n     }\n@@ -11356,6 +12135,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case E:\n@@ -11386,6 +12166,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case E:\n@@ -11402,6 +12183,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -11420,8 +12202,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof submitTopologyWithOpts_result)\n         return this.equals((submitTopologyWithOpts_result)that);\n       return false;\n@@ -11490,7 +12270,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_e()).compareTo(other.is_set_e());\n+      lastComparison = java.lang.Boolean.compare(is_set_e(), other.is_set_e());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -11500,7 +12280,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_ite()).compareTo(other.is_set_ite());\n+      lastComparison = java.lang.Boolean.compare(is_set_ite(), other.is_set_ite());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -11510,7 +12290,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -11524,10 +12304,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -11590,6 +12372,7 @@ public class Nimbus {\n     }\n \n     private static class submitTopologyWithOpts_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public submitTopologyWithOpts_resultStandardScheme getScheme() {\n         return new submitTopologyWithOpts_resultStandardScheme();\n       }\n@@ -11597,6 +12380,7 @@ public class Nimbus {\n \n     private static class submitTopologyWithOpts_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<submitTopologyWithOpts_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, submitTopologyWithOpts_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -11643,6 +12427,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, submitTopologyWithOpts_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -11669,6 +12454,7 @@ public class Nimbus {\n     }\n \n     private static class submitTopologyWithOpts_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public submitTopologyWithOpts_resultTupleScheme getScheme() {\n         return new submitTopologyWithOpts_resultTupleScheme();\n       }\n@@ -11728,6 +12514,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class killTopology_args implements org.apache.storm.thrift.TBase<killTopology_args, killTopology_args._Fields>, java.io.Serializable, Cloneable, Comparable<killTopology_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"killTopology_args\");\n \n@@ -11789,10 +12576,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -11827,6 +12616,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public killTopology_args deepCopy() {\n       return new killTopology_args(this);\n     }\n@@ -11860,6 +12650,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case NAME:\n@@ -11874,6 +12665,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case NAME:\n@@ -11884,6 +12676,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -11898,8 +12691,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof killTopology_args)\n         return this.equals((killTopology_args)that);\n       return false;\n@@ -11942,7 +12733,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_name()).compareTo(other.is_set_name());\n+      lastComparison = java.lang.Boolean.compare(is_set_name(), other.is_set_name());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -11956,14 +12747,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -12006,6 +12800,7 @@ public class Nimbus {\n     }\n \n     private static class killTopology_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public killTopology_argsStandardScheme getScheme() {\n         return new killTopology_argsStandardScheme();\n       }\n@@ -12013,6 +12808,7 @@ public class Nimbus {\n \n     private static class killTopology_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<killTopology_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, killTopology_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -12040,6 +12836,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, killTopology_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -12056,6 +12853,7 @@ public class Nimbus {\n     }\n \n     private static class killTopology_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public killTopology_argsTupleScheme getScheme() {\n         return new killTopology_argsTupleScheme();\n       }\n@@ -12092,6 +12890,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class killTopology_result implements org.apache.storm.thrift.TBase<killTopology_result, killTopology_result._Fields>, java.io.Serializable, Cloneable, Comparable<killTopology_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"killTopology_result\");\n \n@@ -12158,10 +12957,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -12203,6 +13004,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public killTopology_result deepCopy() {\n       return new killTopology_result(this);\n     }\n@@ -12261,6 +13063,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case E:\n@@ -12283,6 +13086,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case E:\n@@ -12296,6 +13100,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -12312,8 +13117,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof killTopology_result)\n         return this.equals((killTopology_result)that);\n       return false;\n@@ -12369,7 +13172,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_e()).compareTo(other.is_set_e());\n+      lastComparison = java.lang.Boolean.compare(is_set_e(), other.is_set_e());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -12379,7 +13182,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -12393,10 +13196,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -12451,6 +13256,7 @@ public class Nimbus {\n     }\n \n     private static class killTopology_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public killTopology_resultStandardScheme getScheme() {\n         return new killTopology_resultStandardScheme();\n       }\n@@ -12458,6 +13264,7 @@ public class Nimbus {\n \n     private static class killTopology_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<killTopology_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, killTopology_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -12495,6 +13302,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, killTopology_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -12516,6 +13324,7 @@ public class Nimbus {\n     }\n \n     private static class killTopology_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public killTopology_resultTupleScheme getScheme() {\n         return new killTopology_resultTupleScheme();\n       }\n@@ -12564,6 +13373,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class killTopologyWithOpts_args implements org.apache.storm.thrift.TBase<killTopologyWithOpts_args, killTopologyWithOpts_args._Fields>, java.io.Serializable, Cloneable, Comparable<killTopologyWithOpts_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"killTopologyWithOpts_args\");\n \n@@ -12630,10 +13440,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -12675,6 +13487,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public killTopologyWithOpts_args deepCopy() {\n       return new killTopologyWithOpts_args(this);\n     }\n@@ -12733,6 +13546,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case NAME:\n@@ -12755,6 +13569,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case NAME:\n@@ -12768,6 +13583,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -12784,8 +13600,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof killTopologyWithOpts_args)\n         return this.equals((killTopologyWithOpts_args)that);\n       return false;\n@@ -12841,7 +13655,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_name()).compareTo(other.is_set_name());\n+      lastComparison = java.lang.Boolean.compare(is_set_name(), other.is_set_name());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -12851,7 +13665,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_options()).compareTo(other.is_set_options());\n+      lastComparison = java.lang.Boolean.compare(is_set_options(), other.is_set_options());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -12865,14 +13679,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -12926,6 +13743,7 @@ public class Nimbus {\n     }\n \n     private static class killTopologyWithOpts_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public killTopologyWithOpts_argsStandardScheme getScheme() {\n         return new killTopologyWithOpts_argsStandardScheme();\n       }\n@@ -12933,6 +13751,7 @@ public class Nimbus {\n \n     private static class killTopologyWithOpts_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<killTopologyWithOpts_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, killTopologyWithOpts_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -12969,6 +13788,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, killTopologyWithOpts_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -12990,6 +13810,7 @@ public class Nimbus {\n     }\n \n     private static class killTopologyWithOpts_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public killTopologyWithOpts_argsTupleScheme getScheme() {\n         return new killTopologyWithOpts_argsTupleScheme();\n       }\n@@ -13037,6 +13858,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class killTopologyWithOpts_result implements org.apache.storm.thrift.TBase<killTopologyWithOpts_result, killTopologyWithOpts_result._Fields>, java.io.Serializable, Cloneable, Comparable<killTopologyWithOpts_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"killTopologyWithOpts_result\");\n \n@@ -13103,10 +13925,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -13148,6 +13972,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public killTopologyWithOpts_result deepCopy() {\n       return new killTopologyWithOpts_result(this);\n     }\n@@ -13206,6 +14031,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case E:\n@@ -13228,6 +14054,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case E:\n@@ -13241,6 +14068,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -13257,8 +14085,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof killTopologyWithOpts_result)\n         return this.equals((killTopologyWithOpts_result)that);\n       return false;\n@@ -13314,7 +14140,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_e()).compareTo(other.is_set_e());\n+      lastComparison = java.lang.Boolean.compare(is_set_e(), other.is_set_e());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -13324,7 +14150,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -13338,10 +14164,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -13396,6 +14224,7 @@ public class Nimbus {\n     }\n \n     private static class killTopologyWithOpts_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public killTopologyWithOpts_resultStandardScheme getScheme() {\n         return new killTopologyWithOpts_resultStandardScheme();\n       }\n@@ -13403,6 +14232,7 @@ public class Nimbus {\n \n     private static class killTopologyWithOpts_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<killTopologyWithOpts_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, killTopologyWithOpts_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -13440,6 +14270,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, killTopologyWithOpts_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -13461,6 +14292,7 @@ public class Nimbus {\n     }\n \n     private static class killTopologyWithOpts_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public killTopologyWithOpts_resultTupleScheme getScheme() {\n         return new killTopologyWithOpts_resultTupleScheme();\n       }\n@@ -13509,6 +14341,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class activate_args implements org.apache.storm.thrift.TBase<activate_args, activate_args._Fields>, java.io.Serializable, Cloneable, Comparable<activate_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"activate_args\");\n \n@@ -13570,10 +14403,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -13608,6 +14443,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public activate_args deepCopy() {\n       return new activate_args(this);\n     }\n@@ -13641,6 +14477,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case NAME:\n@@ -13655,6 +14492,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case NAME:\n@@ -13665,6 +14503,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -13679,8 +14518,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof activate_args)\n         return this.equals((activate_args)that);\n       return false;\n@@ -13723,7 +14560,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_name()).compareTo(other.is_set_name());\n+      lastComparison = java.lang.Boolean.compare(is_set_name(), other.is_set_name());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -13737,14 +14574,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -13787,6 +14627,7 @@ public class Nimbus {\n     }\n \n     private static class activate_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public activate_argsStandardScheme getScheme() {\n         return new activate_argsStandardScheme();\n       }\n@@ -13794,6 +14635,7 @@ public class Nimbus {\n \n     private static class activate_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<activate_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, activate_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -13821,6 +14663,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, activate_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -13837,6 +14680,7 @@ public class Nimbus {\n     }\n \n     private static class activate_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public activate_argsTupleScheme getScheme() {\n         return new activate_argsTupleScheme();\n       }\n@@ -13873,6 +14717,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class activate_result implements org.apache.storm.thrift.TBase<activate_result, activate_result._Fields>, java.io.Serializable, Cloneable, Comparable<activate_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"activate_result\");\n \n@@ -13939,10 +14784,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -13984,6 +14831,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public activate_result deepCopy() {\n       return new activate_result(this);\n     }\n@@ -14042,6 +14890,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case E:\n@@ -14064,6 +14913,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case E:\n@@ -14077,6 +14927,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -14093,8 +14944,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof activate_result)\n         return this.equals((activate_result)that);\n       return false;\n@@ -14150,7 +14999,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_e()).compareTo(other.is_set_e());\n+      lastComparison = java.lang.Boolean.compare(is_set_e(), other.is_set_e());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -14160,7 +15009,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -14174,10 +15023,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -14232,6 +15083,7 @@ public class Nimbus {\n     }\n \n     private static class activate_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public activate_resultStandardScheme getScheme() {\n         return new activate_resultStandardScheme();\n       }\n@@ -14239,6 +15091,7 @@ public class Nimbus {\n \n     private static class activate_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<activate_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, activate_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -14276,6 +15129,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, activate_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -14297,6 +15151,7 @@ public class Nimbus {\n     }\n \n     private static class activate_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public activate_resultTupleScheme getScheme() {\n         return new activate_resultTupleScheme();\n       }\n@@ -14345,6 +15200,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class deactivate_args implements org.apache.storm.thrift.TBase<deactivate_args, deactivate_args._Fields>, java.io.Serializable, Cloneable, Comparable<deactivate_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"deactivate_args\");\n \n@@ -14406,10 +15262,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -14444,6 +15302,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public deactivate_args deepCopy() {\n       return new deactivate_args(this);\n     }\n@@ -14477,6 +15336,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case NAME:\n@@ -14491,6 +15351,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case NAME:\n@@ -14501,6 +15362,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -14515,8 +15377,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof deactivate_args)\n         return this.equals((deactivate_args)that);\n       return false;\n@@ -14559,7 +15419,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_name()).compareTo(other.is_set_name());\n+      lastComparison = java.lang.Boolean.compare(is_set_name(), other.is_set_name());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -14573,14 +15433,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -14623,6 +15486,7 @@ public class Nimbus {\n     }\n \n     private static class deactivate_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public deactivate_argsStandardScheme getScheme() {\n         return new deactivate_argsStandardScheme();\n       }\n@@ -14630,6 +15494,7 @@ public class Nimbus {\n \n     private static class deactivate_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<deactivate_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, deactivate_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -14657,6 +15522,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, deactivate_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -14673,6 +15539,7 @@ public class Nimbus {\n     }\n \n     private static class deactivate_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public deactivate_argsTupleScheme getScheme() {\n         return new deactivate_argsTupleScheme();\n       }\n@@ -14709,6 +15576,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class deactivate_result implements org.apache.storm.thrift.TBase<deactivate_result, deactivate_result._Fields>, java.io.Serializable, Cloneable, Comparable<deactivate_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"deactivate_result\");\n \n@@ -14775,10 +15643,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -14820,6 +15690,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public deactivate_result deepCopy() {\n       return new deactivate_result(this);\n     }\n@@ -14878,6 +15749,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case E:\n@@ -14900,6 +15772,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case E:\n@@ -14913,6 +15786,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -14929,8 +15803,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof deactivate_result)\n         return this.equals((deactivate_result)that);\n       return false;\n@@ -14986,7 +15858,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_e()).compareTo(other.is_set_e());\n+      lastComparison = java.lang.Boolean.compare(is_set_e(), other.is_set_e());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -14996,7 +15868,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -15010,10 +15882,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -15068,6 +15942,7 @@ public class Nimbus {\n     }\n \n     private static class deactivate_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public deactivate_resultStandardScheme getScheme() {\n         return new deactivate_resultStandardScheme();\n       }\n@@ -15075,6 +15950,7 @@ public class Nimbus {\n \n     private static class deactivate_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<deactivate_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, deactivate_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -15112,6 +15988,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, deactivate_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -15133,6 +16010,7 @@ public class Nimbus {\n     }\n \n     private static class deactivate_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public deactivate_resultTupleScheme getScheme() {\n         return new deactivate_resultTupleScheme();\n       }\n@@ -15181,6 +16059,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class rebalance_args implements org.apache.storm.thrift.TBase<rebalance_args, rebalance_args._Fields>, java.io.Serializable, Cloneable, Comparable<rebalance_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"rebalance_args\");\n \n@@ -15247,10 +16126,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -15292,6 +16173,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public rebalance_args deepCopy() {\n       return new rebalance_args(this);\n     }\n@@ -15350,6 +16232,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case NAME:\n@@ -15372,6 +16255,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case NAME:\n@@ -15385,6 +16269,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -15401,8 +16286,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof rebalance_args)\n         return this.equals((rebalance_args)that);\n       return false;\n@@ -15458,7 +16341,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_name()).compareTo(other.is_set_name());\n+      lastComparison = java.lang.Boolean.compare(is_set_name(), other.is_set_name());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -15468,7 +16351,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_options()).compareTo(other.is_set_options());\n+      lastComparison = java.lang.Boolean.compare(is_set_options(), other.is_set_options());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -15482,14 +16365,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -15543,6 +16429,7 @@ public class Nimbus {\n     }\n \n     private static class rebalance_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public rebalance_argsStandardScheme getScheme() {\n         return new rebalance_argsStandardScheme();\n       }\n@@ -15550,6 +16437,7 @@ public class Nimbus {\n \n     private static class rebalance_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<rebalance_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, rebalance_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -15586,6 +16474,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, rebalance_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -15607,6 +16496,7 @@ public class Nimbus {\n     }\n \n     private static class rebalance_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public rebalance_argsTupleScheme getScheme() {\n         return new rebalance_argsTupleScheme();\n       }\n@@ -15654,6 +16544,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class rebalance_result implements org.apache.storm.thrift.TBase<rebalance_result, rebalance_result._Fields>, java.io.Serializable, Cloneable, Comparable<rebalance_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"rebalance_result\");\n \n@@ -15725,10 +16616,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -15777,6 +16670,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public rebalance_result deepCopy() {\n       return new rebalance_result(this);\n     }\n@@ -15860,6 +16754,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case E:\n@@ -15890,6 +16785,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case E:\n@@ -15906,6 +16802,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -15924,8 +16821,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof rebalance_result)\n         return this.equals((rebalance_result)that);\n       return false;\n@@ -15994,7 +16889,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_e()).compareTo(other.is_set_e());\n+      lastComparison = java.lang.Boolean.compare(is_set_e(), other.is_set_e());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -16004,7 +16899,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_ite()).compareTo(other.is_set_ite());\n+      lastComparison = java.lang.Boolean.compare(is_set_ite(), other.is_set_ite());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -16014,7 +16909,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -16028,10 +16923,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -16094,6 +16991,7 @@ public class Nimbus {\n     }\n \n     private static class rebalance_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public rebalance_resultStandardScheme getScheme() {\n         return new rebalance_resultStandardScheme();\n       }\n@@ -16101,6 +16999,7 @@ public class Nimbus {\n \n     private static class rebalance_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<rebalance_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, rebalance_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -16147,6 +17046,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, rebalance_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -16173,6 +17073,7 @@ public class Nimbus {\n     }\n \n     private static class rebalance_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public rebalance_resultTupleScheme getScheme() {\n         return new rebalance_resultTupleScheme();\n       }\n@@ -16232,6 +17133,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class setLogConfig_args implements org.apache.storm.thrift.TBase<setLogConfig_args, setLogConfig_args._Fields>, java.io.Serializable, Cloneable, Comparable<setLogConfig_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"setLogConfig_args\");\n \n@@ -16298,10 +17200,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -16343,6 +17247,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public setLogConfig_args deepCopy() {\n       return new setLogConfig_args(this);\n     }\n@@ -16401,6 +17306,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case NAME:\n@@ -16423,6 +17329,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case NAME:\n@@ -16436,6 +17343,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -16452,8 +17360,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof setLogConfig_args)\n         return this.equals((setLogConfig_args)that);\n       return false;\n@@ -16509,7 +17415,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_name()).compareTo(other.is_set_name());\n+      lastComparison = java.lang.Boolean.compare(is_set_name(), other.is_set_name());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -16519,7 +17425,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_config()).compareTo(other.is_set_config());\n+      lastComparison = java.lang.Boolean.compare(is_set_config(), other.is_set_config());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -16533,14 +17439,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -16594,6 +17503,7 @@ public class Nimbus {\n     }\n \n     private static class setLogConfig_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public setLogConfig_argsStandardScheme getScheme() {\n         return new setLogConfig_argsStandardScheme();\n       }\n@@ -16601,6 +17511,7 @@ public class Nimbus {\n \n     private static class setLogConfig_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<setLogConfig_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, setLogConfig_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -16637,6 +17548,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, setLogConfig_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -16658,6 +17570,7 @@ public class Nimbus {\n     }\n \n     private static class setLogConfig_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public setLogConfig_argsTupleScheme getScheme() {\n         return new setLogConfig_argsTupleScheme();\n       }\n@@ -16705,6 +17618,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class setLogConfig_result implements org.apache.storm.thrift.TBase<setLogConfig_result, setLogConfig_result._Fields>, java.io.Serializable, Cloneable, Comparable<setLogConfig_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"setLogConfig_result\");\n \n@@ -16762,10 +17676,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -16786,6 +17702,7 @@ public class Nimbus {\n     public setLogConfig_result(setLogConfig_result other) {\n     }\n \n+    @Override\n     public setLogConfig_result deepCopy() {\n       return new setLogConfig_result(this);\n     }\n@@ -16794,12 +17711,14 @@ public class Nimbus {\n     public void clear() {\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       }\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       }\n@@ -16807,6 +17726,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -16819,8 +17739,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof setLogConfig_result)\n         return this.equals((setLogConfig_result)that);\n       return false;\n@@ -16854,10 +17772,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -16897,6 +17817,7 @@ public class Nimbus {\n     }\n \n     private static class setLogConfig_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public setLogConfig_resultStandardScheme getScheme() {\n         return new setLogConfig_resultStandardScheme();\n       }\n@@ -16904,6 +17825,7 @@ public class Nimbus {\n \n     private static class setLogConfig_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<setLogConfig_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, setLogConfig_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -16923,6 +17845,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, setLogConfig_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -16934,6 +17857,7 @@ public class Nimbus {\n     }\n \n     private static class setLogConfig_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public setLogConfig_resultTupleScheme getScheme() {\n         return new setLogConfig_resultTupleScheme();\n       }\n@@ -16957,6 +17881,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getLogConfig_args implements org.apache.storm.thrift.TBase<getLogConfig_args, getLogConfig_args._Fields>, java.io.Serializable, Cloneable, Comparable<getLogConfig_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getLogConfig_args\");\n \n@@ -17018,10 +17943,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -17056,6 +17983,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public getLogConfig_args deepCopy() {\n       return new getLogConfig_args(this);\n     }\n@@ -17089,6 +18017,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case NAME:\n@@ -17103,6 +18032,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case NAME:\n@@ -17113,6 +18043,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -17127,8 +18058,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getLogConfig_args)\n         return this.equals((getLogConfig_args)that);\n       return false;\n@@ -17171,7 +18100,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_name()).compareTo(other.is_set_name());\n+      lastComparison = java.lang.Boolean.compare(is_set_name(), other.is_set_name());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -17185,14 +18114,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -17235,6 +18167,7 @@ public class Nimbus {\n     }\n \n     private static class getLogConfig_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getLogConfig_argsStandardScheme getScheme() {\n         return new getLogConfig_argsStandardScheme();\n       }\n@@ -17242,6 +18175,7 @@ public class Nimbus {\n \n     private static class getLogConfig_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getLogConfig_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getLogConfig_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -17269,6 +18203,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getLogConfig_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -17285,6 +18220,7 @@ public class Nimbus {\n     }\n \n     private static class getLogConfig_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getLogConfig_argsTupleScheme getScheme() {\n         return new getLogConfig_argsTupleScheme();\n       }\n@@ -17321,6 +18257,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getLogConfig_result implements org.apache.storm.thrift.TBase<getLogConfig_result, getLogConfig_result._Fields>, java.io.Serializable, Cloneable, Comparable<getLogConfig_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getLogConfig_result\");\n \n@@ -17382,10 +18319,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -17420,6 +18359,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public getLogConfig_result deepCopy() {\n       return new getLogConfig_result(this);\n     }\n@@ -17453,6 +18393,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case SUCCESS:\n@@ -17467,6 +18408,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case SUCCESS:\n@@ -17477,6 +18419,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -17491,8 +18434,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getLogConfig_result)\n         return this.equals((getLogConfig_result)that);\n       return false;\n@@ -17535,7 +18476,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_success()).compareTo(other.is_set_success());\n+      lastComparison = java.lang.Boolean.compare(is_set_success(), other.is_set_success());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -17549,10 +18490,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -17602,6 +18545,7 @@ public class Nimbus {\n     }\n \n     private static class getLogConfig_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getLogConfig_resultStandardScheme getScheme() {\n         return new getLogConfig_resultStandardScheme();\n       }\n@@ -17609,6 +18553,7 @@ public class Nimbus {\n \n     private static class getLogConfig_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getLogConfig_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getLogConfig_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -17637,6 +18582,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getLogConfig_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -17653,6 +18599,7 @@ public class Nimbus {\n     }\n \n     private static class getLogConfig_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getLogConfig_resultTupleScheme getScheme() {\n         return new getLogConfig_resultTupleScheme();\n       }\n@@ -17690,6 +18637,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class debug_args implements org.apache.storm.thrift.TBase<debug_args, debug_args._Fields>, java.io.Serializable, Cloneable, Comparable<debug_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"debug_args\");\n \n@@ -17766,10 +18714,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -17827,6 +18777,7 @@ public class Nimbus {\n       this.samplingPercentage = other.samplingPercentage;\n     }\n \n+    @Override\n     public debug_args deepCopy() {\n       return new debug_args(this);\n     }\n@@ -17933,6 +18884,7 @@ public class Nimbus {\n       __isset_bitfield = org.apache.storm.thrift.EncodingUtils.setBit(__isset_bitfield, __SAMPLINGPERCENTAGE_ISSET_ID, value);\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case NAME:\n@@ -17971,6 +18923,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case NAME:\n@@ -17990,6 +18943,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -18010,8 +18964,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof debug_args)\n         return this.equals((debug_args)that);\n       return false;\n@@ -18089,7 +19041,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_name()).compareTo(other.is_set_name());\n+      lastComparison = java.lang.Boolean.compare(is_set_name(), other.is_set_name());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -18099,7 +19051,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_component()).compareTo(other.is_set_component());\n+      lastComparison = java.lang.Boolean.compare(is_set_component(), other.is_set_component());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -18109,7 +19061,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_enable()).compareTo(other.is_set_enable());\n+      lastComparison = java.lang.Boolean.compare(is_set_enable(), other.is_set_enable());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -18119,7 +19071,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_samplingPercentage()).compareTo(other.is_set_samplingPercentage());\n+      lastComparison = java.lang.Boolean.compare(is_set_samplingPercentage(), other.is_set_samplingPercentage());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -18133,14 +19085,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -18201,6 +19156,7 @@ public class Nimbus {\n     }\n \n     private static class debug_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public debug_argsStandardScheme getScheme() {\n         return new debug_argsStandardScheme();\n       }\n@@ -18208,6 +19164,7 @@ public class Nimbus {\n \n     private static class debug_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<debug_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, debug_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -18259,6 +19216,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, debug_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -18286,6 +19244,7 @@ public class Nimbus {\n     }\n \n     private static class debug_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public debug_argsTupleScheme getScheme() {\n         return new debug_argsTupleScheme();\n       }\n@@ -18352,6 +19311,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class debug_result implements org.apache.storm.thrift.TBase<debug_result, debug_result._Fields>, java.io.Serializable, Cloneable, Comparable<debug_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"debug_result\");\n \n@@ -18418,10 +19378,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -18463,6 +19425,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public debug_result deepCopy() {\n       return new debug_result(this);\n     }\n@@ -18521,6 +19484,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case E:\n@@ -18543,6 +19507,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case E:\n@@ -18556,6 +19521,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -18572,8 +19538,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof debug_result)\n         return this.equals((debug_result)that);\n       return false;\n@@ -18629,7 +19593,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_e()).compareTo(other.is_set_e());\n+      lastComparison = java.lang.Boolean.compare(is_set_e(), other.is_set_e());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -18639,7 +19603,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -18653,10 +19617,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -18711,6 +19677,7 @@ public class Nimbus {\n     }\n \n     private static class debug_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public debug_resultStandardScheme getScheme() {\n         return new debug_resultStandardScheme();\n       }\n@@ -18718,6 +19685,7 @@ public class Nimbus {\n \n     private static class debug_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<debug_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, debug_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -18755,6 +19723,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, debug_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -18776,6 +19745,7 @@ public class Nimbus {\n     }\n \n     private static class debug_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public debug_resultTupleScheme getScheme() {\n         return new debug_resultTupleScheme();\n       }\n@@ -18824,6 +19794,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class setWorkerProfiler_args implements org.apache.storm.thrift.TBase<setWorkerProfiler_args, setWorkerProfiler_args._Fields>, java.io.Serializable, Cloneable, Comparable<setWorkerProfiler_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"setWorkerProfiler_args\");\n \n@@ -18890,10 +19861,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -18935,6 +19908,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public setWorkerProfiler_args deepCopy() {\n       return new setWorkerProfiler_args(this);\n     }\n@@ -18993,6 +19967,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case ID:\n@@ -19015,6 +19990,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case ID:\n@@ -19028,6 +20004,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -19044,8 +20021,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof setWorkerProfiler_args)\n         return this.equals((setWorkerProfiler_args)that);\n       return false;\n@@ -19101,7 +20076,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_id()).compareTo(other.is_set_id());\n+      lastComparison = java.lang.Boolean.compare(is_set_id(), other.is_set_id());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -19111,7 +20086,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_profileRequest()).compareTo(other.is_set_profileRequest());\n+      lastComparison = java.lang.Boolean.compare(is_set_profileRequest(), other.is_set_profileRequest());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -19125,14 +20100,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -19186,6 +20164,7 @@ public class Nimbus {\n     }\n \n     private static class setWorkerProfiler_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public setWorkerProfiler_argsStandardScheme getScheme() {\n         return new setWorkerProfiler_argsStandardScheme();\n       }\n@@ -19193,6 +20172,7 @@ public class Nimbus {\n \n     private static class setWorkerProfiler_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<setWorkerProfiler_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, setWorkerProfiler_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -19229,6 +20209,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, setWorkerProfiler_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -19250,6 +20231,7 @@ public class Nimbus {\n     }\n \n     private static class setWorkerProfiler_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public setWorkerProfiler_argsTupleScheme getScheme() {\n         return new setWorkerProfiler_argsTupleScheme();\n       }\n@@ -19297,6 +20279,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class setWorkerProfiler_result implements org.apache.storm.thrift.TBase<setWorkerProfiler_result, setWorkerProfiler_result._Fields>, java.io.Serializable, Cloneable, Comparable<setWorkerProfiler_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"setWorkerProfiler_result\");\n \n@@ -19354,10 +20337,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -19378,6 +20363,7 @@ public class Nimbus {\n     public setWorkerProfiler_result(setWorkerProfiler_result other) {\n     }\n \n+    @Override\n     public setWorkerProfiler_result deepCopy() {\n       return new setWorkerProfiler_result(this);\n     }\n@@ -19386,12 +20372,14 @@ public class Nimbus {\n     public void clear() {\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       }\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       }\n@@ -19399,6 +20387,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -19411,8 +20400,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof setWorkerProfiler_result)\n         return this.equals((setWorkerProfiler_result)that);\n       return false;\n@@ -19446,10 +20433,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -19489,6 +20478,7 @@ public class Nimbus {\n     }\n \n     private static class setWorkerProfiler_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public setWorkerProfiler_resultStandardScheme getScheme() {\n         return new setWorkerProfiler_resultStandardScheme();\n       }\n@@ -19496,6 +20486,7 @@ public class Nimbus {\n \n     private static class setWorkerProfiler_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<setWorkerProfiler_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, setWorkerProfiler_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -19515,6 +20506,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, setWorkerProfiler_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -19526,6 +20518,7 @@ public class Nimbus {\n     }\n \n     private static class setWorkerProfiler_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public setWorkerProfiler_resultTupleScheme getScheme() {\n         return new setWorkerProfiler_resultTupleScheme();\n       }\n@@ -19549,6 +20542,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getComponentPendingProfileActions_args implements org.apache.storm.thrift.TBase<getComponentPendingProfileActions_args, getComponentPendingProfileActions_args._Fields>, java.io.Serializable, Cloneable, Comparable<getComponentPendingProfileActions_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getComponentPendingProfileActions_args\");\n \n@@ -19624,10 +20618,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -19676,6 +20672,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public getComponentPendingProfileActions_args deepCopy() {\n       return new getComponentPendingProfileActions_args(this);\n     }\n@@ -19767,6 +20764,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case ID:\n@@ -19797,6 +20795,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case ID:\n@@ -19813,6 +20812,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -19831,8 +20831,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getComponentPendingProfileActions_args)\n         return this.equals((getComponentPendingProfileActions_args)that);\n       return false;\n@@ -19901,7 +20899,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_id()).compareTo(other.is_set_id());\n+      lastComparison = java.lang.Boolean.compare(is_set_id(), other.is_set_id());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -19911,7 +20909,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_component_id()).compareTo(other.is_set_component_id());\n+      lastComparison = java.lang.Boolean.compare(is_set_component_id(), other.is_set_component_id());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -19921,7 +20919,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_action()).compareTo(other.is_set_action());\n+      lastComparison = java.lang.Boolean.compare(is_set_action(), other.is_set_action());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -19935,14 +20933,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -20001,6 +21002,7 @@ public class Nimbus {\n     }\n \n     private static class getComponentPendingProfileActions_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getComponentPendingProfileActions_argsStandardScheme getScheme() {\n         return new getComponentPendingProfileActions_argsStandardScheme();\n       }\n@@ -20008,6 +21010,7 @@ public class Nimbus {\n \n     private static class getComponentPendingProfileActions_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getComponentPendingProfileActions_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getComponentPendingProfileActions_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -20051,6 +21054,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getComponentPendingProfileActions_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -20077,6 +21081,7 @@ public class Nimbus {\n     }\n \n     private static class getComponentPendingProfileActions_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getComponentPendingProfileActions_argsTupleScheme getScheme() {\n         return new getComponentPendingProfileActions_argsTupleScheme();\n       }\n@@ -20133,6 +21138,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getComponentPendingProfileActions_result implements org.apache.storm.thrift.TBase<getComponentPendingProfileActions_result, getComponentPendingProfileActions_result._Fields>, java.io.Serializable, Cloneable, Comparable<getComponentPendingProfileActions_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getComponentPendingProfileActions_result\");\n \n@@ -20194,10 +21200,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -20237,6 +21245,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public getComponentPendingProfileActions_result deepCopy() {\n       return new getComponentPendingProfileActions_result(this);\n     }\n@@ -20286,6 +21295,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case SUCCESS:\n@@ -20300,6 +21310,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case SUCCESS:\n@@ -20310,6 +21321,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -20324,8 +21336,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getComponentPendingProfileActions_result)\n         return this.equals((getComponentPendingProfileActions_result)that);\n       return false;\n@@ -20368,7 +21378,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_success()).compareTo(other.is_set_success());\n+      lastComparison = java.lang.Boolean.compare(is_set_success(), other.is_set_success());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -20382,10 +21392,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -20432,6 +21444,7 @@ public class Nimbus {\n     }\n \n     private static class getComponentPendingProfileActions_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getComponentPendingProfileActions_resultStandardScheme getScheme() {\n         return new getComponentPendingProfileActions_resultStandardScheme();\n       }\n@@ -20439,6 +21452,7 @@ public class Nimbus {\n \n     private static class getComponentPendingProfileActions_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getComponentPendingProfileActions_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getComponentPendingProfileActions_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -20477,6 +21491,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getComponentPendingProfileActions_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -20500,6 +21515,7 @@ public class Nimbus {\n     }\n \n     private static class getComponentPendingProfileActions_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getComponentPendingProfileActions_resultTupleScheme getScheme() {\n         return new getComponentPendingProfileActions_resultTupleScheme();\n       }\n@@ -20532,7 +21548,7 @@ public class Nimbus {\n         java.util.BitSet incoming = iprot.readBitSet(1);\n         if (incoming.get(0)) {\n           {\n-            org.apache.storm.thrift.protocol.TList _list975 = new org.apache.storm.thrift.protocol.TList(org.apache.storm.thrift.protocol.TType.STRUCT, iprot.readI32());\n+            org.apache.storm.thrift.protocol.TList _list975 = iprot.readListBegin(org.apache.storm.thrift.protocol.TType.STRUCT);\n             struct.success = new java.util.ArrayList<ProfileRequest>(_list975.size);\n             @org.apache.storm.thrift.annotation.Nullable ProfileRequest _elem976;\n             for (int _i977 = 0; _i977 < _list975.size; ++_i977)\n@@ -20552,6 +21568,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class uploadNewCredentials_args implements org.apache.storm.thrift.TBase<uploadNewCredentials_args, uploadNewCredentials_args._Fields>, java.io.Serializable, Cloneable, Comparable<uploadNewCredentials_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"uploadNewCredentials_args\");\n \n@@ -20618,10 +21635,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -20663,6 +21682,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public uploadNewCredentials_args deepCopy() {\n       return new uploadNewCredentials_args(this);\n     }\n@@ -20721,6 +21741,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case NAME:\n@@ -20743,6 +21764,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case NAME:\n@@ -20756,6 +21778,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -20772,8 +21795,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof uploadNewCredentials_args)\n         return this.equals((uploadNewCredentials_args)that);\n       return false;\n@@ -20829,7 +21850,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_name()).compareTo(other.is_set_name());\n+      lastComparison = java.lang.Boolean.compare(is_set_name(), other.is_set_name());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -20839,7 +21860,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_creds()).compareTo(other.is_set_creds());\n+      lastComparison = java.lang.Boolean.compare(is_set_creds(), other.is_set_creds());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -20853,14 +21874,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -20914,6 +21938,7 @@ public class Nimbus {\n     }\n \n     private static class uploadNewCredentials_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public uploadNewCredentials_argsStandardScheme getScheme() {\n         return new uploadNewCredentials_argsStandardScheme();\n       }\n@@ -20921,6 +21946,7 @@ public class Nimbus {\n \n     private static class uploadNewCredentials_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<uploadNewCredentials_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, uploadNewCredentials_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -20957,6 +21983,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, uploadNewCredentials_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -20978,6 +22005,7 @@ public class Nimbus {\n     }\n \n     private static class uploadNewCredentials_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public uploadNewCredentials_argsTupleScheme getScheme() {\n         return new uploadNewCredentials_argsTupleScheme();\n       }\n@@ -21025,6 +22053,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class uploadNewCredentials_result implements org.apache.storm.thrift.TBase<uploadNewCredentials_result, uploadNewCredentials_result._Fields>, java.io.Serializable, Cloneable, Comparable<uploadNewCredentials_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"uploadNewCredentials_result\");\n \n@@ -21096,10 +22125,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -21148,6 +22179,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public uploadNewCredentials_result deepCopy() {\n       return new uploadNewCredentials_result(this);\n     }\n@@ -21231,6 +22263,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case E:\n@@ -21261,6 +22294,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case E:\n@@ -21277,6 +22311,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -21295,8 +22330,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof uploadNewCredentials_result)\n         return this.equals((uploadNewCredentials_result)that);\n       return false;\n@@ -21365,7 +22398,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_e()).compareTo(other.is_set_e());\n+      lastComparison = java.lang.Boolean.compare(is_set_e(), other.is_set_e());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -21375,7 +22408,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_ite()).compareTo(other.is_set_ite());\n+      lastComparison = java.lang.Boolean.compare(is_set_ite(), other.is_set_ite());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -21385,7 +22418,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -21399,10 +22432,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -21465,6 +22500,7 @@ public class Nimbus {\n     }\n \n     private static class uploadNewCredentials_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public uploadNewCredentials_resultStandardScheme getScheme() {\n         return new uploadNewCredentials_resultStandardScheme();\n       }\n@@ -21472,6 +22508,7 @@ public class Nimbus {\n \n     private static class uploadNewCredentials_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<uploadNewCredentials_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, uploadNewCredentials_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -21518,6 +22555,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, uploadNewCredentials_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -21544,6 +22582,7 @@ public class Nimbus {\n     }\n \n     private static class uploadNewCredentials_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public uploadNewCredentials_resultTupleScheme getScheme() {\n         return new uploadNewCredentials_resultTupleScheme();\n       }\n@@ -21603,6 +22642,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class beginCreateBlob_args implements org.apache.storm.thrift.TBase<beginCreateBlob_args, beginCreateBlob_args._Fields>, java.io.Serializable, Cloneable, Comparable<beginCreateBlob_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"beginCreateBlob_args\");\n \n@@ -21669,10 +22709,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -21714,6 +22756,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public beginCreateBlob_args deepCopy() {\n       return new beginCreateBlob_args(this);\n     }\n@@ -21772,6 +22815,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case KEY:\n@@ -21794,6 +22838,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case KEY:\n@@ -21807,6 +22852,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -21823,8 +22869,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof beginCreateBlob_args)\n         return this.equals((beginCreateBlob_args)that);\n       return false;\n@@ -21880,7 +22924,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_key()).compareTo(other.is_set_key());\n+      lastComparison = java.lang.Boolean.compare(is_set_key(), other.is_set_key());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -21890,7 +22934,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_meta()).compareTo(other.is_set_meta());\n+      lastComparison = java.lang.Boolean.compare(is_set_meta(), other.is_set_meta());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -21904,14 +22948,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -21965,6 +23012,7 @@ public class Nimbus {\n     }\n \n     private static class beginCreateBlob_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public beginCreateBlob_argsStandardScheme getScheme() {\n         return new beginCreateBlob_argsStandardScheme();\n       }\n@@ -21972,6 +23020,7 @@ public class Nimbus {\n \n     private static class beginCreateBlob_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<beginCreateBlob_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, beginCreateBlob_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -22008,6 +23057,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, beginCreateBlob_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -22029,6 +23079,7 @@ public class Nimbus {\n     }\n \n     private static class beginCreateBlob_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public beginCreateBlob_argsTupleScheme getScheme() {\n         return new beginCreateBlob_argsTupleScheme();\n       }\n@@ -22076,6 +23127,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class beginCreateBlob_result implements org.apache.storm.thrift.TBase<beginCreateBlob_result, beginCreateBlob_result._Fields>, java.io.Serializable, Cloneable, Comparable<beginCreateBlob_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"beginCreateBlob_result\");\n \n@@ -22147,10 +23199,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -22199,6 +23253,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public beginCreateBlob_result deepCopy() {\n       return new beginCreateBlob_result(this);\n     }\n@@ -22282,6 +23337,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case SUCCESS:\n@@ -22312,6 +23368,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case SUCCESS:\n@@ -22328,6 +23385,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -22346,8 +23404,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof beginCreateBlob_result)\n         return this.equals((beginCreateBlob_result)that);\n       return false;\n@@ -22416,7 +23472,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_success()).compareTo(other.is_set_success());\n+      lastComparison = java.lang.Boolean.compare(is_set_success(), other.is_set_success());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -22426,7 +23482,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -22436,7 +23492,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_kae()).compareTo(other.is_set_kae());\n+      lastComparison = java.lang.Boolean.compare(is_set_kae(), other.is_set_kae());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -22450,10 +23506,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -22516,6 +23574,7 @@ public class Nimbus {\n     }\n \n     private static class beginCreateBlob_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public beginCreateBlob_resultStandardScheme getScheme() {\n         return new beginCreateBlob_resultStandardScheme();\n       }\n@@ -22523,6 +23582,7 @@ public class Nimbus {\n \n     private static class beginCreateBlob_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<beginCreateBlob_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, beginCreateBlob_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -22568,6 +23628,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, beginCreateBlob_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -22594,6 +23655,7 @@ public class Nimbus {\n     }\n \n     private static class beginCreateBlob_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public beginCreateBlob_resultTupleScheme getScheme() {\n         return new beginCreateBlob_resultTupleScheme();\n       }\n@@ -22652,6 +23714,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class beginUpdateBlob_args implements org.apache.storm.thrift.TBase<beginUpdateBlob_args, beginUpdateBlob_args._Fields>, java.io.Serializable, Cloneable, Comparable<beginUpdateBlob_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"beginUpdateBlob_args\");\n \n@@ -22713,10 +23776,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -22751,6 +23816,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public beginUpdateBlob_args deepCopy() {\n       return new beginUpdateBlob_args(this);\n     }\n@@ -22784,6 +23850,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case KEY:\n@@ -22798,6 +23865,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case KEY:\n@@ -22808,6 +23876,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -22822,8 +23891,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof beginUpdateBlob_args)\n         return this.equals((beginUpdateBlob_args)that);\n       return false;\n@@ -22866,7 +23933,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_key()).compareTo(other.is_set_key());\n+      lastComparison = java.lang.Boolean.compare(is_set_key(), other.is_set_key());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -22880,14 +23947,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -22930,6 +24000,7 @@ public class Nimbus {\n     }\n \n     private static class beginUpdateBlob_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public beginUpdateBlob_argsStandardScheme getScheme() {\n         return new beginUpdateBlob_argsStandardScheme();\n       }\n@@ -22937,6 +24008,7 @@ public class Nimbus {\n \n     private static class beginUpdateBlob_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<beginUpdateBlob_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, beginUpdateBlob_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -22964,6 +24036,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, beginUpdateBlob_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -22980,6 +24053,7 @@ public class Nimbus {\n     }\n \n     private static class beginUpdateBlob_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public beginUpdateBlob_argsTupleScheme getScheme() {\n         return new beginUpdateBlob_argsTupleScheme();\n       }\n@@ -23016,6 +24090,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class beginUpdateBlob_result implements org.apache.storm.thrift.TBase<beginUpdateBlob_result, beginUpdateBlob_result._Fields>, java.io.Serializable, Cloneable, Comparable<beginUpdateBlob_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"beginUpdateBlob_result\");\n \n@@ -23087,10 +24162,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -23139,6 +24216,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public beginUpdateBlob_result deepCopy() {\n       return new beginUpdateBlob_result(this);\n     }\n@@ -23222,6 +24300,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case SUCCESS:\n@@ -23252,6 +24331,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case SUCCESS:\n@@ -23268,6 +24348,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -23286,8 +24367,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof beginUpdateBlob_result)\n         return this.equals((beginUpdateBlob_result)that);\n       return false;\n@@ -23356,7 +24435,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_success()).compareTo(other.is_set_success());\n+      lastComparison = java.lang.Boolean.compare(is_set_success(), other.is_set_success());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -23366,7 +24445,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -23376,7 +24455,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_knf()).compareTo(other.is_set_knf());\n+      lastComparison = java.lang.Boolean.compare(is_set_knf(), other.is_set_knf());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -23390,10 +24469,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -23456,6 +24537,7 @@ public class Nimbus {\n     }\n \n     private static class beginUpdateBlob_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public beginUpdateBlob_resultStandardScheme getScheme() {\n         return new beginUpdateBlob_resultStandardScheme();\n       }\n@@ -23463,6 +24545,7 @@ public class Nimbus {\n \n     private static class beginUpdateBlob_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<beginUpdateBlob_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, beginUpdateBlob_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -23508,6 +24591,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, beginUpdateBlob_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -23534,6 +24618,7 @@ public class Nimbus {\n     }\n \n     private static class beginUpdateBlob_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public beginUpdateBlob_resultTupleScheme getScheme() {\n         return new beginUpdateBlob_resultTupleScheme();\n       }\n@@ -23592,6 +24677,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class uploadBlobChunk_args implements org.apache.storm.thrift.TBase<uploadBlobChunk_args, uploadBlobChunk_args._Fields>, java.io.Serializable, Cloneable, Comparable<uploadBlobChunk_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"uploadBlobChunk_args\");\n \n@@ -23658,10 +24744,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -23703,6 +24791,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public uploadBlobChunk_args deepCopy() {\n       return new uploadBlobChunk_args(this);\n     }\n@@ -23769,6 +24858,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case SESSION:\n@@ -23795,6 +24885,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case SESSION:\n@@ -23808,6 +24899,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -23824,8 +24916,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof uploadBlobChunk_args)\n         return this.equals((uploadBlobChunk_args)that);\n       return false;\n@@ -23881,7 +24971,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_session()).compareTo(other.is_set_session());\n+      lastComparison = java.lang.Boolean.compare(is_set_session(), other.is_set_session());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -23891,7 +24981,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_chunk()).compareTo(other.is_set_chunk());\n+      lastComparison = java.lang.Boolean.compare(is_set_chunk(), other.is_set_chunk());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -23905,14 +24995,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -23963,6 +25056,7 @@ public class Nimbus {\n     }\n \n     private static class uploadBlobChunk_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public uploadBlobChunk_argsStandardScheme getScheme() {\n         return new uploadBlobChunk_argsStandardScheme();\n       }\n@@ -23970,6 +25064,7 @@ public class Nimbus {\n \n     private static class uploadBlobChunk_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<uploadBlobChunk_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, uploadBlobChunk_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -24005,6 +25100,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, uploadBlobChunk_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -24026,6 +25122,7 @@ public class Nimbus {\n     }\n \n     private static class uploadBlobChunk_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public uploadBlobChunk_argsTupleScheme getScheme() {\n         return new uploadBlobChunk_argsTupleScheme();\n       }\n@@ -24072,6 +25169,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class uploadBlobChunk_result implements org.apache.storm.thrift.TBase<uploadBlobChunk_result, uploadBlobChunk_result._Fields>, java.io.Serializable, Cloneable, Comparable<uploadBlobChunk_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"uploadBlobChunk_result\");\n \n@@ -24133,10 +25231,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -24171,6 +25271,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public uploadBlobChunk_result deepCopy() {\n       return new uploadBlobChunk_result(this);\n     }\n@@ -24204,6 +25305,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case AZE:\n@@ -24218,6 +25320,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case AZE:\n@@ -24228,6 +25331,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -24242,8 +25346,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof uploadBlobChunk_result)\n         return this.equals((uploadBlobChunk_result)that);\n       return false;\n@@ -24286,7 +25388,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -24300,10 +25402,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -24350,6 +25454,7 @@ public class Nimbus {\n     }\n \n     private static class uploadBlobChunk_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public uploadBlobChunk_resultStandardScheme getScheme() {\n         return new uploadBlobChunk_resultStandardScheme();\n       }\n@@ -24357,6 +25462,7 @@ public class Nimbus {\n \n     private static class uploadBlobChunk_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<uploadBlobChunk_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, uploadBlobChunk_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -24385,6 +25491,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, uploadBlobChunk_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -24401,6 +25508,7 @@ public class Nimbus {\n     }\n \n     private static class uploadBlobChunk_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public uploadBlobChunk_resultTupleScheme getScheme() {\n         return new uploadBlobChunk_resultTupleScheme();\n       }\n@@ -24438,6 +25546,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class finishBlobUpload_args implements org.apache.storm.thrift.TBase<finishBlobUpload_args, finishBlobUpload_args._Fields>, java.io.Serializable, Cloneable, Comparable<finishBlobUpload_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"finishBlobUpload_args\");\n \n@@ -24499,10 +25608,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -24537,6 +25648,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public finishBlobUpload_args deepCopy() {\n       return new finishBlobUpload_args(this);\n     }\n@@ -24570,6 +25682,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case SESSION:\n@@ -24584,6 +25697,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case SESSION:\n@@ -24594,6 +25708,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -24608,8 +25723,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof finishBlobUpload_args)\n         return this.equals((finishBlobUpload_args)that);\n       return false;\n@@ -24652,7 +25765,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_session()).compareTo(other.is_set_session());\n+      lastComparison = java.lang.Boolean.compare(is_set_session(), other.is_set_session());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -24666,14 +25779,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -24716,6 +25832,7 @@ public class Nimbus {\n     }\n \n     private static class finishBlobUpload_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public finishBlobUpload_argsStandardScheme getScheme() {\n         return new finishBlobUpload_argsStandardScheme();\n       }\n@@ -24723,6 +25840,7 @@ public class Nimbus {\n \n     private static class finishBlobUpload_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<finishBlobUpload_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, finishBlobUpload_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -24750,6 +25868,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, finishBlobUpload_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -24766,6 +25885,7 @@ public class Nimbus {\n     }\n \n     private static class finishBlobUpload_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public finishBlobUpload_argsTupleScheme getScheme() {\n         return new finishBlobUpload_argsTupleScheme();\n       }\n@@ -24802,6 +25922,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class finishBlobUpload_result implements org.apache.storm.thrift.TBase<finishBlobUpload_result, finishBlobUpload_result._Fields>, java.io.Serializable, Cloneable, Comparable<finishBlobUpload_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"finishBlobUpload_result\");\n \n@@ -24863,10 +25984,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -24901,6 +26024,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public finishBlobUpload_result deepCopy() {\n       return new finishBlobUpload_result(this);\n     }\n@@ -24934,6 +26058,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case AZE:\n@@ -24948,6 +26073,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case AZE:\n@@ -24958,6 +26084,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -24972,8 +26099,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof finishBlobUpload_result)\n         return this.equals((finishBlobUpload_result)that);\n       return false;\n@@ -25016,7 +26141,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -25030,10 +26155,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -25080,6 +26207,7 @@ public class Nimbus {\n     }\n \n     private static class finishBlobUpload_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public finishBlobUpload_resultStandardScheme getScheme() {\n         return new finishBlobUpload_resultStandardScheme();\n       }\n@@ -25087,6 +26215,7 @@ public class Nimbus {\n \n     private static class finishBlobUpload_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<finishBlobUpload_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, finishBlobUpload_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -25115,6 +26244,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, finishBlobUpload_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -25131,6 +26261,7 @@ public class Nimbus {\n     }\n \n     private static class finishBlobUpload_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public finishBlobUpload_resultTupleScheme getScheme() {\n         return new finishBlobUpload_resultTupleScheme();\n       }\n@@ -25168,6 +26299,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class cancelBlobUpload_args implements org.apache.storm.thrift.TBase<cancelBlobUpload_args, cancelBlobUpload_args._Fields>, java.io.Serializable, Cloneable, Comparable<cancelBlobUpload_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"cancelBlobUpload_args\");\n \n@@ -25229,10 +26361,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -25267,6 +26401,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public cancelBlobUpload_args deepCopy() {\n       return new cancelBlobUpload_args(this);\n     }\n@@ -25300,6 +26435,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case SESSION:\n@@ -25314,6 +26450,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case SESSION:\n@@ -25324,6 +26461,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -25338,8 +26476,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof cancelBlobUpload_args)\n         return this.equals((cancelBlobUpload_args)that);\n       return false;\n@@ -25382,7 +26518,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_session()).compareTo(other.is_set_session());\n+      lastComparison = java.lang.Boolean.compare(is_set_session(), other.is_set_session());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -25396,14 +26532,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -25446,6 +26585,7 @@ public class Nimbus {\n     }\n \n     private static class cancelBlobUpload_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public cancelBlobUpload_argsStandardScheme getScheme() {\n         return new cancelBlobUpload_argsStandardScheme();\n       }\n@@ -25453,6 +26593,7 @@ public class Nimbus {\n \n     private static class cancelBlobUpload_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<cancelBlobUpload_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, cancelBlobUpload_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -25480,6 +26621,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, cancelBlobUpload_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -25496,6 +26638,7 @@ public class Nimbus {\n     }\n \n     private static class cancelBlobUpload_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public cancelBlobUpload_argsTupleScheme getScheme() {\n         return new cancelBlobUpload_argsTupleScheme();\n       }\n@@ -25532,6 +26675,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class cancelBlobUpload_result implements org.apache.storm.thrift.TBase<cancelBlobUpload_result, cancelBlobUpload_result._Fields>, java.io.Serializable, Cloneable, Comparable<cancelBlobUpload_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"cancelBlobUpload_result\");\n \n@@ -25593,10 +26737,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -25631,6 +26777,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public cancelBlobUpload_result deepCopy() {\n       return new cancelBlobUpload_result(this);\n     }\n@@ -25664,6 +26811,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case AZE:\n@@ -25678,6 +26826,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case AZE:\n@@ -25688,6 +26837,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -25702,8 +26852,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof cancelBlobUpload_result)\n         return this.equals((cancelBlobUpload_result)that);\n       return false;\n@@ -25746,7 +26894,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -25760,10 +26908,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -25810,6 +26960,7 @@ public class Nimbus {\n     }\n \n     private static class cancelBlobUpload_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public cancelBlobUpload_resultStandardScheme getScheme() {\n         return new cancelBlobUpload_resultStandardScheme();\n       }\n@@ -25817,6 +26968,7 @@ public class Nimbus {\n \n     private static class cancelBlobUpload_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<cancelBlobUpload_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, cancelBlobUpload_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -25845,6 +26997,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, cancelBlobUpload_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -25861,6 +27014,7 @@ public class Nimbus {\n     }\n \n     private static class cancelBlobUpload_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public cancelBlobUpload_resultTupleScheme getScheme() {\n         return new cancelBlobUpload_resultTupleScheme();\n       }\n@@ -25898,6 +27052,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getBlobMeta_args implements org.apache.storm.thrift.TBase<getBlobMeta_args, getBlobMeta_args._Fields>, java.io.Serializable, Cloneable, Comparable<getBlobMeta_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getBlobMeta_args\");\n \n@@ -25959,10 +27114,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -25997,6 +27154,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public getBlobMeta_args deepCopy() {\n       return new getBlobMeta_args(this);\n     }\n@@ -26030,6 +27188,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case KEY:\n@@ -26044,6 +27203,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case KEY:\n@@ -26054,6 +27214,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -26068,8 +27229,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getBlobMeta_args)\n         return this.equals((getBlobMeta_args)that);\n       return false;\n@@ -26112,7 +27271,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_key()).compareTo(other.is_set_key());\n+      lastComparison = java.lang.Boolean.compare(is_set_key(), other.is_set_key());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -26126,14 +27285,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -26176,6 +27338,7 @@ public class Nimbus {\n     }\n \n     private static class getBlobMeta_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getBlobMeta_argsStandardScheme getScheme() {\n         return new getBlobMeta_argsStandardScheme();\n       }\n@@ -26183,6 +27346,7 @@ public class Nimbus {\n \n     private static class getBlobMeta_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getBlobMeta_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getBlobMeta_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -26210,6 +27374,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getBlobMeta_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -26226,6 +27391,7 @@ public class Nimbus {\n     }\n \n     private static class getBlobMeta_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getBlobMeta_argsTupleScheme getScheme() {\n         return new getBlobMeta_argsTupleScheme();\n       }\n@@ -26262,6 +27428,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getBlobMeta_result implements org.apache.storm.thrift.TBase<getBlobMeta_result, getBlobMeta_result._Fields>, java.io.Serializable, Cloneable, Comparable<getBlobMeta_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getBlobMeta_result\");\n \n@@ -26333,10 +27500,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -26385,6 +27554,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public getBlobMeta_result deepCopy() {\n       return new getBlobMeta_result(this);\n     }\n@@ -26468,6 +27638,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case SUCCESS:\n@@ -26498,6 +27669,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case SUCCESS:\n@@ -26514,6 +27686,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -26532,8 +27705,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getBlobMeta_result)\n         return this.equals((getBlobMeta_result)that);\n       return false;\n@@ -26602,7 +27773,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_success()).compareTo(other.is_set_success());\n+      lastComparison = java.lang.Boolean.compare(is_set_success(), other.is_set_success());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -26612,7 +27783,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -26622,7 +27793,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_knf()).compareTo(other.is_set_knf());\n+      lastComparison = java.lang.Boolean.compare(is_set_knf(), other.is_set_knf());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -26636,10 +27807,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -26705,6 +27878,7 @@ public class Nimbus {\n     }\n \n     private static class getBlobMeta_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getBlobMeta_resultStandardScheme getScheme() {\n         return new getBlobMeta_resultStandardScheme();\n       }\n@@ -26712,6 +27886,7 @@ public class Nimbus {\n \n     private static class getBlobMeta_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getBlobMeta_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getBlobMeta_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -26758,6 +27933,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getBlobMeta_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -26784,6 +27960,7 @@ public class Nimbus {\n     }\n \n     private static class getBlobMeta_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getBlobMeta_resultTupleScheme getScheme() {\n         return new getBlobMeta_resultTupleScheme();\n       }\n@@ -26843,6 +28020,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class setBlobMeta_args implements org.apache.storm.thrift.TBase<setBlobMeta_args, setBlobMeta_args._Fields>, java.io.Serializable, Cloneable, Comparable<setBlobMeta_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"setBlobMeta_args\");\n \n@@ -26909,10 +28087,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -26954,6 +28134,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public setBlobMeta_args deepCopy() {\n       return new setBlobMeta_args(this);\n     }\n@@ -27012,6 +28193,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case KEY:\n@@ -27034,6 +28216,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case KEY:\n@@ -27047,6 +28230,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -27063,8 +28247,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof setBlobMeta_args)\n         return this.equals((setBlobMeta_args)that);\n       return false;\n@@ -27120,7 +28302,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_key()).compareTo(other.is_set_key());\n+      lastComparison = java.lang.Boolean.compare(is_set_key(), other.is_set_key());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -27130,7 +28312,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_meta()).compareTo(other.is_set_meta());\n+      lastComparison = java.lang.Boolean.compare(is_set_meta(), other.is_set_meta());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -27144,14 +28326,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -27205,6 +28390,7 @@ public class Nimbus {\n     }\n \n     private static class setBlobMeta_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public setBlobMeta_argsStandardScheme getScheme() {\n         return new setBlobMeta_argsStandardScheme();\n       }\n@@ -27212,6 +28398,7 @@ public class Nimbus {\n \n     private static class setBlobMeta_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<setBlobMeta_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, setBlobMeta_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -27248,6 +28435,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, setBlobMeta_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -27269,6 +28457,7 @@ public class Nimbus {\n     }\n \n     private static class setBlobMeta_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public setBlobMeta_argsTupleScheme getScheme() {\n         return new setBlobMeta_argsTupleScheme();\n       }\n@@ -27316,6 +28505,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class setBlobMeta_result implements org.apache.storm.thrift.TBase<setBlobMeta_result, setBlobMeta_result._Fields>, java.io.Serializable, Cloneable, Comparable<setBlobMeta_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"setBlobMeta_result\");\n \n@@ -27382,10 +28572,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -27427,6 +28619,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public setBlobMeta_result deepCopy() {\n       return new setBlobMeta_result(this);\n     }\n@@ -27485,6 +28678,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case AZE:\n@@ -27507,6 +28701,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case AZE:\n@@ -27520,6 +28715,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -27536,8 +28732,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof setBlobMeta_result)\n         return this.equals((setBlobMeta_result)that);\n       return false;\n@@ -27593,7 +28787,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -27603,7 +28797,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_knf()).compareTo(other.is_set_knf());\n+      lastComparison = java.lang.Boolean.compare(is_set_knf(), other.is_set_knf());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -27617,10 +28811,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -27675,6 +28871,7 @@ public class Nimbus {\n     }\n \n     private static class setBlobMeta_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public setBlobMeta_resultStandardScheme getScheme() {\n         return new setBlobMeta_resultStandardScheme();\n       }\n@@ -27682,6 +28879,7 @@ public class Nimbus {\n \n     private static class setBlobMeta_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<setBlobMeta_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, setBlobMeta_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -27719,6 +28917,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, setBlobMeta_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -27740,6 +28939,7 @@ public class Nimbus {\n     }\n \n     private static class setBlobMeta_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public setBlobMeta_resultTupleScheme getScheme() {\n         return new setBlobMeta_resultTupleScheme();\n       }\n@@ -27788,6 +28988,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class beginBlobDownload_args implements org.apache.storm.thrift.TBase<beginBlobDownload_args, beginBlobDownload_args._Fields>, java.io.Serializable, Cloneable, Comparable<beginBlobDownload_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"beginBlobDownload_args\");\n \n@@ -27849,10 +29050,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -27887,6 +29090,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public beginBlobDownload_args deepCopy() {\n       return new beginBlobDownload_args(this);\n     }\n@@ -27920,6 +29124,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case KEY:\n@@ -27934,6 +29139,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case KEY:\n@@ -27944,6 +29150,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -27958,8 +29165,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof beginBlobDownload_args)\n         return this.equals((beginBlobDownload_args)that);\n       return false;\n@@ -28002,7 +29207,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_key()).compareTo(other.is_set_key());\n+      lastComparison = java.lang.Boolean.compare(is_set_key(), other.is_set_key());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -28016,14 +29221,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -28066,6 +29274,7 @@ public class Nimbus {\n     }\n \n     private static class beginBlobDownload_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public beginBlobDownload_argsStandardScheme getScheme() {\n         return new beginBlobDownload_argsStandardScheme();\n       }\n@@ -28073,6 +29282,7 @@ public class Nimbus {\n \n     private static class beginBlobDownload_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<beginBlobDownload_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, beginBlobDownload_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -28100,6 +29310,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, beginBlobDownload_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -28116,6 +29327,7 @@ public class Nimbus {\n     }\n \n     private static class beginBlobDownload_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public beginBlobDownload_argsTupleScheme getScheme() {\n         return new beginBlobDownload_argsTupleScheme();\n       }\n@@ -28152,6 +29364,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class beginBlobDownload_result implements org.apache.storm.thrift.TBase<beginBlobDownload_result, beginBlobDownload_result._Fields>, java.io.Serializable, Cloneable, Comparable<beginBlobDownload_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"beginBlobDownload_result\");\n \n@@ -28223,10 +29436,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -28275,6 +29490,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public beginBlobDownload_result deepCopy() {\n       return new beginBlobDownload_result(this);\n     }\n@@ -28358,6 +29574,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case SUCCESS:\n@@ -28388,6 +29605,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case SUCCESS:\n@@ -28404,6 +29622,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -28422,8 +29641,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof beginBlobDownload_result)\n         return this.equals((beginBlobDownload_result)that);\n       return false;\n@@ -28492,7 +29709,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_success()).compareTo(other.is_set_success());\n+      lastComparison = java.lang.Boolean.compare(is_set_success(), other.is_set_success());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -28502,7 +29719,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -28512,7 +29729,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_knf()).compareTo(other.is_set_knf());\n+      lastComparison = java.lang.Boolean.compare(is_set_knf(), other.is_set_knf());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -28526,10 +29743,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -28595,6 +29814,7 @@ public class Nimbus {\n     }\n \n     private static class beginBlobDownload_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public beginBlobDownload_resultStandardScheme getScheme() {\n         return new beginBlobDownload_resultStandardScheme();\n       }\n@@ -28602,6 +29822,7 @@ public class Nimbus {\n \n     private static class beginBlobDownload_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<beginBlobDownload_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, beginBlobDownload_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -28648,6 +29869,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, beginBlobDownload_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -28674,6 +29896,7 @@ public class Nimbus {\n     }\n \n     private static class beginBlobDownload_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public beginBlobDownload_resultTupleScheme getScheme() {\n         return new beginBlobDownload_resultTupleScheme();\n       }\n@@ -28733,6 +29956,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class downloadBlobChunk_args implements org.apache.storm.thrift.TBase<downloadBlobChunk_args, downloadBlobChunk_args._Fields>, java.io.Serializable, Cloneable, Comparable<downloadBlobChunk_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"downloadBlobChunk_args\");\n \n@@ -28794,10 +30018,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -28832,6 +30058,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public downloadBlobChunk_args deepCopy() {\n       return new downloadBlobChunk_args(this);\n     }\n@@ -28865,6 +30092,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case SESSION:\n@@ -28879,6 +30107,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case SESSION:\n@@ -28889,6 +30118,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -28903,8 +30133,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof downloadBlobChunk_args)\n         return this.equals((downloadBlobChunk_args)that);\n       return false;\n@@ -28947,7 +30175,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_session()).compareTo(other.is_set_session());\n+      lastComparison = java.lang.Boolean.compare(is_set_session(), other.is_set_session());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -28961,14 +30189,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -29011,6 +30242,7 @@ public class Nimbus {\n     }\n \n     private static class downloadBlobChunk_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public downloadBlobChunk_argsStandardScheme getScheme() {\n         return new downloadBlobChunk_argsStandardScheme();\n       }\n@@ -29018,6 +30250,7 @@ public class Nimbus {\n \n     private static class downloadBlobChunk_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<downloadBlobChunk_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, downloadBlobChunk_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -29045,6 +30278,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, downloadBlobChunk_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -29061,6 +30295,7 @@ public class Nimbus {\n     }\n \n     private static class downloadBlobChunk_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public downloadBlobChunk_argsTupleScheme getScheme() {\n         return new downloadBlobChunk_argsTupleScheme();\n       }\n@@ -29097,6 +30332,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class downloadBlobChunk_result implements org.apache.storm.thrift.TBase<downloadBlobChunk_result, downloadBlobChunk_result._Fields>, java.io.Serializable, Cloneable, Comparable<downloadBlobChunk_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"downloadBlobChunk_result\");\n \n@@ -29163,10 +30399,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -29208,6 +30446,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public downloadBlobChunk_result deepCopy() {\n       return new downloadBlobChunk_result(this);\n     }\n@@ -29274,6 +30513,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case SUCCESS:\n@@ -29300,6 +30540,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case SUCCESS:\n@@ -29313,6 +30554,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -29329,8 +30571,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof downloadBlobChunk_result)\n         return this.equals((downloadBlobChunk_result)that);\n       return false;\n@@ -29386,7 +30626,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_success()).compareTo(other.is_set_success());\n+      lastComparison = java.lang.Boolean.compare(is_set_success(), other.is_set_success());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -29396,7 +30636,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -29410,10 +30650,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -29468,6 +30710,7 @@ public class Nimbus {\n     }\n \n     private static class downloadBlobChunk_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public downloadBlobChunk_resultStandardScheme getScheme() {\n         return new downloadBlobChunk_resultStandardScheme();\n       }\n@@ -29475,6 +30718,7 @@ public class Nimbus {\n \n     private static class downloadBlobChunk_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<downloadBlobChunk_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, downloadBlobChunk_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -29511,6 +30755,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, downloadBlobChunk_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -29532,6 +30777,7 @@ public class Nimbus {\n     }\n \n     private static class downloadBlobChunk_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public downloadBlobChunk_resultTupleScheme getScheme() {\n         return new downloadBlobChunk_resultTupleScheme();\n       }\n@@ -29579,6 +30825,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class deleteBlob_args implements org.apache.storm.thrift.TBase<deleteBlob_args, deleteBlob_args._Fields>, java.io.Serializable, Cloneable, Comparable<deleteBlob_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"deleteBlob_args\");\n \n@@ -29640,10 +30887,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -29678,6 +30927,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public deleteBlob_args deepCopy() {\n       return new deleteBlob_args(this);\n     }\n@@ -29711,6 +30961,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case KEY:\n@@ -29725,6 +30976,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case KEY:\n@@ -29735,6 +30987,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -29749,8 +31002,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof deleteBlob_args)\n         return this.equals((deleteBlob_args)that);\n       return false;\n@@ -29793,7 +31044,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_key()).compareTo(other.is_set_key());\n+      lastComparison = java.lang.Boolean.compare(is_set_key(), other.is_set_key());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -29807,14 +31058,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -29857,6 +31111,7 @@ public class Nimbus {\n     }\n \n     private static class deleteBlob_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public deleteBlob_argsStandardScheme getScheme() {\n         return new deleteBlob_argsStandardScheme();\n       }\n@@ -29864,6 +31119,7 @@ public class Nimbus {\n \n     private static class deleteBlob_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<deleteBlob_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, deleteBlob_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -29891,6 +31147,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, deleteBlob_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -29907,6 +31164,7 @@ public class Nimbus {\n     }\n \n     private static class deleteBlob_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public deleteBlob_argsTupleScheme getScheme() {\n         return new deleteBlob_argsTupleScheme();\n       }\n@@ -29943,6 +31201,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class deleteBlob_result implements org.apache.storm.thrift.TBase<deleteBlob_result, deleteBlob_result._Fields>, java.io.Serializable, Cloneable, Comparable<deleteBlob_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"deleteBlob_result\");\n \n@@ -30014,10 +31273,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -30066,6 +31327,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public deleteBlob_result deepCopy() {\n       return new deleteBlob_result(this);\n     }\n@@ -30149,6 +31411,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case AZE:\n@@ -30179,6 +31442,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case AZE:\n@@ -30195,6 +31459,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -30213,8 +31478,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof deleteBlob_result)\n         return this.equals((deleteBlob_result)that);\n       return false;\n@@ -30283,7 +31546,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -30293,7 +31556,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_knf()).compareTo(other.is_set_knf());\n+      lastComparison = java.lang.Boolean.compare(is_set_knf(), other.is_set_knf());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -30303,7 +31566,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_ise()).compareTo(other.is_set_ise());\n+      lastComparison = java.lang.Boolean.compare(is_set_ise(), other.is_set_ise());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -30317,10 +31580,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -30383,6 +31648,7 @@ public class Nimbus {\n     }\n \n     private static class deleteBlob_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public deleteBlob_resultStandardScheme getScheme() {\n         return new deleteBlob_resultStandardScheme();\n       }\n@@ -30390,6 +31656,7 @@ public class Nimbus {\n \n     private static class deleteBlob_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<deleteBlob_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, deleteBlob_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -30436,6 +31703,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, deleteBlob_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -30462,6 +31730,7 @@ public class Nimbus {\n     }\n \n     private static class deleteBlob_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public deleteBlob_resultTupleScheme getScheme() {\n         return new deleteBlob_resultTupleScheme();\n       }\n@@ -30521,6 +31790,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class listBlobs_args implements org.apache.storm.thrift.TBase<listBlobs_args, listBlobs_args._Fields>, java.io.Serializable, Cloneable, Comparable<listBlobs_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"listBlobs_args\");\n \n@@ -30582,10 +31852,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -30620,6 +31892,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public listBlobs_args deepCopy() {\n       return new listBlobs_args(this);\n     }\n@@ -30653,6 +31926,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case SESSION:\n@@ -30667,6 +31941,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case SESSION:\n@@ -30677,6 +31952,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -30691,8 +31967,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof listBlobs_args)\n         return this.equals((listBlobs_args)that);\n       return false;\n@@ -30735,7 +32009,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_session()).compareTo(other.is_set_session());\n+      lastComparison = java.lang.Boolean.compare(is_set_session(), other.is_set_session());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -30749,14 +32023,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -30799,6 +32076,7 @@ public class Nimbus {\n     }\n \n     private static class listBlobs_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public listBlobs_argsStandardScheme getScheme() {\n         return new listBlobs_argsStandardScheme();\n       }\n@@ -30806,6 +32084,7 @@ public class Nimbus {\n \n     private static class listBlobs_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<listBlobs_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, listBlobs_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -30833,6 +32112,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, listBlobs_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -30849,6 +32129,7 @@ public class Nimbus {\n     }\n \n     private static class listBlobs_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public listBlobs_argsTupleScheme getScheme() {\n         return new listBlobs_argsTupleScheme();\n       }\n@@ -30885,6 +32166,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class listBlobs_result implements org.apache.storm.thrift.TBase<listBlobs_result, listBlobs_result._Fields>, java.io.Serializable, Cloneable, Comparable<listBlobs_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"listBlobs_result\");\n \n@@ -30946,10 +32228,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -30984,6 +32268,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public listBlobs_result deepCopy() {\n       return new listBlobs_result(this);\n     }\n@@ -31017,6 +32302,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case SUCCESS:\n@@ -31031,6 +32317,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case SUCCESS:\n@@ -31041,6 +32328,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -31055,8 +32343,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof listBlobs_result)\n         return this.equals((listBlobs_result)that);\n       return false;\n@@ -31099,7 +32385,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_success()).compareTo(other.is_set_success());\n+      lastComparison = java.lang.Boolean.compare(is_set_success(), other.is_set_success());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -31113,10 +32399,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -31166,6 +32454,7 @@ public class Nimbus {\n     }\n \n     private static class listBlobs_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public listBlobs_resultStandardScheme getScheme() {\n         return new listBlobs_resultStandardScheme();\n       }\n@@ -31173,6 +32462,7 @@ public class Nimbus {\n \n     private static class listBlobs_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<listBlobs_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, listBlobs_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -31201,6 +32491,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, listBlobs_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -31217,6 +32508,7 @@ public class Nimbus {\n     }\n \n     private static class listBlobs_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public listBlobs_resultTupleScheme getScheme() {\n         return new listBlobs_resultTupleScheme();\n       }\n@@ -31254,6 +32546,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getBlobReplication_args implements org.apache.storm.thrift.TBase<getBlobReplication_args, getBlobReplication_args._Fields>, java.io.Serializable, Cloneable, Comparable<getBlobReplication_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getBlobReplication_args\");\n \n@@ -31315,10 +32608,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -31353,6 +32648,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public getBlobReplication_args deepCopy() {\n       return new getBlobReplication_args(this);\n     }\n@@ -31386,6 +32682,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case KEY:\n@@ -31400,6 +32697,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case KEY:\n@@ -31410,6 +32708,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -31424,8 +32723,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getBlobReplication_args)\n         return this.equals((getBlobReplication_args)that);\n       return false;\n@@ -31468,7 +32765,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_key()).compareTo(other.is_set_key());\n+      lastComparison = java.lang.Boolean.compare(is_set_key(), other.is_set_key());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -31482,14 +32779,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -31532,6 +32832,7 @@ public class Nimbus {\n     }\n \n     private static class getBlobReplication_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getBlobReplication_argsStandardScheme getScheme() {\n         return new getBlobReplication_argsStandardScheme();\n       }\n@@ -31539,6 +32840,7 @@ public class Nimbus {\n \n     private static class getBlobReplication_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getBlobReplication_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getBlobReplication_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -31566,6 +32868,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getBlobReplication_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -31582,6 +32885,7 @@ public class Nimbus {\n     }\n \n     private static class getBlobReplication_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getBlobReplication_argsTupleScheme getScheme() {\n         return new getBlobReplication_argsTupleScheme();\n       }\n@@ -31618,6 +32922,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getBlobReplication_result implements org.apache.storm.thrift.TBase<getBlobReplication_result, getBlobReplication_result._Fields>, java.io.Serializable, Cloneable, Comparable<getBlobReplication_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getBlobReplication_result\");\n \n@@ -31689,10 +32994,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -31743,6 +33050,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public getBlobReplication_result deepCopy() {\n       return new getBlobReplication_result(this);\n     }\n@@ -31825,6 +33133,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case SUCCESS:\n@@ -31855,6 +33164,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case SUCCESS:\n@@ -31871,6 +33181,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -31889,8 +33200,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getBlobReplication_result)\n         return this.equals((getBlobReplication_result)that);\n       return false;\n@@ -31957,7 +33266,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_success()).compareTo(other.is_set_success());\n+      lastComparison = java.lang.Boolean.compare(is_set_success(), other.is_set_success());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -31967,7 +33276,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -31977,7 +33286,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_knf()).compareTo(other.is_set_knf());\n+      lastComparison = java.lang.Boolean.compare(is_set_knf(), other.is_set_knf());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -31991,10 +33300,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -32055,6 +33366,7 @@ public class Nimbus {\n     }\n \n     private static class getBlobReplication_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getBlobReplication_resultStandardScheme getScheme() {\n         return new getBlobReplication_resultStandardScheme();\n       }\n@@ -32062,6 +33374,7 @@ public class Nimbus {\n \n     private static class getBlobReplication_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getBlobReplication_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getBlobReplication_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -32107,6 +33420,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getBlobReplication_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -32133,6 +33447,7 @@ public class Nimbus {\n     }\n \n     private static class getBlobReplication_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getBlobReplication_resultTupleScheme getScheme() {\n         return new getBlobReplication_resultTupleScheme();\n       }\n@@ -32191,6 +33506,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class updateBlobReplication_args implements org.apache.storm.thrift.TBase<updateBlobReplication_args, updateBlobReplication_args._Fields>, java.io.Serializable, Cloneable, Comparable<updateBlobReplication_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"updateBlobReplication_args\");\n \n@@ -32257,10 +33573,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -32304,6 +33622,7 @@ public class Nimbus {\n       this.replication = other.replication;\n     }\n \n+    @Override\n     public updateBlobReplication_args deepCopy() {\n       return new updateBlobReplication_args(this);\n     }\n@@ -32361,6 +33680,7 @@ public class Nimbus {\n       __isset_bitfield = org.apache.storm.thrift.EncodingUtils.setBit(__isset_bitfield, __REPLICATION_ISSET_ID, value);\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case KEY:\n@@ -32383,6 +33703,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case KEY:\n@@ -32396,6 +33717,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -32412,8 +33734,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof updateBlobReplication_args)\n         return this.equals((updateBlobReplication_args)that);\n       return false;\n@@ -32467,7 +33787,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_key()).compareTo(other.is_set_key());\n+      lastComparison = java.lang.Boolean.compare(is_set_key(), other.is_set_key());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -32477,7 +33797,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_replication()).compareTo(other.is_set_replication());\n+      lastComparison = java.lang.Boolean.compare(is_set_replication(), other.is_set_replication());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -32491,14 +33811,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -32547,6 +33870,7 @@ public class Nimbus {\n     }\n \n     private static class updateBlobReplication_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public updateBlobReplication_argsStandardScheme getScheme() {\n         return new updateBlobReplication_argsStandardScheme();\n       }\n@@ -32554,6 +33878,7 @@ public class Nimbus {\n \n     private static class updateBlobReplication_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<updateBlobReplication_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, updateBlobReplication_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -32589,6 +33914,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, updateBlobReplication_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -32608,6 +33934,7 @@ public class Nimbus {\n     }\n \n     private static class updateBlobReplication_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public updateBlobReplication_argsTupleScheme getScheme() {\n         return new updateBlobReplication_argsTupleScheme();\n       }\n@@ -32654,6 +33981,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class updateBlobReplication_result implements org.apache.storm.thrift.TBase<updateBlobReplication_result, updateBlobReplication_result._Fields>, java.io.Serializable, Cloneable, Comparable<updateBlobReplication_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"updateBlobReplication_result\");\n \n@@ -32725,10 +34053,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -32779,6 +34109,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public updateBlobReplication_result deepCopy() {\n       return new updateBlobReplication_result(this);\n     }\n@@ -32861,6 +34192,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case SUCCESS:\n@@ -32891,6 +34223,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case SUCCESS:\n@@ -32907,6 +34240,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -32925,8 +34259,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof updateBlobReplication_result)\n         return this.equals((updateBlobReplication_result)that);\n       return false;\n@@ -32993,7 +34325,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_success()).compareTo(other.is_set_success());\n+      lastComparison = java.lang.Boolean.compare(is_set_success(), other.is_set_success());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -33003,7 +34335,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -33013,7 +34345,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_knf()).compareTo(other.is_set_knf());\n+      lastComparison = java.lang.Boolean.compare(is_set_knf(), other.is_set_knf());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -33027,10 +34359,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -33091,6 +34425,7 @@ public class Nimbus {\n     }\n \n     private static class updateBlobReplication_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public updateBlobReplication_resultStandardScheme getScheme() {\n         return new updateBlobReplication_resultStandardScheme();\n       }\n@@ -33098,6 +34433,7 @@ public class Nimbus {\n \n     private static class updateBlobReplication_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<updateBlobReplication_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, updateBlobReplication_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -33143,6 +34479,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, updateBlobReplication_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -33169,6 +34506,7 @@ public class Nimbus {\n     }\n \n     private static class updateBlobReplication_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public updateBlobReplication_resultTupleScheme getScheme() {\n         return new updateBlobReplication_resultTupleScheme();\n       }\n@@ -33227,6 +34565,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class createStateInZookeeper_args implements org.apache.storm.thrift.TBase<createStateInZookeeper_args, createStateInZookeeper_args._Fields>, java.io.Serializable, Cloneable, Comparable<createStateInZookeeper_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"createStateInZookeeper_args\");\n \n@@ -33288,10 +34627,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -33326,6 +34667,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public createStateInZookeeper_args deepCopy() {\n       return new createStateInZookeeper_args(this);\n     }\n@@ -33359,6 +34701,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case KEY:\n@@ -33373,6 +34716,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case KEY:\n@@ -33383,6 +34727,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -33397,8 +34742,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof createStateInZookeeper_args)\n         return this.equals((createStateInZookeeper_args)that);\n       return false;\n@@ -33441,7 +34784,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_key()).compareTo(other.is_set_key());\n+      lastComparison = java.lang.Boolean.compare(is_set_key(), other.is_set_key());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -33455,14 +34798,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -33505,6 +34851,7 @@ public class Nimbus {\n     }\n \n     private static class createStateInZookeeper_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public createStateInZookeeper_argsStandardScheme getScheme() {\n         return new createStateInZookeeper_argsStandardScheme();\n       }\n@@ -33512,6 +34859,7 @@ public class Nimbus {\n \n     private static class createStateInZookeeper_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<createStateInZookeeper_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, createStateInZookeeper_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -33539,6 +34887,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, createStateInZookeeper_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -33555,6 +34904,7 @@ public class Nimbus {\n     }\n \n     private static class createStateInZookeeper_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public createStateInZookeeper_argsTupleScheme getScheme() {\n         return new createStateInZookeeper_argsTupleScheme();\n       }\n@@ -33591,6 +34941,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class createStateInZookeeper_result implements org.apache.storm.thrift.TBase<createStateInZookeeper_result, createStateInZookeeper_result._Fields>, java.io.Serializable, Cloneable, Comparable<createStateInZookeeper_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"createStateInZookeeper_result\");\n \n@@ -33648,10 +34999,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -33672,6 +35025,7 @@ public class Nimbus {\n     public createStateInZookeeper_result(createStateInZookeeper_result other) {\n     }\n \n+    @Override\n     public createStateInZookeeper_result deepCopy() {\n       return new createStateInZookeeper_result(this);\n     }\n@@ -33680,12 +35034,14 @@ public class Nimbus {\n     public void clear() {\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       }\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       }\n@@ -33693,6 +35049,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -33705,8 +35062,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof createStateInZookeeper_result)\n         return this.equals((createStateInZookeeper_result)that);\n       return false;\n@@ -33740,10 +35095,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -33783,6 +35140,7 @@ public class Nimbus {\n     }\n \n     private static class createStateInZookeeper_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public createStateInZookeeper_resultStandardScheme getScheme() {\n         return new createStateInZookeeper_resultStandardScheme();\n       }\n@@ -33790,6 +35148,7 @@ public class Nimbus {\n \n     private static class createStateInZookeeper_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<createStateInZookeeper_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, createStateInZookeeper_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -33809,6 +35168,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, createStateInZookeeper_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -33820,6 +35180,7 @@ public class Nimbus {\n     }\n \n     private static class createStateInZookeeper_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public createStateInZookeeper_resultTupleScheme getScheme() {\n         return new createStateInZookeeper_resultTupleScheme();\n       }\n@@ -33843,6 +35204,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class beginFileUpload_args implements org.apache.storm.thrift.TBase<beginFileUpload_args, beginFileUpload_args._Fields>, java.io.Serializable, Cloneable, Comparable<beginFileUpload_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"beginFileUpload_args\");\n \n@@ -33900,10 +35262,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -33924,6 +35288,7 @@ public class Nimbus {\n     public beginFileUpload_args(beginFileUpload_args other) {\n     }\n \n+    @Override\n     public beginFileUpload_args deepCopy() {\n       return new beginFileUpload_args(this);\n     }\n@@ -33932,12 +35297,14 @@ public class Nimbus {\n     public void clear() {\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       }\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       }\n@@ -33945,6 +35312,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -33957,8 +35325,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof beginFileUpload_args)\n         return this.equals((beginFileUpload_args)that);\n       return false;\n@@ -33992,14 +35358,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -34035,6 +35404,7 @@ public class Nimbus {\n     }\n \n     private static class beginFileUpload_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public beginFileUpload_argsStandardScheme getScheme() {\n         return new beginFileUpload_argsStandardScheme();\n       }\n@@ -34042,6 +35412,7 @@ public class Nimbus {\n \n     private static class beginFileUpload_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<beginFileUpload_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, beginFileUpload_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -34061,6 +35432,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, beginFileUpload_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -34072,6 +35444,7 @@ public class Nimbus {\n     }\n \n     private static class beginFileUpload_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public beginFileUpload_argsTupleScheme getScheme() {\n         return new beginFileUpload_argsTupleScheme();\n       }\n@@ -34095,6 +35468,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class beginFileUpload_result implements org.apache.storm.thrift.TBase<beginFileUpload_result, beginFileUpload_result._Fields>, java.io.Serializable, Cloneable, Comparable<beginFileUpload_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"beginFileUpload_result\");\n \n@@ -34161,10 +35535,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -34206,6 +35582,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public beginFileUpload_result deepCopy() {\n       return new beginFileUpload_result(this);\n     }\n@@ -34264,6 +35641,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case SUCCESS:\n@@ -34286,6 +35664,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case SUCCESS:\n@@ -34299,6 +35678,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -34315,8 +35695,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof beginFileUpload_result)\n         return this.equals((beginFileUpload_result)that);\n       return false;\n@@ -34372,7 +35750,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_success()).compareTo(other.is_set_success());\n+      lastComparison = java.lang.Boolean.compare(is_set_success(), other.is_set_success());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -34382,7 +35760,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -34396,10 +35774,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -34454,6 +35834,7 @@ public class Nimbus {\n     }\n \n     private static class beginFileUpload_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public beginFileUpload_resultStandardScheme getScheme() {\n         return new beginFileUpload_resultStandardScheme();\n       }\n@@ -34461,6 +35842,7 @@ public class Nimbus {\n \n     private static class beginFileUpload_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<beginFileUpload_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, beginFileUpload_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -34497,6 +35879,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, beginFileUpload_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -34518,6 +35901,7 @@ public class Nimbus {\n     }\n \n     private static class beginFileUpload_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public beginFileUpload_resultTupleScheme getScheme() {\n         return new beginFileUpload_resultTupleScheme();\n       }\n@@ -34565,6 +35949,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class uploadChunk_args implements org.apache.storm.thrift.TBase<uploadChunk_args, uploadChunk_args._Fields>, java.io.Serializable, Cloneable, Comparable<uploadChunk_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"uploadChunk_args\");\n \n@@ -34631,10 +36016,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -34676,6 +36063,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public uploadChunk_args deepCopy() {\n       return new uploadChunk_args(this);\n     }\n@@ -34742,6 +36130,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case LOCATION:\n@@ -34768,6 +36157,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case LOCATION:\n@@ -34781,6 +36171,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -34797,8 +36188,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof uploadChunk_args)\n         return this.equals((uploadChunk_args)that);\n       return false;\n@@ -34854,7 +36243,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_location()).compareTo(other.is_set_location());\n+      lastComparison = java.lang.Boolean.compare(is_set_location(), other.is_set_location());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -34864,7 +36253,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_chunk()).compareTo(other.is_set_chunk());\n+      lastComparison = java.lang.Boolean.compare(is_set_chunk(), other.is_set_chunk());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -34878,14 +36267,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -34936,6 +36328,7 @@ public class Nimbus {\n     }\n \n     private static class uploadChunk_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public uploadChunk_argsStandardScheme getScheme() {\n         return new uploadChunk_argsStandardScheme();\n       }\n@@ -34943,6 +36336,7 @@ public class Nimbus {\n \n     private static class uploadChunk_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<uploadChunk_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, uploadChunk_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -34978,6 +36372,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, uploadChunk_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -34999,6 +36394,7 @@ public class Nimbus {\n     }\n \n     private static class uploadChunk_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public uploadChunk_argsTupleScheme getScheme() {\n         return new uploadChunk_argsTupleScheme();\n       }\n@@ -35045,6 +36441,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class uploadChunk_result implements org.apache.storm.thrift.TBase<uploadChunk_result, uploadChunk_result._Fields>, java.io.Serializable, Cloneable, Comparable<uploadChunk_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"uploadChunk_result\");\n \n@@ -35106,10 +36503,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -35144,6 +36543,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public uploadChunk_result deepCopy() {\n       return new uploadChunk_result(this);\n     }\n@@ -35177,6 +36577,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case AZE:\n@@ -35191,6 +36592,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case AZE:\n@@ -35201,6 +36603,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -35215,8 +36618,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof uploadChunk_result)\n         return this.equals((uploadChunk_result)that);\n       return false;\n@@ -35259,7 +36660,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -35273,10 +36674,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -35323,6 +36726,7 @@ public class Nimbus {\n     }\n \n     private static class uploadChunk_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public uploadChunk_resultStandardScheme getScheme() {\n         return new uploadChunk_resultStandardScheme();\n       }\n@@ -35330,6 +36734,7 @@ public class Nimbus {\n \n     private static class uploadChunk_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<uploadChunk_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, uploadChunk_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -35358,6 +36763,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, uploadChunk_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -35374,6 +36780,7 @@ public class Nimbus {\n     }\n \n     private static class uploadChunk_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public uploadChunk_resultTupleScheme getScheme() {\n         return new uploadChunk_resultTupleScheme();\n       }\n@@ -35411,6 +36818,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class finishFileUpload_args implements org.apache.storm.thrift.TBase<finishFileUpload_args, finishFileUpload_args._Fields>, java.io.Serializable, Cloneable, Comparable<finishFileUpload_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"finishFileUpload_args\");\n \n@@ -35472,10 +36880,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -35510,6 +36920,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public finishFileUpload_args deepCopy() {\n       return new finishFileUpload_args(this);\n     }\n@@ -35543,6 +36954,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case LOCATION:\n@@ -35557,6 +36969,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case LOCATION:\n@@ -35567,6 +36980,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -35581,8 +36995,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof finishFileUpload_args)\n         return this.equals((finishFileUpload_args)that);\n       return false;\n@@ -35625,7 +37037,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_location()).compareTo(other.is_set_location());\n+      lastComparison = java.lang.Boolean.compare(is_set_location(), other.is_set_location());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -35639,14 +37051,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -35689,6 +37104,7 @@ public class Nimbus {\n     }\n \n     private static class finishFileUpload_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public finishFileUpload_argsStandardScheme getScheme() {\n         return new finishFileUpload_argsStandardScheme();\n       }\n@@ -35696,6 +37112,7 @@ public class Nimbus {\n \n     private static class finishFileUpload_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<finishFileUpload_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, finishFileUpload_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -35723,6 +37140,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, finishFileUpload_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -35739,6 +37157,7 @@ public class Nimbus {\n     }\n \n     private static class finishFileUpload_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public finishFileUpload_argsTupleScheme getScheme() {\n         return new finishFileUpload_argsTupleScheme();\n       }\n@@ -35775,6 +37194,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class finishFileUpload_result implements org.apache.storm.thrift.TBase<finishFileUpload_result, finishFileUpload_result._Fields>, java.io.Serializable, Cloneable, Comparable<finishFileUpload_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"finishFileUpload_result\");\n \n@@ -35836,10 +37256,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -35874,6 +37296,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public finishFileUpload_result deepCopy() {\n       return new finishFileUpload_result(this);\n     }\n@@ -35907,6 +37330,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case AZE:\n@@ -35921,6 +37345,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case AZE:\n@@ -35931,6 +37356,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -35945,8 +37371,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof finishFileUpload_result)\n         return this.equals((finishFileUpload_result)that);\n       return false;\n@@ -35989,7 +37413,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -36003,10 +37427,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -36053,6 +37479,7 @@ public class Nimbus {\n     }\n \n     private static class finishFileUpload_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public finishFileUpload_resultStandardScheme getScheme() {\n         return new finishFileUpload_resultStandardScheme();\n       }\n@@ -36060,6 +37487,7 @@ public class Nimbus {\n \n     private static class finishFileUpload_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<finishFileUpload_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, finishFileUpload_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -36088,6 +37516,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, finishFileUpload_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -36104,6 +37533,7 @@ public class Nimbus {\n     }\n \n     private static class finishFileUpload_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public finishFileUpload_resultTupleScheme getScheme() {\n         return new finishFileUpload_resultTupleScheme();\n       }\n@@ -36141,6 +37571,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class downloadChunk_args implements org.apache.storm.thrift.TBase<downloadChunk_args, downloadChunk_args._Fields>, java.io.Serializable, Cloneable, Comparable<downloadChunk_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"downloadChunk_args\");\n \n@@ -36202,10 +37633,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -36240,6 +37673,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public downloadChunk_args deepCopy() {\n       return new downloadChunk_args(this);\n     }\n@@ -36273,6 +37707,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case ID:\n@@ -36287,6 +37722,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case ID:\n@@ -36297,6 +37733,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -36311,8 +37748,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof downloadChunk_args)\n         return this.equals((downloadChunk_args)that);\n       return false;\n@@ -36355,7 +37790,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_id()).compareTo(other.is_set_id());\n+      lastComparison = java.lang.Boolean.compare(is_set_id(), other.is_set_id());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -36369,14 +37804,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -36419,6 +37857,7 @@ public class Nimbus {\n     }\n \n     private static class downloadChunk_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public downloadChunk_argsStandardScheme getScheme() {\n         return new downloadChunk_argsStandardScheme();\n       }\n@@ -36426,6 +37865,7 @@ public class Nimbus {\n \n     private static class downloadChunk_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<downloadChunk_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, downloadChunk_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -36453,6 +37893,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, downloadChunk_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -36469,6 +37910,7 @@ public class Nimbus {\n     }\n \n     private static class downloadChunk_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public downloadChunk_argsTupleScheme getScheme() {\n         return new downloadChunk_argsTupleScheme();\n       }\n@@ -36505,6 +37947,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class downloadChunk_result implements org.apache.storm.thrift.TBase<downloadChunk_result, downloadChunk_result._Fields>, java.io.Serializable, Cloneable, Comparable<downloadChunk_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"downloadChunk_result\");\n \n@@ -36571,10 +38014,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -36616,6 +38061,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public downloadChunk_result deepCopy() {\n       return new downloadChunk_result(this);\n     }\n@@ -36682,6 +38128,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case SUCCESS:\n@@ -36708,6 +38155,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case SUCCESS:\n@@ -36721,6 +38169,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -36737,8 +38186,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof downloadChunk_result)\n         return this.equals((downloadChunk_result)that);\n       return false;\n@@ -36794,7 +38241,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_success()).compareTo(other.is_set_success());\n+      lastComparison = java.lang.Boolean.compare(is_set_success(), other.is_set_success());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -36804,7 +38251,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -36818,10 +38265,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -36876,6 +38325,7 @@ public class Nimbus {\n     }\n \n     private static class downloadChunk_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public downloadChunk_resultStandardScheme getScheme() {\n         return new downloadChunk_resultStandardScheme();\n       }\n@@ -36883,6 +38333,7 @@ public class Nimbus {\n \n     private static class downloadChunk_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<downloadChunk_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, downloadChunk_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -36919,6 +38370,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, downloadChunk_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -36940,6 +38392,7 @@ public class Nimbus {\n     }\n \n     private static class downloadChunk_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public downloadChunk_resultTupleScheme getScheme() {\n         return new downloadChunk_resultTupleScheme();\n       }\n@@ -36987,6 +38440,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getNimbusConf_args implements org.apache.storm.thrift.TBase<getNimbusConf_args, getNimbusConf_args._Fields>, java.io.Serializable, Cloneable, Comparable<getNimbusConf_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getNimbusConf_args\");\n \n@@ -37044,10 +38498,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -37068,6 +38524,7 @@ public class Nimbus {\n     public getNimbusConf_args(getNimbusConf_args other) {\n     }\n \n+    @Override\n     public getNimbusConf_args deepCopy() {\n       return new getNimbusConf_args(this);\n     }\n@@ -37076,12 +38533,14 @@ public class Nimbus {\n     public void clear() {\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       }\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       }\n@@ -37089,6 +38548,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -37101,8 +38561,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getNimbusConf_args)\n         return this.equals((getNimbusConf_args)that);\n       return false;\n@@ -37136,14 +38594,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -37179,6 +38640,7 @@ public class Nimbus {\n     }\n \n     private static class getNimbusConf_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getNimbusConf_argsStandardScheme getScheme() {\n         return new getNimbusConf_argsStandardScheme();\n       }\n@@ -37186,6 +38648,7 @@ public class Nimbus {\n \n     private static class getNimbusConf_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getNimbusConf_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getNimbusConf_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -37205,6 +38668,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getNimbusConf_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -37216,6 +38680,7 @@ public class Nimbus {\n     }\n \n     private static class getNimbusConf_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getNimbusConf_argsTupleScheme getScheme() {\n         return new getNimbusConf_argsTupleScheme();\n       }\n@@ -37239,6 +38704,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getNimbusConf_result implements org.apache.storm.thrift.TBase<getNimbusConf_result, getNimbusConf_result._Fields>, java.io.Serializable, Cloneable, Comparable<getNimbusConf_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getNimbusConf_result\");\n \n@@ -37305,10 +38771,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -37350,6 +38818,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public getNimbusConf_result deepCopy() {\n       return new getNimbusConf_result(this);\n     }\n@@ -37408,6 +38877,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case SUCCESS:\n@@ -37430,6 +38900,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case SUCCESS:\n@@ -37443,6 +38914,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -37459,8 +38931,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getNimbusConf_result)\n         return this.equals((getNimbusConf_result)that);\n       return false;\n@@ -37516,7 +38986,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_success()).compareTo(other.is_set_success());\n+      lastComparison = java.lang.Boolean.compare(is_set_success(), other.is_set_success());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -37526,7 +38996,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -37540,10 +39010,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -37598,6 +39070,7 @@ public class Nimbus {\n     }\n \n     private static class getNimbusConf_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getNimbusConf_resultStandardScheme getScheme() {\n         return new getNimbusConf_resultStandardScheme();\n       }\n@@ -37605,6 +39078,7 @@ public class Nimbus {\n \n     private static class getNimbusConf_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getNimbusConf_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getNimbusConf_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -37641,6 +39115,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getNimbusConf_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -37662,6 +39137,7 @@ public class Nimbus {\n     }\n \n     private static class getNimbusConf_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getNimbusConf_resultTupleScheme getScheme() {\n         return new getNimbusConf_resultTupleScheme();\n       }\n@@ -37709,6 +39185,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getClusterInfo_args implements org.apache.storm.thrift.TBase<getClusterInfo_args, getClusterInfo_args._Fields>, java.io.Serializable, Cloneable, Comparable<getClusterInfo_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getClusterInfo_args\");\n \n@@ -37766,10 +39243,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -37790,6 +39269,7 @@ public class Nimbus {\n     public getClusterInfo_args(getClusterInfo_args other) {\n     }\n \n+    @Override\n     public getClusterInfo_args deepCopy() {\n       return new getClusterInfo_args(this);\n     }\n@@ -37798,12 +39278,14 @@ public class Nimbus {\n     public void clear() {\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       }\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       }\n@@ -37811,6 +39293,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -37823,8 +39306,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getClusterInfo_args)\n         return this.equals((getClusterInfo_args)that);\n       return false;\n@@ -37858,14 +39339,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -37901,6 +39385,7 @@ public class Nimbus {\n     }\n \n     private static class getClusterInfo_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getClusterInfo_argsStandardScheme getScheme() {\n         return new getClusterInfo_argsStandardScheme();\n       }\n@@ -37908,6 +39393,7 @@ public class Nimbus {\n \n     private static class getClusterInfo_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getClusterInfo_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getClusterInfo_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -37927,6 +39413,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getClusterInfo_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -37938,6 +39425,7 @@ public class Nimbus {\n     }\n \n     private static class getClusterInfo_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getClusterInfo_argsTupleScheme getScheme() {\n         return new getClusterInfo_argsTupleScheme();\n       }\n@@ -37961,6 +39449,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getClusterInfo_result implements org.apache.storm.thrift.TBase<getClusterInfo_result, getClusterInfo_result._Fields>, java.io.Serializable, Cloneable, Comparable<getClusterInfo_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getClusterInfo_result\");\n \n@@ -38027,10 +39516,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -38072,6 +39563,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public getClusterInfo_result deepCopy() {\n       return new getClusterInfo_result(this);\n     }\n@@ -38130,6 +39622,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case SUCCESS:\n@@ -38152,6 +39645,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case SUCCESS:\n@@ -38165,6 +39659,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -38181,8 +39676,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getClusterInfo_result)\n         return this.equals((getClusterInfo_result)that);\n       return false;\n@@ -38238,7 +39731,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_success()).compareTo(other.is_set_success());\n+      lastComparison = java.lang.Boolean.compare(is_set_success(), other.is_set_success());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -38248,7 +39741,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -38262,10 +39755,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -38323,6 +39818,7 @@ public class Nimbus {\n     }\n \n     private static class getClusterInfo_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getClusterInfo_resultStandardScheme getScheme() {\n         return new getClusterInfo_resultStandardScheme();\n       }\n@@ -38330,6 +39826,7 @@ public class Nimbus {\n \n     private static class getClusterInfo_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getClusterInfo_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getClusterInfo_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -38367,6 +39864,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getClusterInfo_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -38388,6 +39886,7 @@ public class Nimbus {\n     }\n \n     private static class getClusterInfo_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getClusterInfo_resultTupleScheme getScheme() {\n         return new getClusterInfo_resultTupleScheme();\n       }\n@@ -38436,6 +39935,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getTopologySummaries_args implements org.apache.storm.thrift.TBase<getTopologySummaries_args, getTopologySummaries_args._Fields>, java.io.Serializable, Cloneable, Comparable<getTopologySummaries_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getTopologySummaries_args\");\n \n@@ -38493,10 +39993,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -38517,6 +40019,7 @@ public class Nimbus {\n     public getTopologySummaries_args(getTopologySummaries_args other) {\n     }\n \n+    @Override\n     public getTopologySummaries_args deepCopy() {\n       return new getTopologySummaries_args(this);\n     }\n@@ -38525,12 +40028,14 @@ public class Nimbus {\n     public void clear() {\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       }\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       }\n@@ -38538,6 +40043,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -38550,8 +40056,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getTopologySummaries_args)\n         return this.equals((getTopologySummaries_args)that);\n       return false;\n@@ -38585,14 +40089,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -38628,6 +40135,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologySummaries_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologySummaries_argsStandardScheme getScheme() {\n         return new getTopologySummaries_argsStandardScheme();\n       }\n@@ -38635,6 +40143,7 @@ public class Nimbus {\n \n     private static class getTopologySummaries_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getTopologySummaries_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getTopologySummaries_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -38654,6 +40163,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getTopologySummaries_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -38665,6 +40175,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologySummaries_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologySummaries_argsTupleScheme getScheme() {\n         return new getTopologySummaries_argsTupleScheme();\n       }\n@@ -38688,6 +40199,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getTopologySummaries_result implements org.apache.storm.thrift.TBase<getTopologySummaries_result, getTopologySummaries_result._Fields>, java.io.Serializable, Cloneable, Comparable<getTopologySummaries_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getTopologySummaries_result\");\n \n@@ -38754,10 +40266,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -38804,6 +40318,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public getTopologySummaries_result deepCopy() {\n       return new getTopologySummaries_result(this);\n     }\n@@ -38878,6 +40393,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case SUCCESS:\n@@ -38900,6 +40416,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case SUCCESS:\n@@ -38913,6 +40430,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -38929,8 +40447,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getTopologySummaries_result)\n         return this.equals((getTopologySummaries_result)that);\n       return false;\n@@ -38986,7 +40502,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_success()).compareTo(other.is_set_success());\n+      lastComparison = java.lang.Boolean.compare(is_set_success(), other.is_set_success());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -38996,7 +40512,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -39010,10 +40526,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -39068,6 +40586,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologySummaries_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologySummaries_resultStandardScheme getScheme() {\n         return new getTopologySummaries_resultStandardScheme();\n       }\n@@ -39075,6 +40594,7 @@ public class Nimbus {\n \n     private static class getTopologySummaries_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getTopologySummaries_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getTopologySummaries_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -39122,6 +40642,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getTopologySummaries_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -39150,6 +40671,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologySummaries_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologySummaries_resultTupleScheme getScheme() {\n         return new getTopologySummaries_resultTupleScheme();\n       }\n@@ -39188,7 +40710,7 @@ public class Nimbus {\n         java.util.BitSet incoming = iprot.readBitSet(2);\n         if (incoming.get(0)) {\n           {\n-            org.apache.storm.thrift.protocol.TList _list983 = new org.apache.storm.thrift.protocol.TList(org.apache.storm.thrift.protocol.TType.STRUCT, iprot.readI32());\n+            org.apache.storm.thrift.protocol.TList _list983 = iprot.readListBegin(org.apache.storm.thrift.protocol.TType.STRUCT);\n             struct.success = new java.util.ArrayList<TopologySummary>(_list983.size);\n             @org.apache.storm.thrift.annotation.Nullable TopologySummary _elem984;\n             for (int _i985 = 0; _i985 < _list983.size; ++_i985)\n@@ -39213,6 +40735,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getTopologySummaryByName_args implements org.apache.storm.thrift.TBase<getTopologySummaryByName_args, getTopologySummaryByName_args._Fields>, java.io.Serializable, Cloneable, Comparable<getTopologySummaryByName_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getTopologySummaryByName_args\");\n \n@@ -39274,10 +40797,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -39312,6 +40837,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public getTopologySummaryByName_args deepCopy() {\n       return new getTopologySummaryByName_args(this);\n     }\n@@ -39345,6 +40871,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case NAME:\n@@ -39359,6 +40886,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case NAME:\n@@ -39369,6 +40897,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -39383,8 +40912,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getTopologySummaryByName_args)\n         return this.equals((getTopologySummaryByName_args)that);\n       return false;\n@@ -39427,7 +40954,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_name()).compareTo(other.is_set_name());\n+      lastComparison = java.lang.Boolean.compare(is_set_name(), other.is_set_name());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -39441,14 +40968,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -39491,6 +41021,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologySummaryByName_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologySummaryByName_argsStandardScheme getScheme() {\n         return new getTopologySummaryByName_argsStandardScheme();\n       }\n@@ -39498,6 +41029,7 @@ public class Nimbus {\n \n     private static class getTopologySummaryByName_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getTopologySummaryByName_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getTopologySummaryByName_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -39525,6 +41057,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getTopologySummaryByName_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -39541,6 +41074,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologySummaryByName_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologySummaryByName_argsTupleScheme getScheme() {\n         return new getTopologySummaryByName_argsTupleScheme();\n       }\n@@ -39577,6 +41111,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getTopologySummaryByName_result implements org.apache.storm.thrift.TBase<getTopologySummaryByName_result, getTopologySummaryByName_result._Fields>, java.io.Serializable, Cloneable, Comparable<getTopologySummaryByName_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getTopologySummaryByName_result\");\n \n@@ -39648,10 +41183,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -39700,6 +41237,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public getTopologySummaryByName_result deepCopy() {\n       return new getTopologySummaryByName_result(this);\n     }\n@@ -39783,6 +41321,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case SUCCESS:\n@@ -39813,6 +41352,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case SUCCESS:\n@@ -39829,6 +41369,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -39847,8 +41388,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getTopologySummaryByName_result)\n         return this.equals((getTopologySummaryByName_result)that);\n       return false;\n@@ -39917,7 +41456,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_success()).compareTo(other.is_set_success());\n+      lastComparison = java.lang.Boolean.compare(is_set_success(), other.is_set_success());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -39927,7 +41466,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_e()).compareTo(other.is_set_e());\n+      lastComparison = java.lang.Boolean.compare(is_set_e(), other.is_set_e());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -39937,7 +41476,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -39951,10 +41490,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -40020,6 +41561,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologySummaryByName_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologySummaryByName_resultStandardScheme getScheme() {\n         return new getTopologySummaryByName_resultStandardScheme();\n       }\n@@ -40027,6 +41569,7 @@ public class Nimbus {\n \n     private static class getTopologySummaryByName_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getTopologySummaryByName_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getTopologySummaryByName_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -40073,6 +41616,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getTopologySummaryByName_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -40099,6 +41643,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologySummaryByName_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologySummaryByName_resultTupleScheme getScheme() {\n         return new getTopologySummaryByName_resultTupleScheme();\n       }\n@@ -40158,6 +41703,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getTopologySummary_args implements org.apache.storm.thrift.TBase<getTopologySummary_args, getTopologySummary_args._Fields>, java.io.Serializable, Cloneable, Comparable<getTopologySummary_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getTopologySummary_args\");\n \n@@ -40219,10 +41765,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -40257,6 +41805,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public getTopologySummary_args deepCopy() {\n       return new getTopologySummary_args(this);\n     }\n@@ -40290,6 +41839,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case ID:\n@@ -40304,6 +41854,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case ID:\n@@ -40314,6 +41865,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -40328,8 +41880,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getTopologySummary_args)\n         return this.equals((getTopologySummary_args)that);\n       return false;\n@@ -40372,7 +41922,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_id()).compareTo(other.is_set_id());\n+      lastComparison = java.lang.Boolean.compare(is_set_id(), other.is_set_id());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -40386,14 +41936,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -40436,6 +41989,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologySummary_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologySummary_argsStandardScheme getScheme() {\n         return new getTopologySummary_argsStandardScheme();\n       }\n@@ -40443,6 +41997,7 @@ public class Nimbus {\n \n     private static class getTopologySummary_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getTopologySummary_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getTopologySummary_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -40470,6 +42025,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getTopologySummary_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -40486,6 +42042,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologySummary_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologySummary_argsTupleScheme getScheme() {\n         return new getTopologySummary_argsTupleScheme();\n       }\n@@ -40522,6 +42079,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getTopologySummary_result implements org.apache.storm.thrift.TBase<getTopologySummary_result, getTopologySummary_result._Fields>, java.io.Serializable, Cloneable, Comparable<getTopologySummary_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getTopologySummary_result\");\n \n@@ -40593,10 +42151,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -40645,6 +42205,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public getTopologySummary_result deepCopy() {\n       return new getTopologySummary_result(this);\n     }\n@@ -40728,6 +42289,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case SUCCESS:\n@@ -40758,6 +42320,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case SUCCESS:\n@@ -40774,6 +42337,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -40792,8 +42356,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getTopologySummary_result)\n         return this.equals((getTopologySummary_result)that);\n       return false;\n@@ -40862,7 +42424,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_success()).compareTo(other.is_set_success());\n+      lastComparison = java.lang.Boolean.compare(is_set_success(), other.is_set_success());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -40872,7 +42434,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_e()).compareTo(other.is_set_e());\n+      lastComparison = java.lang.Boolean.compare(is_set_e(), other.is_set_e());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -40882,7 +42444,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -40896,10 +42458,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -40965,6 +42529,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologySummary_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologySummary_resultStandardScheme getScheme() {\n         return new getTopologySummary_resultStandardScheme();\n       }\n@@ -40972,6 +42537,7 @@ public class Nimbus {\n \n     private static class getTopologySummary_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getTopologySummary_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getTopologySummary_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -41018,6 +42584,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getTopologySummary_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -41044,6 +42611,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologySummary_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologySummary_resultTupleScheme getScheme() {\n         return new getTopologySummary_resultTupleScheme();\n       }\n@@ -41103,6 +42671,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getLeader_args implements org.apache.storm.thrift.TBase<getLeader_args, getLeader_args._Fields>, java.io.Serializable, Cloneable, Comparable<getLeader_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getLeader_args\");\n \n@@ -41160,10 +42729,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -41184,6 +42755,7 @@ public class Nimbus {\n     public getLeader_args(getLeader_args other) {\n     }\n \n+    @Override\n     public getLeader_args deepCopy() {\n       return new getLeader_args(this);\n     }\n@@ -41192,12 +42764,14 @@ public class Nimbus {\n     public void clear() {\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       }\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       }\n@@ -41205,6 +42779,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -41217,8 +42792,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getLeader_args)\n         return this.equals((getLeader_args)that);\n       return false;\n@@ -41252,14 +42825,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -41295,6 +42871,7 @@ public class Nimbus {\n     }\n \n     private static class getLeader_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getLeader_argsStandardScheme getScheme() {\n         return new getLeader_argsStandardScheme();\n       }\n@@ -41302,6 +42879,7 @@ public class Nimbus {\n \n     private static class getLeader_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getLeader_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getLeader_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -41321,6 +42899,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getLeader_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -41332,6 +42911,7 @@ public class Nimbus {\n     }\n \n     private static class getLeader_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getLeader_argsTupleScheme getScheme() {\n         return new getLeader_argsTupleScheme();\n       }\n@@ -41355,6 +42935,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getLeader_result implements org.apache.storm.thrift.TBase<getLeader_result, getLeader_result._Fields>, java.io.Serializable, Cloneable, Comparable<getLeader_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getLeader_result\");\n \n@@ -41421,10 +43002,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -41466,6 +43049,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public getLeader_result deepCopy() {\n       return new getLeader_result(this);\n     }\n@@ -41524,6 +43108,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case SUCCESS:\n@@ -41546,6 +43131,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case SUCCESS:\n@@ -41559,6 +43145,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -41575,8 +43162,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getLeader_result)\n         return this.equals((getLeader_result)that);\n       return false;\n@@ -41632,7 +43217,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_success()).compareTo(other.is_set_success());\n+      lastComparison = java.lang.Boolean.compare(is_set_success(), other.is_set_success());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -41642,7 +43227,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -41656,10 +43241,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -41717,6 +43304,7 @@ public class Nimbus {\n     }\n \n     private static class getLeader_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getLeader_resultStandardScheme getScheme() {\n         return new getLeader_resultStandardScheme();\n       }\n@@ -41724,6 +43312,7 @@ public class Nimbus {\n \n     private static class getLeader_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getLeader_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getLeader_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -41761,6 +43350,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getLeader_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -41782,6 +43372,7 @@ public class Nimbus {\n     }\n \n     private static class getLeader_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getLeader_resultTupleScheme getScheme() {\n         return new getLeader_resultTupleScheme();\n       }\n@@ -41830,6 +43421,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class isTopologyNameAllowed_args implements org.apache.storm.thrift.TBase<isTopologyNameAllowed_args, isTopologyNameAllowed_args._Fields>, java.io.Serializable, Cloneable, Comparable<isTopologyNameAllowed_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"isTopologyNameAllowed_args\");\n \n@@ -41891,10 +43483,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -41929,6 +43523,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public isTopologyNameAllowed_args deepCopy() {\n       return new isTopologyNameAllowed_args(this);\n     }\n@@ -41962,6 +43557,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case NAME:\n@@ -41976,6 +43572,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case NAME:\n@@ -41986,6 +43583,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -42000,8 +43598,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof isTopologyNameAllowed_args)\n         return this.equals((isTopologyNameAllowed_args)that);\n       return false;\n@@ -42044,7 +43640,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_name()).compareTo(other.is_set_name());\n+      lastComparison = java.lang.Boolean.compare(is_set_name(), other.is_set_name());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -42058,14 +43654,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -42108,6 +43707,7 @@ public class Nimbus {\n     }\n \n     private static class isTopologyNameAllowed_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public isTopologyNameAllowed_argsStandardScheme getScheme() {\n         return new isTopologyNameAllowed_argsStandardScheme();\n       }\n@@ -42115,6 +43715,7 @@ public class Nimbus {\n \n     private static class isTopologyNameAllowed_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<isTopologyNameAllowed_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, isTopologyNameAllowed_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -42142,6 +43743,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, isTopologyNameAllowed_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -42158,6 +43760,7 @@ public class Nimbus {\n     }\n \n     private static class isTopologyNameAllowed_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public isTopologyNameAllowed_argsTupleScheme getScheme() {\n         return new isTopologyNameAllowed_argsTupleScheme();\n       }\n@@ -42194,6 +43797,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class isTopologyNameAllowed_result implements org.apache.storm.thrift.TBase<isTopologyNameAllowed_result, isTopologyNameAllowed_result._Fields>, java.io.Serializable, Cloneable, Comparable<isTopologyNameAllowed_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"isTopologyNameAllowed_result\");\n \n@@ -42260,10 +43864,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -42307,6 +43913,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public isTopologyNameAllowed_result deepCopy() {\n       return new isTopologyNameAllowed_result(this);\n     }\n@@ -42364,6 +43971,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case SUCCESS:\n@@ -42386,6 +43994,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case SUCCESS:\n@@ -42399,6 +44008,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -42415,8 +44025,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof isTopologyNameAllowed_result)\n         return this.equals((isTopologyNameAllowed_result)that);\n       return false;\n@@ -42470,7 +44078,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_success()).compareTo(other.is_set_success());\n+      lastComparison = java.lang.Boolean.compare(is_set_success(), other.is_set_success());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -42480,7 +44088,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -42494,10 +44102,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -42550,6 +44160,7 @@ public class Nimbus {\n     }\n \n     private static class isTopologyNameAllowed_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public isTopologyNameAllowed_resultStandardScheme getScheme() {\n         return new isTopologyNameAllowed_resultStandardScheme();\n       }\n@@ -42557,6 +44168,7 @@ public class Nimbus {\n \n     private static class isTopologyNameAllowed_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<isTopologyNameAllowed_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, isTopologyNameAllowed_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -42593,6 +44205,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, isTopologyNameAllowed_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -42614,6 +44227,7 @@ public class Nimbus {\n     }\n \n     private static class isTopologyNameAllowed_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public isTopologyNameAllowed_resultTupleScheme getScheme() {\n         return new isTopologyNameAllowed_resultTupleScheme();\n       }\n@@ -42661,6 +44275,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getTopologyInfoByName_args implements org.apache.storm.thrift.TBase<getTopologyInfoByName_args, getTopologyInfoByName_args._Fields>, java.io.Serializable, Cloneable, Comparable<getTopologyInfoByName_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getTopologyInfoByName_args\");\n \n@@ -42722,10 +44337,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -42760,6 +44377,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public getTopologyInfoByName_args deepCopy() {\n       return new getTopologyInfoByName_args(this);\n     }\n@@ -42793,6 +44411,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case NAME:\n@@ -42807,6 +44426,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case NAME:\n@@ -42817,6 +44437,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -42831,8 +44452,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getTopologyInfoByName_args)\n         return this.equals((getTopologyInfoByName_args)that);\n       return false;\n@@ -42875,7 +44494,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_name()).compareTo(other.is_set_name());\n+      lastComparison = java.lang.Boolean.compare(is_set_name(), other.is_set_name());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -42889,14 +44508,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -42939,6 +44561,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologyInfoByName_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologyInfoByName_argsStandardScheme getScheme() {\n         return new getTopologyInfoByName_argsStandardScheme();\n       }\n@@ -42946,6 +44569,7 @@ public class Nimbus {\n \n     private static class getTopologyInfoByName_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getTopologyInfoByName_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getTopologyInfoByName_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -42973,6 +44597,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getTopologyInfoByName_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -42989,6 +44614,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologyInfoByName_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologyInfoByName_argsTupleScheme getScheme() {\n         return new getTopologyInfoByName_argsTupleScheme();\n       }\n@@ -43025,6 +44651,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getTopologyInfoByName_result implements org.apache.storm.thrift.TBase<getTopologyInfoByName_result, getTopologyInfoByName_result._Fields>, java.io.Serializable, Cloneable, Comparable<getTopologyInfoByName_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getTopologyInfoByName_result\");\n \n@@ -43096,10 +44723,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -43148,6 +44777,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public getTopologyInfoByName_result deepCopy() {\n       return new getTopologyInfoByName_result(this);\n     }\n@@ -43231,6 +44861,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case SUCCESS:\n@@ -43261,6 +44892,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case SUCCESS:\n@@ -43277,6 +44909,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -43295,8 +44928,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getTopologyInfoByName_result)\n         return this.equals((getTopologyInfoByName_result)that);\n       return false;\n@@ -43365,7 +44996,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_success()).compareTo(other.is_set_success());\n+      lastComparison = java.lang.Boolean.compare(is_set_success(), other.is_set_success());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -43375,7 +45006,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_e()).compareTo(other.is_set_e());\n+      lastComparison = java.lang.Boolean.compare(is_set_e(), other.is_set_e());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -43385,7 +45016,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -43399,10 +45030,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -43468,6 +45101,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologyInfoByName_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologyInfoByName_resultStandardScheme getScheme() {\n         return new getTopologyInfoByName_resultStandardScheme();\n       }\n@@ -43475,6 +45109,7 @@ public class Nimbus {\n \n     private static class getTopologyInfoByName_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getTopologyInfoByName_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getTopologyInfoByName_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -43521,6 +45156,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getTopologyInfoByName_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -43547,6 +45183,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologyInfoByName_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologyInfoByName_resultTupleScheme getScheme() {\n         return new getTopologyInfoByName_resultTupleScheme();\n       }\n@@ -43606,6 +45243,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getTopologyInfo_args implements org.apache.storm.thrift.TBase<getTopologyInfo_args, getTopologyInfo_args._Fields>, java.io.Serializable, Cloneable, Comparable<getTopologyInfo_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getTopologyInfo_args\");\n \n@@ -43667,10 +45305,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -43705,6 +45345,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public getTopologyInfo_args deepCopy() {\n       return new getTopologyInfo_args(this);\n     }\n@@ -43738,6 +45379,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case ID:\n@@ -43752,6 +45394,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case ID:\n@@ -43762,6 +45405,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -43776,8 +45420,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getTopologyInfo_args)\n         return this.equals((getTopologyInfo_args)that);\n       return false;\n@@ -43820,7 +45462,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_id()).compareTo(other.is_set_id());\n+      lastComparison = java.lang.Boolean.compare(is_set_id(), other.is_set_id());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -43834,14 +45476,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -43884,6 +45529,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologyInfo_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologyInfo_argsStandardScheme getScheme() {\n         return new getTopologyInfo_argsStandardScheme();\n       }\n@@ -43891,6 +45537,7 @@ public class Nimbus {\n \n     private static class getTopologyInfo_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getTopologyInfo_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getTopologyInfo_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -43918,6 +45565,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getTopologyInfo_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -43934,6 +45582,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologyInfo_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologyInfo_argsTupleScheme getScheme() {\n         return new getTopologyInfo_argsTupleScheme();\n       }\n@@ -43970,6 +45619,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getTopologyInfo_result implements org.apache.storm.thrift.TBase<getTopologyInfo_result, getTopologyInfo_result._Fields>, java.io.Serializable, Cloneable, Comparable<getTopologyInfo_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getTopologyInfo_result\");\n \n@@ -44041,10 +45691,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -44093,6 +45745,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public getTopologyInfo_result deepCopy() {\n       return new getTopologyInfo_result(this);\n     }\n@@ -44176,6 +45829,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case SUCCESS:\n@@ -44206,6 +45860,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case SUCCESS:\n@@ -44222,6 +45877,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -44240,8 +45896,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getTopologyInfo_result)\n         return this.equals((getTopologyInfo_result)that);\n       return false;\n@@ -44310,7 +45964,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_success()).compareTo(other.is_set_success());\n+      lastComparison = java.lang.Boolean.compare(is_set_success(), other.is_set_success());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -44320,7 +45974,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_e()).compareTo(other.is_set_e());\n+      lastComparison = java.lang.Boolean.compare(is_set_e(), other.is_set_e());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -44330,7 +45984,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -44344,10 +45998,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -44413,6 +46069,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologyInfo_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologyInfo_resultStandardScheme getScheme() {\n         return new getTopologyInfo_resultStandardScheme();\n       }\n@@ -44420,6 +46077,7 @@ public class Nimbus {\n \n     private static class getTopologyInfo_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getTopologyInfo_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getTopologyInfo_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -44466,6 +46124,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getTopologyInfo_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -44492,6 +46151,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologyInfo_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologyInfo_resultTupleScheme getScheme() {\n         return new getTopologyInfo_resultTupleScheme();\n       }\n@@ -44551,6 +46211,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getTopologyInfoByNameWithOpts_args implements org.apache.storm.thrift.TBase<getTopologyInfoByNameWithOpts_args, getTopologyInfoByNameWithOpts_args._Fields>, java.io.Serializable, Cloneable, Comparable<getTopologyInfoByNameWithOpts_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getTopologyInfoByNameWithOpts_args\");\n \n@@ -44617,10 +46278,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -44662,6 +46325,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public getTopologyInfoByNameWithOpts_args deepCopy() {\n       return new getTopologyInfoByNameWithOpts_args(this);\n     }\n@@ -44720,6 +46384,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case NAME:\n@@ -44742,6 +46407,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case NAME:\n@@ -44755,6 +46421,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -44771,8 +46438,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getTopologyInfoByNameWithOpts_args)\n         return this.equals((getTopologyInfoByNameWithOpts_args)that);\n       return false;\n@@ -44828,7 +46493,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_name()).compareTo(other.is_set_name());\n+      lastComparison = java.lang.Boolean.compare(is_set_name(), other.is_set_name());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -44838,7 +46503,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_options()).compareTo(other.is_set_options());\n+      lastComparison = java.lang.Boolean.compare(is_set_options(), other.is_set_options());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -44852,14 +46517,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -44913,6 +46581,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologyInfoByNameWithOpts_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologyInfoByNameWithOpts_argsStandardScheme getScheme() {\n         return new getTopologyInfoByNameWithOpts_argsStandardScheme();\n       }\n@@ -44920,6 +46589,7 @@ public class Nimbus {\n \n     private static class getTopologyInfoByNameWithOpts_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getTopologyInfoByNameWithOpts_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getTopologyInfoByNameWithOpts_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -44956,6 +46626,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getTopologyInfoByNameWithOpts_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -44977,6 +46648,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologyInfoByNameWithOpts_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologyInfoByNameWithOpts_argsTupleScheme getScheme() {\n         return new getTopologyInfoByNameWithOpts_argsTupleScheme();\n       }\n@@ -45024,6 +46696,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getTopologyInfoByNameWithOpts_result implements org.apache.storm.thrift.TBase<getTopologyInfoByNameWithOpts_result, getTopologyInfoByNameWithOpts_result._Fields>, java.io.Serializable, Cloneable, Comparable<getTopologyInfoByNameWithOpts_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getTopologyInfoByNameWithOpts_result\");\n \n@@ -45095,10 +46768,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -45147,6 +46822,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public getTopologyInfoByNameWithOpts_result deepCopy() {\n       return new getTopologyInfoByNameWithOpts_result(this);\n     }\n@@ -45230,6 +46906,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case SUCCESS:\n@@ -45260,6 +46937,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case SUCCESS:\n@@ -45276,6 +46954,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -45294,8 +46973,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getTopologyInfoByNameWithOpts_result)\n         return this.equals((getTopologyInfoByNameWithOpts_result)that);\n       return false;\n@@ -45364,7 +47041,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_success()).compareTo(other.is_set_success());\n+      lastComparison = java.lang.Boolean.compare(is_set_success(), other.is_set_success());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -45374,7 +47051,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_e()).compareTo(other.is_set_e());\n+      lastComparison = java.lang.Boolean.compare(is_set_e(), other.is_set_e());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -45384,7 +47061,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -45398,10 +47075,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -45467,6 +47146,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologyInfoByNameWithOpts_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologyInfoByNameWithOpts_resultStandardScheme getScheme() {\n         return new getTopologyInfoByNameWithOpts_resultStandardScheme();\n       }\n@@ -45474,6 +47154,7 @@ public class Nimbus {\n \n     private static class getTopologyInfoByNameWithOpts_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getTopologyInfoByNameWithOpts_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getTopologyInfoByNameWithOpts_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -45520,6 +47201,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getTopologyInfoByNameWithOpts_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -45546,6 +47228,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologyInfoByNameWithOpts_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologyInfoByNameWithOpts_resultTupleScheme getScheme() {\n         return new getTopologyInfoByNameWithOpts_resultTupleScheme();\n       }\n@@ -45605,6 +47288,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getTopologyInfoWithOpts_args implements org.apache.storm.thrift.TBase<getTopologyInfoWithOpts_args, getTopologyInfoWithOpts_args._Fields>, java.io.Serializable, Cloneable, Comparable<getTopologyInfoWithOpts_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getTopologyInfoWithOpts_args\");\n \n@@ -45671,10 +47355,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -45716,6 +47402,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public getTopologyInfoWithOpts_args deepCopy() {\n       return new getTopologyInfoWithOpts_args(this);\n     }\n@@ -45774,6 +47461,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case ID:\n@@ -45796,6 +47484,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case ID:\n@@ -45809,6 +47498,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -45825,8 +47515,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getTopologyInfoWithOpts_args)\n         return this.equals((getTopologyInfoWithOpts_args)that);\n       return false;\n@@ -45882,7 +47570,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_id()).compareTo(other.is_set_id());\n+      lastComparison = java.lang.Boolean.compare(is_set_id(), other.is_set_id());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -45892,7 +47580,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_options()).compareTo(other.is_set_options());\n+      lastComparison = java.lang.Boolean.compare(is_set_options(), other.is_set_options());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -45906,14 +47594,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -45967,6 +47658,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologyInfoWithOpts_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologyInfoWithOpts_argsStandardScheme getScheme() {\n         return new getTopologyInfoWithOpts_argsStandardScheme();\n       }\n@@ -45974,6 +47666,7 @@ public class Nimbus {\n \n     private static class getTopologyInfoWithOpts_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getTopologyInfoWithOpts_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getTopologyInfoWithOpts_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -46010,6 +47703,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getTopologyInfoWithOpts_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -46031,6 +47725,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologyInfoWithOpts_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologyInfoWithOpts_argsTupleScheme getScheme() {\n         return new getTopologyInfoWithOpts_argsTupleScheme();\n       }\n@@ -46078,6 +47773,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getTopologyInfoWithOpts_result implements org.apache.storm.thrift.TBase<getTopologyInfoWithOpts_result, getTopologyInfoWithOpts_result._Fields>, java.io.Serializable, Cloneable, Comparable<getTopologyInfoWithOpts_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getTopologyInfoWithOpts_result\");\n \n@@ -46149,10 +47845,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -46201,6 +47899,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public getTopologyInfoWithOpts_result deepCopy() {\n       return new getTopologyInfoWithOpts_result(this);\n     }\n@@ -46284,6 +47983,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case SUCCESS:\n@@ -46314,6 +48014,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case SUCCESS:\n@@ -46330,6 +48031,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -46348,8 +48050,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getTopologyInfoWithOpts_result)\n         return this.equals((getTopologyInfoWithOpts_result)that);\n       return false;\n@@ -46418,7 +48118,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_success()).compareTo(other.is_set_success());\n+      lastComparison = java.lang.Boolean.compare(is_set_success(), other.is_set_success());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -46428,7 +48128,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_e()).compareTo(other.is_set_e());\n+      lastComparison = java.lang.Boolean.compare(is_set_e(), other.is_set_e());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -46438,7 +48138,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -46452,10 +48152,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -46521,6 +48223,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologyInfoWithOpts_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologyInfoWithOpts_resultStandardScheme getScheme() {\n         return new getTopologyInfoWithOpts_resultStandardScheme();\n       }\n@@ -46528,6 +48231,7 @@ public class Nimbus {\n \n     private static class getTopologyInfoWithOpts_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getTopologyInfoWithOpts_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getTopologyInfoWithOpts_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -46574,6 +48278,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getTopologyInfoWithOpts_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -46600,6 +48305,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologyInfoWithOpts_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologyInfoWithOpts_resultTupleScheme getScheme() {\n         return new getTopologyInfoWithOpts_resultTupleScheme();\n       }\n@@ -46659,6 +48365,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getTopologyPageInfo_args implements org.apache.storm.thrift.TBase<getTopologyPageInfo_args, getTopologyPageInfo_args._Fields>, java.io.Serializable, Cloneable, Comparable<getTopologyPageInfo_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getTopologyPageInfo_args\");\n \n@@ -46730,10 +48437,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -46784,6 +48493,7 @@ public class Nimbus {\n       this.is_include_sys = other.is_include_sys;\n     }\n \n+    @Override\n     public getTopologyPageInfo_args deepCopy() {\n       return new getTopologyPageInfo_args(this);\n     }\n@@ -46866,6 +48576,7 @@ public class Nimbus {\n       __isset_bitfield = org.apache.storm.thrift.EncodingUtils.setBit(__isset_bitfield, __IS_INCLUDE_SYS_ISSET_ID, value);\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case ID:\n@@ -46896,6 +48607,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case ID:\n@@ -46912,6 +48624,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -46930,8 +48643,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getTopologyPageInfo_args)\n         return this.equals((getTopologyPageInfo_args)that);\n       return false;\n@@ -46998,7 +48709,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_id()).compareTo(other.is_set_id());\n+      lastComparison = java.lang.Boolean.compare(is_set_id(), other.is_set_id());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -47008,7 +48719,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_window()).compareTo(other.is_set_window());\n+      lastComparison = java.lang.Boolean.compare(is_set_window(), other.is_set_window());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -47018,7 +48729,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_is_include_sys()).compareTo(other.is_set_is_include_sys());\n+      lastComparison = java.lang.Boolean.compare(is_set_is_include_sys(), other.is_set_is_include_sys());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -47032,14 +48743,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -47096,6 +48810,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologyPageInfo_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologyPageInfo_argsStandardScheme getScheme() {\n         return new getTopologyPageInfo_argsStandardScheme();\n       }\n@@ -47103,6 +48818,7 @@ public class Nimbus {\n \n     private static class getTopologyPageInfo_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getTopologyPageInfo_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getTopologyPageInfo_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -47146,6 +48862,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getTopologyPageInfo_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -47170,6 +48887,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologyPageInfo_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologyPageInfo_argsTupleScheme getScheme() {\n         return new getTopologyPageInfo_argsTupleScheme();\n       }\n@@ -47226,6 +48944,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getTopologyPageInfo_result implements org.apache.storm.thrift.TBase<getTopologyPageInfo_result, getTopologyPageInfo_result._Fields>, java.io.Serializable, Cloneable, Comparable<getTopologyPageInfo_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getTopologyPageInfo_result\");\n \n@@ -47297,10 +49016,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -47349,6 +49070,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public getTopologyPageInfo_result deepCopy() {\n       return new getTopologyPageInfo_result(this);\n     }\n@@ -47432,6 +49154,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case SUCCESS:\n@@ -47462,6 +49185,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case SUCCESS:\n@@ -47478,6 +49202,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -47496,8 +49221,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getTopologyPageInfo_result)\n         return this.equals((getTopologyPageInfo_result)that);\n       return false;\n@@ -47566,7 +49289,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_success()).compareTo(other.is_set_success());\n+      lastComparison = java.lang.Boolean.compare(is_set_success(), other.is_set_success());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -47576,7 +49299,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_e()).compareTo(other.is_set_e());\n+      lastComparison = java.lang.Boolean.compare(is_set_e(), other.is_set_e());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -47586,7 +49309,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -47600,10 +49323,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -47669,6 +49394,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologyPageInfo_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologyPageInfo_resultStandardScheme getScheme() {\n         return new getTopologyPageInfo_resultStandardScheme();\n       }\n@@ -47676,6 +49402,7 @@ public class Nimbus {\n \n     private static class getTopologyPageInfo_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getTopologyPageInfo_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getTopologyPageInfo_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -47722,6 +49449,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getTopologyPageInfo_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -47748,6 +49476,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologyPageInfo_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologyPageInfo_resultTupleScheme getScheme() {\n         return new getTopologyPageInfo_resultTupleScheme();\n       }\n@@ -47807,6 +49536,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getSupervisorPageInfo_args implements org.apache.storm.thrift.TBase<getSupervisorPageInfo_args, getSupervisorPageInfo_args._Fields>, java.io.Serializable, Cloneable, Comparable<getSupervisorPageInfo_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getSupervisorPageInfo_args\");\n \n@@ -47878,10 +49608,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -47932,6 +49664,7 @@ public class Nimbus {\n       this.is_include_sys = other.is_include_sys;\n     }\n \n+    @Override\n     public getSupervisorPageInfo_args deepCopy() {\n       return new getSupervisorPageInfo_args(this);\n     }\n@@ -48014,6 +49747,7 @@ public class Nimbus {\n       __isset_bitfield = org.apache.storm.thrift.EncodingUtils.setBit(__isset_bitfield, __IS_INCLUDE_SYS_ISSET_ID, value);\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case ID:\n@@ -48044,6 +49778,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case ID:\n@@ -48060,6 +49795,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -48078,8 +49814,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getSupervisorPageInfo_args)\n         return this.equals((getSupervisorPageInfo_args)that);\n       return false;\n@@ -48146,7 +49880,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_id()).compareTo(other.is_set_id());\n+      lastComparison = java.lang.Boolean.compare(is_set_id(), other.is_set_id());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -48156,7 +49890,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_host()).compareTo(other.is_set_host());\n+      lastComparison = java.lang.Boolean.compare(is_set_host(), other.is_set_host());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -48166,7 +49900,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_is_include_sys()).compareTo(other.is_set_is_include_sys());\n+      lastComparison = java.lang.Boolean.compare(is_set_is_include_sys(), other.is_set_is_include_sys());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -48180,14 +49914,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -48244,6 +49981,7 @@ public class Nimbus {\n     }\n \n     private static class getSupervisorPageInfo_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getSupervisorPageInfo_argsStandardScheme getScheme() {\n         return new getSupervisorPageInfo_argsStandardScheme();\n       }\n@@ -48251,6 +49989,7 @@ public class Nimbus {\n \n     private static class getSupervisorPageInfo_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getSupervisorPageInfo_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getSupervisorPageInfo_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -48294,6 +50033,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getSupervisorPageInfo_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -48318,6 +50058,7 @@ public class Nimbus {\n     }\n \n     private static class getSupervisorPageInfo_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getSupervisorPageInfo_argsTupleScheme getScheme() {\n         return new getSupervisorPageInfo_argsTupleScheme();\n       }\n@@ -48374,6 +50115,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getSupervisorPageInfo_result implements org.apache.storm.thrift.TBase<getSupervisorPageInfo_result, getSupervisorPageInfo_result._Fields>, java.io.Serializable, Cloneable, Comparable<getSupervisorPageInfo_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getSupervisorPageInfo_result\");\n \n@@ -48445,10 +50187,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -48497,6 +50241,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public getSupervisorPageInfo_result deepCopy() {\n       return new getSupervisorPageInfo_result(this);\n     }\n@@ -48580,6 +50325,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case SUCCESS:\n@@ -48610,6 +50356,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case SUCCESS:\n@@ -48626,6 +50373,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -48644,8 +50392,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getSupervisorPageInfo_result)\n         return this.equals((getSupervisorPageInfo_result)that);\n       return false;\n@@ -48714,7 +50460,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_success()).compareTo(other.is_set_success());\n+      lastComparison = java.lang.Boolean.compare(is_set_success(), other.is_set_success());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -48724,7 +50470,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_e()).compareTo(other.is_set_e());\n+      lastComparison = java.lang.Boolean.compare(is_set_e(), other.is_set_e());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -48734,7 +50480,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -48748,10 +50494,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -48817,6 +50565,7 @@ public class Nimbus {\n     }\n \n     private static class getSupervisorPageInfo_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getSupervisorPageInfo_resultStandardScheme getScheme() {\n         return new getSupervisorPageInfo_resultStandardScheme();\n       }\n@@ -48824,6 +50573,7 @@ public class Nimbus {\n \n     private static class getSupervisorPageInfo_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getSupervisorPageInfo_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getSupervisorPageInfo_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -48870,6 +50620,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getSupervisorPageInfo_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -48896,6 +50647,7 @@ public class Nimbus {\n     }\n \n     private static class getSupervisorPageInfo_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getSupervisorPageInfo_resultTupleScheme getScheme() {\n         return new getSupervisorPageInfo_resultTupleScheme();\n       }\n@@ -48955,6 +50707,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getComponentPageInfo_args implements org.apache.storm.thrift.TBase<getComponentPageInfo_args, getComponentPageInfo_args._Fields>, java.io.Serializable, Cloneable, Comparable<getComponentPageInfo_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getComponentPageInfo_args\");\n \n@@ -49031,10 +50784,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -49092,6 +50847,7 @@ public class Nimbus {\n       this.is_include_sys = other.is_include_sys;\n     }\n \n+    @Override\n     public getComponentPageInfo_args deepCopy() {\n       return new getComponentPageInfo_args(this);\n     }\n@@ -49199,6 +50955,7 @@ public class Nimbus {\n       __isset_bitfield = org.apache.storm.thrift.EncodingUtils.setBit(__isset_bitfield, __IS_INCLUDE_SYS_ISSET_ID, value);\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case TOPOLOGY_ID:\n@@ -49237,6 +50994,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case TOPOLOGY_ID:\n@@ -49256,6 +51014,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -49276,8 +51035,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getComponentPageInfo_args)\n         return this.equals((getComponentPageInfo_args)that);\n       return false;\n@@ -49357,7 +51114,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_topology_id()).compareTo(other.is_set_topology_id());\n+      lastComparison = java.lang.Boolean.compare(is_set_topology_id(), other.is_set_topology_id());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -49367,7 +51124,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_component_id()).compareTo(other.is_set_component_id());\n+      lastComparison = java.lang.Boolean.compare(is_set_component_id(), other.is_set_component_id());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -49377,7 +51134,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_window()).compareTo(other.is_set_window());\n+      lastComparison = java.lang.Boolean.compare(is_set_window(), other.is_set_window());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -49387,7 +51144,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_is_include_sys()).compareTo(other.is_set_is_include_sys());\n+      lastComparison = java.lang.Boolean.compare(is_set_is_include_sys(), other.is_set_is_include_sys());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -49401,14 +51158,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -49473,6 +51233,7 @@ public class Nimbus {\n     }\n \n     private static class getComponentPageInfo_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getComponentPageInfo_argsStandardScheme getScheme() {\n         return new getComponentPageInfo_argsStandardScheme();\n       }\n@@ -49480,6 +51241,7 @@ public class Nimbus {\n \n     private static class getComponentPageInfo_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getComponentPageInfo_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getComponentPageInfo_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -49531,6 +51293,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getComponentPageInfo_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -49560,6 +51323,7 @@ public class Nimbus {\n     }\n \n     private static class getComponentPageInfo_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getComponentPageInfo_argsTupleScheme getScheme() {\n         return new getComponentPageInfo_argsTupleScheme();\n       }\n@@ -49626,6 +51390,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getComponentPageInfo_result implements org.apache.storm.thrift.TBase<getComponentPageInfo_result, getComponentPageInfo_result._Fields>, java.io.Serializable, Cloneable, Comparable<getComponentPageInfo_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getComponentPageInfo_result\");\n \n@@ -49697,10 +51462,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -49749,6 +51516,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public getComponentPageInfo_result deepCopy() {\n       return new getComponentPageInfo_result(this);\n     }\n@@ -49832,6 +51600,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case SUCCESS:\n@@ -49862,6 +51631,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case SUCCESS:\n@@ -49878,6 +51648,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -49896,8 +51667,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getComponentPageInfo_result)\n         return this.equals((getComponentPageInfo_result)that);\n       return false;\n@@ -49966,7 +51735,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_success()).compareTo(other.is_set_success());\n+      lastComparison = java.lang.Boolean.compare(is_set_success(), other.is_set_success());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -49976,7 +51745,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_e()).compareTo(other.is_set_e());\n+      lastComparison = java.lang.Boolean.compare(is_set_e(), other.is_set_e());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -49986,7 +51755,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -50000,10 +51769,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -50069,6 +51840,7 @@ public class Nimbus {\n     }\n \n     private static class getComponentPageInfo_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getComponentPageInfo_resultStandardScheme getScheme() {\n         return new getComponentPageInfo_resultStandardScheme();\n       }\n@@ -50076,6 +51848,7 @@ public class Nimbus {\n \n     private static class getComponentPageInfo_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getComponentPageInfo_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getComponentPageInfo_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -50122,6 +51895,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getComponentPageInfo_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -50148,6 +51922,7 @@ public class Nimbus {\n     }\n \n     private static class getComponentPageInfo_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getComponentPageInfo_resultTupleScheme getScheme() {\n         return new getComponentPageInfo_resultTupleScheme();\n       }\n@@ -50207,6 +51982,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getTopologyConf_args implements org.apache.storm.thrift.TBase<getTopologyConf_args, getTopologyConf_args._Fields>, java.io.Serializable, Cloneable, Comparable<getTopologyConf_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getTopologyConf_args\");\n \n@@ -50268,10 +52044,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -50306,6 +52084,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public getTopologyConf_args deepCopy() {\n       return new getTopologyConf_args(this);\n     }\n@@ -50339,6 +52118,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case ID:\n@@ -50353,6 +52133,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case ID:\n@@ -50363,6 +52144,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -50377,8 +52159,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getTopologyConf_args)\n         return this.equals((getTopologyConf_args)that);\n       return false;\n@@ -50421,7 +52201,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_id()).compareTo(other.is_set_id());\n+      lastComparison = java.lang.Boolean.compare(is_set_id(), other.is_set_id());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -50435,14 +52215,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -50485,6 +52268,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologyConf_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologyConf_argsStandardScheme getScheme() {\n         return new getTopologyConf_argsStandardScheme();\n       }\n@@ -50492,6 +52276,7 @@ public class Nimbus {\n \n     private static class getTopologyConf_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getTopologyConf_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getTopologyConf_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -50519,6 +52304,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getTopologyConf_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -50535,6 +52321,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologyConf_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologyConf_argsTupleScheme getScheme() {\n         return new getTopologyConf_argsTupleScheme();\n       }\n@@ -50571,6 +52358,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getTopologyConf_result implements org.apache.storm.thrift.TBase<getTopologyConf_result, getTopologyConf_result._Fields>, java.io.Serializable, Cloneable, Comparable<getTopologyConf_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getTopologyConf_result\");\n \n@@ -50642,10 +52430,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -50694,6 +52484,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public getTopologyConf_result deepCopy() {\n       return new getTopologyConf_result(this);\n     }\n@@ -50777,6 +52568,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case SUCCESS:\n@@ -50807,6 +52599,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case SUCCESS:\n@@ -50823,6 +52616,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -50841,8 +52635,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getTopologyConf_result)\n         return this.equals((getTopologyConf_result)that);\n       return false;\n@@ -50911,7 +52703,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_success()).compareTo(other.is_set_success());\n+      lastComparison = java.lang.Boolean.compare(is_set_success(), other.is_set_success());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -50921,7 +52713,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_e()).compareTo(other.is_set_e());\n+      lastComparison = java.lang.Boolean.compare(is_set_e(), other.is_set_e());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -50931,7 +52723,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -50945,10 +52737,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -51011,6 +52805,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologyConf_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologyConf_resultStandardScheme getScheme() {\n         return new getTopologyConf_resultStandardScheme();\n       }\n@@ -51018,6 +52813,7 @@ public class Nimbus {\n \n     private static class getTopologyConf_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getTopologyConf_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getTopologyConf_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -51063,6 +52859,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getTopologyConf_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -51089,6 +52886,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologyConf_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologyConf_resultTupleScheme getScheme() {\n         return new getTopologyConf_resultTupleScheme();\n       }\n@@ -51147,6 +52945,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getTopology_args implements org.apache.storm.thrift.TBase<getTopology_args, getTopology_args._Fields>, java.io.Serializable, Cloneable, Comparable<getTopology_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getTopology_args\");\n \n@@ -51208,10 +53007,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -51246,6 +53047,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public getTopology_args deepCopy() {\n       return new getTopology_args(this);\n     }\n@@ -51279,6 +53081,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case ID:\n@@ -51293,6 +53096,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case ID:\n@@ -51303,6 +53107,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -51317,8 +53122,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getTopology_args)\n         return this.equals((getTopology_args)that);\n       return false;\n@@ -51361,7 +53164,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_id()).compareTo(other.is_set_id());\n+      lastComparison = java.lang.Boolean.compare(is_set_id(), other.is_set_id());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -51375,14 +53178,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -51425,6 +53231,7 @@ public class Nimbus {\n     }\n \n     private static class getTopology_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopology_argsStandardScheme getScheme() {\n         return new getTopology_argsStandardScheme();\n       }\n@@ -51432,6 +53239,7 @@ public class Nimbus {\n \n     private static class getTopology_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getTopology_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getTopology_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -51459,6 +53267,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getTopology_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -51475,6 +53284,7 @@ public class Nimbus {\n     }\n \n     private static class getTopology_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopology_argsTupleScheme getScheme() {\n         return new getTopology_argsTupleScheme();\n       }\n@@ -51511,6 +53321,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getTopology_result implements org.apache.storm.thrift.TBase<getTopology_result, getTopology_result._Fields>, java.io.Serializable, Cloneable, Comparable<getTopology_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getTopology_result\");\n \n@@ -51582,10 +53393,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -51634,6 +53447,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public getTopology_result deepCopy() {\n       return new getTopology_result(this);\n     }\n@@ -51717,6 +53531,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case SUCCESS:\n@@ -51747,6 +53562,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case SUCCESS:\n@@ -51763,6 +53579,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -51781,8 +53598,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getTopology_result)\n         return this.equals((getTopology_result)that);\n       return false;\n@@ -51851,7 +53666,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_success()).compareTo(other.is_set_success());\n+      lastComparison = java.lang.Boolean.compare(is_set_success(), other.is_set_success());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -51861,7 +53676,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_e()).compareTo(other.is_set_e());\n+      lastComparison = java.lang.Boolean.compare(is_set_e(), other.is_set_e());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -51871,7 +53686,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -51885,10 +53700,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -51954,6 +53771,7 @@ public class Nimbus {\n     }\n \n     private static class getTopology_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopology_resultStandardScheme getScheme() {\n         return new getTopology_resultStandardScheme();\n       }\n@@ -51961,6 +53779,7 @@ public class Nimbus {\n \n     private static class getTopology_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getTopology_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getTopology_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -52007,6 +53826,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getTopology_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -52033,6 +53853,7 @@ public class Nimbus {\n     }\n \n     private static class getTopology_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopology_resultTupleScheme getScheme() {\n         return new getTopology_resultTupleScheme();\n       }\n@@ -52092,6 +53913,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getUserTopology_args implements org.apache.storm.thrift.TBase<getUserTopology_args, getUserTopology_args._Fields>, java.io.Serializable, Cloneable, Comparable<getUserTopology_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getUserTopology_args\");\n \n@@ -52153,10 +53975,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -52191,6 +54015,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public getUserTopology_args deepCopy() {\n       return new getUserTopology_args(this);\n     }\n@@ -52224,6 +54049,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case ID:\n@@ -52238,6 +54064,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case ID:\n@@ -52248,6 +54075,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -52262,8 +54090,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getUserTopology_args)\n         return this.equals((getUserTopology_args)that);\n       return false;\n@@ -52306,7 +54132,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_id()).compareTo(other.is_set_id());\n+      lastComparison = java.lang.Boolean.compare(is_set_id(), other.is_set_id());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -52320,14 +54146,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -52370,6 +54199,7 @@ public class Nimbus {\n     }\n \n     private static class getUserTopology_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getUserTopology_argsStandardScheme getScheme() {\n         return new getUserTopology_argsStandardScheme();\n       }\n@@ -52377,6 +54207,7 @@ public class Nimbus {\n \n     private static class getUserTopology_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getUserTopology_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getUserTopology_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -52404,6 +54235,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getUserTopology_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -52420,6 +54252,7 @@ public class Nimbus {\n     }\n \n     private static class getUserTopology_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getUserTopology_argsTupleScheme getScheme() {\n         return new getUserTopology_argsTupleScheme();\n       }\n@@ -52456,6 +54289,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getUserTopology_result implements org.apache.storm.thrift.TBase<getUserTopology_result, getUserTopology_result._Fields>, java.io.Serializable, Cloneable, Comparable<getUserTopology_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getUserTopology_result\");\n \n@@ -52527,10 +54361,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -52579,6 +54415,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public getUserTopology_result deepCopy() {\n       return new getUserTopology_result(this);\n     }\n@@ -52662,6 +54499,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case SUCCESS:\n@@ -52692,6 +54530,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case SUCCESS:\n@@ -52708,6 +54547,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -52726,8 +54566,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getUserTopology_result)\n         return this.equals((getUserTopology_result)that);\n       return false;\n@@ -52796,7 +54634,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_success()).compareTo(other.is_set_success());\n+      lastComparison = java.lang.Boolean.compare(is_set_success(), other.is_set_success());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -52806,7 +54644,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_e()).compareTo(other.is_set_e());\n+      lastComparison = java.lang.Boolean.compare(is_set_e(), other.is_set_e());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -52816,7 +54654,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -52830,10 +54668,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -52899,6 +54739,7 @@ public class Nimbus {\n     }\n \n     private static class getUserTopology_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getUserTopology_resultStandardScheme getScheme() {\n         return new getUserTopology_resultStandardScheme();\n       }\n@@ -52906,6 +54747,7 @@ public class Nimbus {\n \n     private static class getUserTopology_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getUserTopology_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getUserTopology_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -52952,6 +54794,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getUserTopology_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -52978,6 +54821,7 @@ public class Nimbus {\n     }\n \n     private static class getUserTopology_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getUserTopology_resultTupleScheme getScheme() {\n         return new getUserTopology_resultTupleScheme();\n       }\n@@ -53037,6 +54881,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getTopologyHistory_args implements org.apache.storm.thrift.TBase<getTopologyHistory_args, getTopologyHistory_args._Fields>, java.io.Serializable, Cloneable, Comparable<getTopologyHistory_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getTopologyHistory_args\");\n \n@@ -53098,10 +54943,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -53136,6 +54983,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public getTopologyHistory_args deepCopy() {\n       return new getTopologyHistory_args(this);\n     }\n@@ -53169,6 +55017,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case USER:\n@@ -53183,6 +55032,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case USER:\n@@ -53193,6 +55043,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -53207,8 +55058,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getTopologyHistory_args)\n         return this.equals((getTopologyHistory_args)that);\n       return false;\n@@ -53251,7 +55100,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_user()).compareTo(other.is_set_user());\n+      lastComparison = java.lang.Boolean.compare(is_set_user(), other.is_set_user());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -53265,14 +55114,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -53315,6 +55167,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologyHistory_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologyHistory_argsStandardScheme getScheme() {\n         return new getTopologyHistory_argsStandardScheme();\n       }\n@@ -53322,6 +55175,7 @@ public class Nimbus {\n \n     private static class getTopologyHistory_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getTopologyHistory_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getTopologyHistory_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -53349,6 +55203,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getTopologyHistory_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -53365,6 +55220,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologyHistory_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologyHistory_argsTupleScheme getScheme() {\n         return new getTopologyHistory_argsTupleScheme();\n       }\n@@ -53401,6 +55257,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getTopologyHistory_result implements org.apache.storm.thrift.TBase<getTopologyHistory_result, getTopologyHistory_result._Fields>, java.io.Serializable, Cloneable, Comparable<getTopologyHistory_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getTopologyHistory_result\");\n \n@@ -53467,10 +55324,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -53512,6 +55371,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public getTopologyHistory_result deepCopy() {\n       return new getTopologyHistory_result(this);\n     }\n@@ -53570,6 +55430,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case SUCCESS:\n@@ -53592,6 +55453,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case SUCCESS:\n@@ -53605,6 +55467,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -53621,8 +55484,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getTopologyHistory_result)\n         return this.equals((getTopologyHistory_result)that);\n       return false;\n@@ -53678,7 +55539,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_success()).compareTo(other.is_set_success());\n+      lastComparison = java.lang.Boolean.compare(is_set_success(), other.is_set_success());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -53688,7 +55549,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -53702,10 +55563,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -53763,6 +55626,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologyHistory_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologyHistory_resultStandardScheme getScheme() {\n         return new getTopologyHistory_resultStandardScheme();\n       }\n@@ -53770,6 +55634,7 @@ public class Nimbus {\n \n     private static class getTopologyHistory_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getTopologyHistory_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getTopologyHistory_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -53807,6 +55672,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getTopologyHistory_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -53828,6 +55694,7 @@ public class Nimbus {\n     }\n \n     private static class getTopologyHistory_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getTopologyHistory_resultTupleScheme getScheme() {\n         return new getTopologyHistory_resultTupleScheme();\n       }\n@@ -53876,6 +55743,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getOwnerResourceSummaries_args implements org.apache.storm.thrift.TBase<getOwnerResourceSummaries_args, getOwnerResourceSummaries_args._Fields>, java.io.Serializable, Cloneable, Comparable<getOwnerResourceSummaries_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getOwnerResourceSummaries_args\");\n \n@@ -53937,10 +55805,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -53975,6 +55845,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public getOwnerResourceSummaries_args deepCopy() {\n       return new getOwnerResourceSummaries_args(this);\n     }\n@@ -54008,6 +55879,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case OWNER:\n@@ -54022,6 +55894,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case OWNER:\n@@ -54032,6 +55905,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -54046,8 +55920,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getOwnerResourceSummaries_args)\n         return this.equals((getOwnerResourceSummaries_args)that);\n       return false;\n@@ -54090,7 +55962,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_owner()).compareTo(other.is_set_owner());\n+      lastComparison = java.lang.Boolean.compare(is_set_owner(), other.is_set_owner());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -54104,14 +55976,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -54154,6 +56029,7 @@ public class Nimbus {\n     }\n \n     private static class getOwnerResourceSummaries_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getOwnerResourceSummaries_argsStandardScheme getScheme() {\n         return new getOwnerResourceSummaries_argsStandardScheme();\n       }\n@@ -54161,6 +56037,7 @@ public class Nimbus {\n \n     private static class getOwnerResourceSummaries_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getOwnerResourceSummaries_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getOwnerResourceSummaries_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -54188,6 +56065,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getOwnerResourceSummaries_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -54204,6 +56082,7 @@ public class Nimbus {\n     }\n \n     private static class getOwnerResourceSummaries_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getOwnerResourceSummaries_argsTupleScheme getScheme() {\n         return new getOwnerResourceSummaries_argsTupleScheme();\n       }\n@@ -54240,6 +56119,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getOwnerResourceSummaries_result implements org.apache.storm.thrift.TBase<getOwnerResourceSummaries_result, getOwnerResourceSummaries_result._Fields>, java.io.Serializable, Cloneable, Comparable<getOwnerResourceSummaries_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getOwnerResourceSummaries_result\");\n \n@@ -54306,10 +56186,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -54356,6 +56238,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public getOwnerResourceSummaries_result deepCopy() {\n       return new getOwnerResourceSummaries_result(this);\n     }\n@@ -54430,6 +56313,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case SUCCESS:\n@@ -54452,6 +56336,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case SUCCESS:\n@@ -54465,6 +56350,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -54481,8 +56367,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getOwnerResourceSummaries_result)\n         return this.equals((getOwnerResourceSummaries_result)that);\n       return false;\n@@ -54538,7 +56422,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_success()).compareTo(other.is_set_success());\n+      lastComparison = java.lang.Boolean.compare(is_set_success(), other.is_set_success());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -54548,7 +56432,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -54562,10 +56446,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -54620,6 +56506,7 @@ public class Nimbus {\n     }\n \n     private static class getOwnerResourceSummaries_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getOwnerResourceSummaries_resultStandardScheme getScheme() {\n         return new getOwnerResourceSummaries_resultStandardScheme();\n       }\n@@ -54627,6 +56514,7 @@ public class Nimbus {\n \n     private static class getOwnerResourceSummaries_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getOwnerResourceSummaries_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getOwnerResourceSummaries_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -54674,6 +56562,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getOwnerResourceSummaries_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -54702,6 +56591,7 @@ public class Nimbus {\n     }\n \n     private static class getOwnerResourceSummaries_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getOwnerResourceSummaries_resultTupleScheme getScheme() {\n         return new getOwnerResourceSummaries_resultTupleScheme();\n       }\n@@ -54740,7 +56630,7 @@ public class Nimbus {\n         java.util.BitSet incoming = iprot.readBitSet(2);\n         if (incoming.get(0)) {\n           {\n-            org.apache.storm.thrift.protocol.TList _list991 = new org.apache.storm.thrift.protocol.TList(org.apache.storm.thrift.protocol.TType.STRUCT, iprot.readI32());\n+            org.apache.storm.thrift.protocol.TList _list991 = iprot.readListBegin(org.apache.storm.thrift.protocol.TType.STRUCT);\n             struct.success = new java.util.ArrayList<OwnerResourceSummary>(_list991.size);\n             @org.apache.storm.thrift.annotation.Nullable OwnerResourceSummary _elem992;\n             for (int _i993 = 0; _i993 < _list991.size; ++_i993)\n@@ -54765,6 +56655,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getSupervisorAssignments_args implements org.apache.storm.thrift.TBase<getSupervisorAssignments_args, getSupervisorAssignments_args._Fields>, java.io.Serializable, Cloneable, Comparable<getSupervisorAssignments_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getSupervisorAssignments_args\");\n \n@@ -54826,10 +56717,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -54864,6 +56757,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public getSupervisorAssignments_args deepCopy() {\n       return new getSupervisorAssignments_args(this);\n     }\n@@ -54897,6 +56791,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case NODE:\n@@ -54911,6 +56806,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case NODE:\n@@ -54921,6 +56817,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -54935,8 +56832,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getSupervisorAssignments_args)\n         return this.equals((getSupervisorAssignments_args)that);\n       return false;\n@@ -54979,7 +56874,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_node()).compareTo(other.is_set_node());\n+      lastComparison = java.lang.Boolean.compare(is_set_node(), other.is_set_node());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -54993,14 +56888,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -55043,6 +56941,7 @@ public class Nimbus {\n     }\n \n     private static class getSupervisorAssignments_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getSupervisorAssignments_argsStandardScheme getScheme() {\n         return new getSupervisorAssignments_argsStandardScheme();\n       }\n@@ -55050,6 +56949,7 @@ public class Nimbus {\n \n     private static class getSupervisorAssignments_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getSupervisorAssignments_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getSupervisorAssignments_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -55077,6 +56977,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getSupervisorAssignments_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -55093,6 +56994,7 @@ public class Nimbus {\n     }\n \n     private static class getSupervisorAssignments_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getSupervisorAssignments_argsTupleScheme getScheme() {\n         return new getSupervisorAssignments_argsTupleScheme();\n       }\n@@ -55129,6 +57031,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class getSupervisorAssignments_result implements org.apache.storm.thrift.TBase<getSupervisorAssignments_result, getSupervisorAssignments_result._Fields>, java.io.Serializable, Cloneable, Comparable<getSupervisorAssignments_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"getSupervisorAssignments_result\");\n \n@@ -55195,10 +57098,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -55240,6 +57145,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public getSupervisorAssignments_result deepCopy() {\n       return new getSupervisorAssignments_result(this);\n     }\n@@ -55298,6 +57204,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case SUCCESS:\n@@ -55320,6 +57227,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case SUCCESS:\n@@ -55333,6 +57241,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -55349,8 +57258,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof getSupervisorAssignments_result)\n         return this.equals((getSupervisorAssignments_result)that);\n       return false;\n@@ -55406,7 +57313,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_success()).compareTo(other.is_set_success());\n+      lastComparison = java.lang.Boolean.compare(is_set_success(), other.is_set_success());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -55416,7 +57323,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -55430,10 +57337,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -55491,6 +57400,7 @@ public class Nimbus {\n     }\n \n     private static class getSupervisorAssignments_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getSupervisorAssignments_resultStandardScheme getScheme() {\n         return new getSupervisorAssignments_resultStandardScheme();\n       }\n@@ -55498,6 +57408,7 @@ public class Nimbus {\n \n     private static class getSupervisorAssignments_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<getSupervisorAssignments_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, getSupervisorAssignments_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -55535,6 +57446,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, getSupervisorAssignments_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -55556,6 +57468,7 @@ public class Nimbus {\n     }\n \n     private static class getSupervisorAssignments_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public getSupervisorAssignments_resultTupleScheme getScheme() {\n         return new getSupervisorAssignments_resultTupleScheme();\n       }\n@@ -55604,6 +57517,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class sendSupervisorWorkerHeartbeats_args implements org.apache.storm.thrift.TBase<sendSupervisorWorkerHeartbeats_args, sendSupervisorWorkerHeartbeats_args._Fields>, java.io.Serializable, Cloneable, Comparable<sendSupervisorWorkerHeartbeats_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"sendSupervisorWorkerHeartbeats_args\");\n \n@@ -55665,10 +57579,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -55703,6 +57619,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public sendSupervisorWorkerHeartbeats_args deepCopy() {\n       return new sendSupervisorWorkerHeartbeats_args(this);\n     }\n@@ -55736,6 +57653,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case HEARTBEATS:\n@@ -55750,6 +57668,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case HEARTBEATS:\n@@ -55760,6 +57679,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -55774,8 +57694,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof sendSupervisorWorkerHeartbeats_args)\n         return this.equals((sendSupervisorWorkerHeartbeats_args)that);\n       return false;\n@@ -55818,7 +57736,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_heartbeats()).compareTo(other.is_set_heartbeats());\n+      lastComparison = java.lang.Boolean.compare(is_set_heartbeats(), other.is_set_heartbeats());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -55832,14 +57750,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -55885,6 +57806,7 @@ public class Nimbus {\n     }\n \n     private static class sendSupervisorWorkerHeartbeats_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public sendSupervisorWorkerHeartbeats_argsStandardScheme getScheme() {\n         return new sendSupervisorWorkerHeartbeats_argsStandardScheme();\n       }\n@@ -55892,6 +57814,7 @@ public class Nimbus {\n \n     private static class sendSupervisorWorkerHeartbeats_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<sendSupervisorWorkerHeartbeats_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, sendSupervisorWorkerHeartbeats_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -55920,6 +57843,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, sendSupervisorWorkerHeartbeats_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -55936,6 +57860,7 @@ public class Nimbus {\n     }\n \n     private static class sendSupervisorWorkerHeartbeats_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public sendSupervisorWorkerHeartbeats_argsTupleScheme getScheme() {\n         return new sendSupervisorWorkerHeartbeats_argsTupleScheme();\n       }\n@@ -55973,6 +57898,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class sendSupervisorWorkerHeartbeats_result implements org.apache.storm.thrift.TBase<sendSupervisorWorkerHeartbeats_result, sendSupervisorWorkerHeartbeats_result._Fields>, java.io.Serializable, Cloneable, Comparable<sendSupervisorWorkerHeartbeats_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"sendSupervisorWorkerHeartbeats_result\");\n \n@@ -56034,10 +57960,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -56072,6 +58000,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public sendSupervisorWorkerHeartbeats_result deepCopy() {\n       return new sendSupervisorWorkerHeartbeats_result(this);\n     }\n@@ -56105,6 +58034,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case AZE:\n@@ -56119,6 +58049,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case AZE:\n@@ -56129,6 +58060,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -56143,8 +58075,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof sendSupervisorWorkerHeartbeats_result)\n         return this.equals((sendSupervisorWorkerHeartbeats_result)that);\n       return false;\n@@ -56187,7 +58117,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -56201,10 +58131,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -56251,6 +58183,7 @@ public class Nimbus {\n     }\n \n     private static class sendSupervisorWorkerHeartbeats_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public sendSupervisorWorkerHeartbeats_resultStandardScheme getScheme() {\n         return new sendSupervisorWorkerHeartbeats_resultStandardScheme();\n       }\n@@ -56258,6 +58191,7 @@ public class Nimbus {\n \n     private static class sendSupervisorWorkerHeartbeats_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<sendSupervisorWorkerHeartbeats_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, sendSupervisorWorkerHeartbeats_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -56286,6 +58220,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, sendSupervisorWorkerHeartbeats_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -56302,6 +58237,7 @@ public class Nimbus {\n     }\n \n     private static class sendSupervisorWorkerHeartbeats_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public sendSupervisorWorkerHeartbeats_resultTupleScheme getScheme() {\n         return new sendSupervisorWorkerHeartbeats_resultTupleScheme();\n       }\n@@ -56339,6 +58275,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class sendSupervisorWorkerHeartbeat_args implements org.apache.storm.thrift.TBase<sendSupervisorWorkerHeartbeat_args, sendSupervisorWorkerHeartbeat_args._Fields>, java.io.Serializable, Cloneable, Comparable<sendSupervisorWorkerHeartbeat_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"sendSupervisorWorkerHeartbeat_args\");\n \n@@ -56400,10 +58337,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -56438,6 +58377,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public sendSupervisorWorkerHeartbeat_args deepCopy() {\n       return new sendSupervisorWorkerHeartbeat_args(this);\n     }\n@@ -56471,6 +58411,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case HEATBEAT:\n@@ -56485,6 +58426,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case HEATBEAT:\n@@ -56495,6 +58437,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -56509,8 +58452,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof sendSupervisorWorkerHeartbeat_args)\n         return this.equals((sendSupervisorWorkerHeartbeat_args)that);\n       return false;\n@@ -56553,7 +58494,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_heatbeat()).compareTo(other.is_set_heatbeat());\n+      lastComparison = java.lang.Boolean.compare(is_set_heatbeat(), other.is_set_heatbeat());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -56567,14 +58508,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -56620,6 +58564,7 @@ public class Nimbus {\n     }\n \n     private static class sendSupervisorWorkerHeartbeat_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public sendSupervisorWorkerHeartbeat_argsStandardScheme getScheme() {\n         return new sendSupervisorWorkerHeartbeat_argsStandardScheme();\n       }\n@@ -56627,6 +58572,7 @@ public class Nimbus {\n \n     private static class sendSupervisorWorkerHeartbeat_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<sendSupervisorWorkerHeartbeat_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, sendSupervisorWorkerHeartbeat_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -56655,6 +58601,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, sendSupervisorWorkerHeartbeat_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -56671,6 +58618,7 @@ public class Nimbus {\n     }\n \n     private static class sendSupervisorWorkerHeartbeat_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public sendSupervisorWorkerHeartbeat_argsTupleScheme getScheme() {\n         return new sendSupervisorWorkerHeartbeat_argsTupleScheme();\n       }\n@@ -56708,6 +58656,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class sendSupervisorWorkerHeartbeat_result implements org.apache.storm.thrift.TBase<sendSupervisorWorkerHeartbeat_result, sendSupervisorWorkerHeartbeat_result._Fields>, java.io.Serializable, Cloneable, Comparable<sendSupervisorWorkerHeartbeat_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"sendSupervisorWorkerHeartbeat_result\");\n \n@@ -56774,10 +58723,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -56819,6 +58770,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public sendSupervisorWorkerHeartbeat_result deepCopy() {\n       return new sendSupervisorWorkerHeartbeat_result(this);\n     }\n@@ -56877,6 +58829,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case AZE:\n@@ -56899,6 +58852,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case AZE:\n@@ -56912,6 +58866,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -56928,8 +58883,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof sendSupervisorWorkerHeartbeat_result)\n         return this.equals((sendSupervisorWorkerHeartbeat_result)that);\n       return false;\n@@ -56985,7 +58938,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -56995,7 +58948,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_e()).compareTo(other.is_set_e());\n+      lastComparison = java.lang.Boolean.compare(is_set_e(), other.is_set_e());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -57009,10 +58962,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -57067,6 +59022,7 @@ public class Nimbus {\n     }\n \n     private static class sendSupervisorWorkerHeartbeat_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public sendSupervisorWorkerHeartbeat_resultStandardScheme getScheme() {\n         return new sendSupervisorWorkerHeartbeat_resultStandardScheme();\n       }\n@@ -57074,6 +59030,7 @@ public class Nimbus {\n \n     private static class sendSupervisorWorkerHeartbeat_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<sendSupervisorWorkerHeartbeat_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, sendSupervisorWorkerHeartbeat_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -57111,6 +59068,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, sendSupervisorWorkerHeartbeat_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -57132,6 +59090,7 @@ public class Nimbus {\n     }\n \n     private static class sendSupervisorWorkerHeartbeat_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public sendSupervisorWorkerHeartbeat_resultTupleScheme getScheme() {\n         return new sendSupervisorWorkerHeartbeat_resultTupleScheme();\n       }\n@@ -57180,6 +59139,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class processWorkerMetrics_args implements org.apache.storm.thrift.TBase<processWorkerMetrics_args, processWorkerMetrics_args._Fields>, java.io.Serializable, Cloneable, Comparable<processWorkerMetrics_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"processWorkerMetrics_args\");\n \n@@ -57241,10 +59201,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -57279,6 +59241,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public processWorkerMetrics_args deepCopy() {\n       return new processWorkerMetrics_args(this);\n     }\n@@ -57312,6 +59275,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case METRICS:\n@@ -57326,6 +59290,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case METRICS:\n@@ -57336,6 +59301,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -57350,8 +59316,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof processWorkerMetrics_args)\n         return this.equals((processWorkerMetrics_args)that);\n       return false;\n@@ -57394,7 +59358,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_metrics()).compareTo(other.is_set_metrics());\n+      lastComparison = java.lang.Boolean.compare(is_set_metrics(), other.is_set_metrics());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -57408,14 +59372,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -57461,6 +59428,7 @@ public class Nimbus {\n     }\n \n     private static class processWorkerMetrics_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public processWorkerMetrics_argsStandardScheme getScheme() {\n         return new processWorkerMetrics_argsStandardScheme();\n       }\n@@ -57468,6 +59436,7 @@ public class Nimbus {\n \n     private static class processWorkerMetrics_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<processWorkerMetrics_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, processWorkerMetrics_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -57496,6 +59465,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, processWorkerMetrics_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -57512,6 +59482,7 @@ public class Nimbus {\n     }\n \n     private static class processWorkerMetrics_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public processWorkerMetrics_argsTupleScheme getScheme() {\n         return new processWorkerMetrics_argsTupleScheme();\n       }\n@@ -57549,6 +59520,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class processWorkerMetrics_result implements org.apache.storm.thrift.TBase<processWorkerMetrics_result, processWorkerMetrics_result._Fields>, java.io.Serializable, Cloneable, Comparable<processWorkerMetrics_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"processWorkerMetrics_result\");\n \n@@ -57606,10 +59578,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -57630,6 +59604,7 @@ public class Nimbus {\n     public processWorkerMetrics_result(processWorkerMetrics_result other) {\n     }\n \n+    @Override\n     public processWorkerMetrics_result deepCopy() {\n       return new processWorkerMetrics_result(this);\n     }\n@@ -57638,12 +59613,14 @@ public class Nimbus {\n     public void clear() {\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       }\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       }\n@@ -57651,6 +59628,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -57663,8 +59641,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof processWorkerMetrics_result)\n         return this.equals((processWorkerMetrics_result)that);\n       return false;\n@@ -57698,10 +59674,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -57741,6 +59719,7 @@ public class Nimbus {\n     }\n \n     private static class processWorkerMetrics_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public processWorkerMetrics_resultStandardScheme getScheme() {\n         return new processWorkerMetrics_resultStandardScheme();\n       }\n@@ -57748,6 +59727,7 @@ public class Nimbus {\n \n     private static class processWorkerMetrics_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<processWorkerMetrics_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, processWorkerMetrics_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -57767,6 +59747,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, processWorkerMetrics_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -57778,6 +59759,7 @@ public class Nimbus {\n     }\n \n     private static class processWorkerMetrics_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public processWorkerMetrics_resultTupleScheme getScheme() {\n         return new processWorkerMetrics_resultTupleScheme();\n       }\n@@ -57801,6 +59783,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class isRemoteBlobExists_args implements org.apache.storm.thrift.TBase<isRemoteBlobExists_args, isRemoteBlobExists_args._Fields>, java.io.Serializable, Cloneable, Comparable<isRemoteBlobExists_args>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"isRemoteBlobExists_args\");\n \n@@ -57862,10 +59845,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -57900,6 +59885,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public isRemoteBlobExists_args deepCopy() {\n       return new isRemoteBlobExists_args(this);\n     }\n@@ -57933,6 +59919,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case BLOB_KEY:\n@@ -57947,6 +59934,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case BLOB_KEY:\n@@ -57957,6 +59945,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -57971,8 +59960,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof isRemoteBlobExists_args)\n         return this.equals((isRemoteBlobExists_args)that);\n       return false;\n@@ -58015,7 +60002,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_blobKey()).compareTo(other.is_set_blobKey());\n+      lastComparison = java.lang.Boolean.compare(is_set_blobKey(), other.is_set_blobKey());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -58029,14 +60016,17 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n \n+    @Override\n     public void write(org.apache.storm.thrift.protocol.TProtocol oprot) throws org.apache.storm.thrift.TException {\n       scheme(oprot).write(oprot, this);\n     }\n@@ -58079,6 +60069,7 @@ public class Nimbus {\n     }\n \n     private static class isRemoteBlobExists_argsStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public isRemoteBlobExists_argsStandardScheme getScheme() {\n         return new isRemoteBlobExists_argsStandardScheme();\n       }\n@@ -58086,6 +60077,7 @@ public class Nimbus {\n \n     private static class isRemoteBlobExists_argsStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<isRemoteBlobExists_args> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, isRemoteBlobExists_args struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -58113,6 +60105,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, isRemoteBlobExists_args struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -58129,6 +60122,7 @@ public class Nimbus {\n     }\n \n     private static class isRemoteBlobExists_argsTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public isRemoteBlobExists_argsTupleScheme getScheme() {\n         return new isRemoteBlobExists_argsTupleScheme();\n       }\n@@ -58165,6 +60159,7 @@ public class Nimbus {\n     }\n   }\n \n+  @SuppressWarnings({\"cast\", \"rawtypes\", \"serial\", \"unchecked\", \"unused\"})\n   public static class isRemoteBlobExists_result implements org.apache.storm.thrift.TBase<isRemoteBlobExists_result, isRemoteBlobExists_result._Fields>, java.io.Serializable, Cloneable, Comparable<isRemoteBlobExists_result>   {\n     private static final org.apache.storm.thrift.protocol.TStruct STRUCT_DESC = new org.apache.storm.thrift.protocol.TStruct(\"isRemoteBlobExists_result\");\n \n@@ -58231,10 +60226,12 @@ public class Nimbus {\n         _fieldName = fieldName;\n       }\n \n+      @Override\n       public short getThriftFieldId() {\n         return _thriftId;\n       }\n \n+      @Override\n       public java.lang.String getFieldName() {\n         return _fieldName;\n       }\n@@ -58278,6 +60275,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public isRemoteBlobExists_result deepCopy() {\n       return new isRemoteBlobExists_result(this);\n     }\n@@ -58335,6 +60333,7 @@ public class Nimbus {\n       }\n     }\n \n+    @Override\n     public void setFieldValue(_Fields field, @org.apache.storm.thrift.annotation.Nullable java.lang.Object value) {\n       switch (field) {\n       case SUCCESS:\n@@ -58357,6 +60356,7 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public java.lang.Object getFieldValue(_Fields field) {\n       switch (field) {\n       case SUCCESS:\n@@ -58370,6 +60370,7 @@ public class Nimbus {\n     }\n \n     /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */\n+    @Override\n     public boolean isSet(_Fields field) {\n       if (field == null) {\n         throw new java.lang.IllegalArgumentException();\n@@ -58386,8 +60387,6 @@ public class Nimbus {\n \n     @Override\n     public boolean equals(java.lang.Object that) {\n-      if (that == null)\n-        return false;\n       if (that instanceof isRemoteBlobExists_result)\n         return this.equals((isRemoteBlobExists_result)that);\n       return false;\n@@ -58441,7 +60440,7 @@ public class Nimbus {\n \n       int lastComparison = 0;\n \n-      lastComparison = java.lang.Boolean.valueOf(is_set_success()).compareTo(other.is_set_success());\n+      lastComparison = java.lang.Boolean.compare(is_set_success(), other.is_set_success());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -58451,7 +60450,7 @@ public class Nimbus {\n           return lastComparison;\n         }\n       }\n-      lastComparison = java.lang.Boolean.valueOf(is_set_aze()).compareTo(other.is_set_aze());\n+      lastComparison = java.lang.Boolean.compare(is_set_aze(), other.is_set_aze());\n       if (lastComparison != 0) {\n         return lastComparison;\n       }\n@@ -58465,10 +60464,12 @@ public class Nimbus {\n     }\n \n     @org.apache.storm.thrift.annotation.Nullable\n+    @Override\n     public _Fields fieldForId(int fieldId) {\n       return _Fields.findByThriftId(fieldId);\n     }\n \n+    @Override\n     public void read(org.apache.storm.thrift.protocol.TProtocol iprot) throws org.apache.storm.thrift.TException {\n       scheme(iprot).read(iprot, this);\n     }\n@@ -58521,6 +60522,7 @@ public class Nimbus {\n     }\n \n     private static class isRemoteBlobExists_resultStandardSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public isRemoteBlobExists_resultStandardScheme getScheme() {\n         return new isRemoteBlobExists_resultStandardScheme();\n       }\n@@ -58528,6 +60530,7 @@ public class Nimbus {\n \n     private static class isRemoteBlobExists_resultStandardScheme extends org.apache.storm.thrift.scheme.StandardScheme<isRemoteBlobExists_result> {\n \n+      @Override\n       public void read(org.apache.storm.thrift.protocol.TProtocol iprot, isRemoteBlobExists_result struct) throws org.apache.storm.thrift.TException {\n         org.apache.storm.thrift.protocol.TField schemeField;\n         iprot.readStructBegin();\n@@ -58564,6 +60567,7 @@ public class Nimbus {\n         struct.validate();\n       }\n \n+      @Override\n       public void write(org.apache.storm.thrift.protocol.TProtocol oprot, isRemoteBlobExists_result struct) throws org.apache.storm.thrift.TException {\n         struct.validate();\n \n@@ -58585,6 +60589,7 @@ public class Nimbus {\n     }\n \n     private static class isRemoteBlobExists_resultTupleSchemeFactory implements org.apache.storm.thrift.scheme.SchemeFactory {\n+      @Override\n       public isRemoteBlobExists_resultTupleScheme getScheme() {\n         return new isRemoteBlobExists_resultTupleScheme();\n       }\n",
            "security_relevancy": ""
        },
        {
            "diff": "@@ -1,42 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version\n- * 2.0 (the \"License\"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the License for the specific language governing permissions\n- * and limitations under the License.\n- */\n-\n-package org.apache.storm.cassandra.trident.state;\n-\n-import java.util.Map;\n-import org.apache.storm.cassandra.CassandraContext;\n-import org.apache.storm.cassandra.query.CQLResultSetValuesMapper;\n-import org.apache.storm.cassandra.query.CQLStatementTupleMapper;\n-import org.apache.storm.task.IMetricsContext;\n-import org.apache.storm.trident.state.State;\n-import org.apache.storm.trident.state.StateFactory;\n-\n-public class CassandraStateFactory implements StateFactory {\n-    private final CassandraState.Options options;\n-\n-    public CassandraStateFactory(CassandraState.Options options) {\n-        this.options = options;\n-    }\n-\n-    public CassandraStateFactory(CQLStatementTupleMapper cqlStatementTupleMapper, CQLResultSetValuesMapper cqlResultSetValuesMapper) {\n-        this(new CassandraState.Options(new CassandraContext()).withCQLStatementTupleMapper(cqlStatementTupleMapper)\n-                                                               .withCQLResultSetValuesMapper(cqlResultSetValuesMapper));\n-    }\n-\n-    @Override\n-    public State makeState(Map<String, Object> conf, IMetricsContext metrics, int partitionIndex, int numPartitions) {\n-        CassandraState cassandraState = new CassandraState(conf, options);\n-        cassandraState.prepare();\n-\n-        return cassandraState;\n-    }\n-}\n",
            "security_relevancy": ""
        },
        {
            "diff": "@@ -1,89 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.storm.rocketmq.topology;\n-\n-import java.util.Properties;\n-import org.apache.storm.Config;\n-import org.apache.storm.StormSubmitter;\n-import org.apache.storm.generated.StormTopology;\n-import org.apache.storm.rocketmq.RocketMqConfig;\n-import org.apache.storm.rocketmq.SpoutConfig;\n-import org.apache.storm.rocketmq.bolt.RocketMqBolt;\n-import org.apache.storm.rocketmq.common.mapper.FieldNameBasedTupleToMessageMapper;\n-import org.apache.storm.rocketmq.common.mapper.TupleToMessageMapper;\n-import org.apache.storm.rocketmq.common.selector.DefaultTopicSelector;\n-import org.apache.storm.rocketmq.common.selector.TopicSelector;\n-import org.apache.storm.rocketmq.spout.RocketMqSpout;\n-import org.apache.storm.topology.TopologyBuilder;\n-import org.apache.storm.tuple.Fields;\n-\n-public class WordCountTopology {\n-    private static final String WORD_SPOUT = \"WORD_SPOUT\";\n-    private static final String COUNT_BOLT = \"COUNT_BOLT\";\n-    private static final String INSERT_BOLT = \"INSERT_BOLT\";\n-\n-    private static final String CONSUMER_GROUP = \"wordcount\";\n-    private static final String CONSUMER_TOPIC = \"source\";\n-\n-    public static StormTopology buildTopology(String nameserverAddr, String topic) {\n-        Properties properties = new Properties();\n-        properties.setProperty(SpoutConfig.NAME_SERVER_ADDR, nameserverAddr);\n-        properties.setProperty(SpoutConfig.CONSUMER_GROUP, CONSUMER_GROUP);\n-        properties.setProperty(SpoutConfig.CONSUMER_TOPIC, CONSUMER_TOPIC);\n-\n-        RocketMqSpout spout = new RocketMqSpout(properties);\n-\n-        TupleToMessageMapper mapper = new FieldNameBasedTupleToMessageMapper(\"word\", \"count\");\n-        TopicSelector selector = new DefaultTopicSelector(topic);\n-\n-        properties = new Properties();\n-        properties.setProperty(RocketMqConfig.NAME_SERVER_ADDR, nameserverAddr);\n-\n-        RocketMqBolt insertBolt = new RocketMqBolt()\n-                .withMapper(mapper)\n-                .withSelector(selector)\n-                .withProperties(properties);\n-\n-        // wordSpout ==> countBolt ==> insertBolt\n-        TopologyBuilder builder = new TopologyBuilder();\n-\n-        WordCounter bolt = new WordCounter();\n-        builder.setSpout(WORD_SPOUT, spout, 1);\n-        builder.setBolt(COUNT_BOLT, bolt, 1).fieldsGrouping(WORD_SPOUT, new Fields(\"str\"));\n-        builder.setBolt(INSERT_BOLT, insertBolt, 1).shuffleGrouping(COUNT_BOLT);\n-\n-        return builder.createTopology();\n-    }\n-\n-    public static void main(String[] args) throws Exception {\n-        Config conf = new Config();\n-        conf.setMaxSpoutPending(5);\n-        conf.setNumWorkers(3);\n-\n-        String topologyName = \"wordCounter\";\n-        if (args.length < 2) {\n-            System.out.println(\"Usage: WordCountTopology <nameserver addr> <topic> [topology name]\");\n-        } else {\n-            if (args.length > 3) {\n-                topologyName = args[2];\n-            }\n-            StormSubmitter.submitTopology(topologyName, conf, buildTopology(args[0], args[1]));\n-        }\n-    }\n-}\n",
            "security_relevancy": ""
        },
        {
            "diff": "@@ -15,21 +15,19 @@ package org.apache.storm.security.auth;\n import java.util.Map;\n import org.apache.storm.Config;\n import org.apache.storm.thrift.transport.TTransportException;\n-import org.apache.storm.utils.ThrowableNestedCauseMatcher;\n import org.apache.storm.utils.Utils;\n-import org.junit.Before;\n-import org.junit.Rule;\n-import org.junit.Test;\n-import org.junit.rules.ExpectedException;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n \n public class ThriftClientTest {\n \n-    @Rule\n-    public ExpectedException expectedException = ExpectedException.none();\n-    private int NIMBUS_TIMEOUT = 3 * 1000;\n+    private final int NIMBUS_TIMEOUT = 3 * 1000;\n     private Map<String, Object> conf;\n \n-    @Before\n+    @BeforeEach\n     public void setup() {\n         conf = Utils.readDefaultConfig();\n         conf.put(Config.STORM_NIMBUS_RETRY_TIMES, 0);\n@@ -37,25 +35,27 @@ public class ThriftClientTest {\n \n     @Test\n     public void testConstructorThrowsIfPortNegative() {\n-        expectedException.expect(ThrowableNestedCauseMatcher.isCausedBy(IllegalArgumentException.class));\n-        new ThriftClient(conf, ThriftConnectionType.DRPC, \"bogushost\", -1, NIMBUS_TIMEOUT);\n+        assertThrows(IllegalArgumentException.class,\n+            () -> new ThriftClient(conf, ThriftConnectionType.DRPC, \"bogushost\", -1, NIMBUS_TIMEOUT));\n     }\n \n     @Test\n     public void testConstructorThrowsIfPortZero() {\n-        expectedException.expect(ThrowableNestedCauseMatcher.isCausedBy(IllegalArgumentException.class));\n-        new ThriftClient(conf, ThriftConnectionType.DRPC, \"bogushost\", 0, NIMBUS_TIMEOUT);\n+        assertThrows(IllegalArgumentException.class,\n+            () -> new ThriftClient(conf, ThriftConnectionType.DRPC, \"bogushost\", 0, NIMBUS_TIMEOUT));\n     }\n \n     @Test\n     public void testConstructorThrowsIfHostNull() {\n-        expectedException.expect(ThrowableNestedCauseMatcher.isCausedBy(IllegalArgumentException.class));\n-        new ThriftClient(conf, ThriftConnectionType.DRPC, null, 4242, NIMBUS_TIMEOUT);\n+        assertThrows(IllegalArgumentException.class,\n+            () -> new ThriftClient(conf, ThriftConnectionType.DRPC, null, 4242, NIMBUS_TIMEOUT));\n     }\n \n     @Test\n     public void testConstructorThrowsIfHostEmpty() {\n-        expectedException.expect(ThrowableNestedCauseMatcher.isCausedBy(TTransportException.class));\n-        new ThriftClient(conf, ThriftConnectionType.DRPC, \"\", 4242, NIMBUS_TIMEOUT);\n+        Exception e = assertThrows(RuntimeException.class,\n+            () -> new ThriftClient(conf, ThriftConnectionType.DRPC, \"\", 4242, NIMBUS_TIMEOUT));\n+        // Now the cause of the thrown exception must be TTransportException\n+        assertTrue(e.getCause().getCause() instanceof TTransportException, e.getCause().getMessage());\n     }\n }\n",
            "security_relevancy": ""
        },
        {
            "diff": "@@ -33,12 +33,11 @@ import org.apache.hadoop.hbase.client.Connection;\n import org.apache.hadoop.hbase.client.ConnectionFactory;\n import org.apache.hadoop.hbase.security.User;\n import org.apache.hadoop.hbase.security.UserProvider;\n-import org.apache.hadoop.hbase.security.token.TokenUtil;\n+import org.apache.hadoop.hbase.security.token.ClientTokenUtil;\n import org.apache.hadoop.security.Credentials;\n import org.apache.hadoop.security.UserGroupInformation;\n import org.apache.hadoop.security.token.Token;\n import org.apache.hadoop.security.token.TokenIdentifier;\n-import org.apache.storm.Config;\n import org.apache.storm.common.AbstractHadoopNimbusPluginAutoCreds;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n@@ -93,7 +92,7 @@ public class AutoHBaseNimbus extends AbstractHadoopNimbusPluginAutoCreds {\n \n                 if (user.isHBaseSecurityEnabled(hbaseConf)) {\n                     final Connection connection = ConnectionFactory.createConnection(hbaseConf, user);\n-                    TokenUtil.obtainAndCacheToken(connection, user);\n+                    ClientTokenUtil.obtainAndCacheToken(connection, user);\n \n                     LOG.info(\"Obtained HBase tokens, adding to user credentials.\");\n \n",
            "security_relevancy": ""
        },
        {
            "diff": "@@ -1,58 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.storm.kinesis.spout.test;\n-\n-import com.amazonaws.services.kinesis.model.Record;\n-import org.apache.storm.kinesis.spout.RecordToTupleMapper;\n-import org.apache.storm.tuple.Fields;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import java.io.Serializable;\n-import java.nio.charset.CharacterCodingException;\n-import java.nio.charset.Charset;\n-import java.nio.charset.CharsetDecoder;\n-import java.util.ArrayList;\n-import java.util.List;\n-\n-public class TestRecordToTupleMapper implements RecordToTupleMapper, Serializable {\n-    private static final Logger LOG = LoggerFactory.getLogger(TestRecordToTupleMapper.class);\n-    @Override\n-    public Fields getOutputFields() {\n-        return new Fields(\"partitionKey\", \"sequenceNumber\", \"data\");\n-    }\n-\n-    @Override\n-    public List<Object> getTuple(Record record) {\n-        CharsetDecoder decoder = Charset.forName(\"UTF-8\").newDecoder();\n-        List<Object> tuple = new ArrayList<>();\n-        tuple.add(record.getPartitionKey());\n-        tuple.add(record.getSequenceNumber());\n-        try {\n-            String data = decoder.decode(record.getData()).toString();\n-            LOG.info(\"data is \" + data);\n-            tuple.add(data);\n-        } catch (CharacterCodingException e) {\n-            e.printStackTrace();\n-            LOG.warn(\"Exception occured. Emitting tuple with empty string data\", e);\n-            tuple.add(\"\");\n-        }\n-        LOG.info(\"Tuple from record is \" + tuple);\n-        return tuple;\n-    }\n-}\n",
            "security_relevancy": ""
        },
        {
            "diff": "@@ -34,12 +34,13 @@ import org.apache.kafka.clients.producer.Producer;\n import org.apache.kafka.clients.producer.ProducerRecord;\n import org.apache.kafka.common.Cluster;\n import org.apache.kafka.common.KafkaException;\n+import org.apache.kafka.common.serialization.StringSerializer;\n import org.apache.storm.Testing;\n import org.apache.storm.task.OutputCollector;\n import org.apache.storm.task.TopologyContext;\n import org.apache.storm.testing.MkTupleParam;\n import org.apache.storm.tuple.Tuple;\n-import org.junit.Test;\n+import org.junit.jupiter.api.Test;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n@@ -66,7 +67,9 @@ public class KafkaBoltTest {\n \n     @Test\n     public void testSimple() {\n-        MockProducer<String, String> producer = new MockProducer<>(Cluster.empty(), false, null, null, null);\n+        MockProducer<String, String> producer = new MockProducer<>(\n+                Cluster.empty(), false,\n+                null, new StringSerializer(), new StringSerializer());\n         KafkaBolt<String, String> bolt = makeBolt(producer);\n \n         OutputCollector collector = mock(OutputCollector.class);\n@@ -95,7 +98,9 @@ public class KafkaBoltTest {\n \n     @Test\n     public void testSimpleWithError() {\n-        MockProducer<String, String> producer = new MockProducer<>(Cluster.empty(), false, null, null, null);\n+        MockProducer<String, String> producer = new MockProducer<>(\n+                Cluster.empty(), false,\n+                null, new StringSerializer(), new StringSerializer());\n         KafkaBolt<String, String> bolt = makeBolt(producer);\n \n         OutputCollector collector = mock(OutputCollector.class);\n@@ -126,7 +131,9 @@ public class KafkaBoltTest {\n \n     @Test\n     public void testCustomCallbackIsWrappedByDefaultCallbackBehavior() {\n-        MockProducer<String, String> producer = new MockProducer<>(Cluster.empty(), false, null, null, null);\n+        MockProducer<String, String> producer = new MockProducer<>(\n+                Cluster.empty(), false,\n+                null, new StringSerializer(), new StringSerializer());\n         KafkaBolt<String, String> bolt = makeBolt(producer);\n \n         PreparableCallback customCallback = mock(PreparableCallback.class);\n",
            "security_relevancy": ""
        },
        {
            "diff": "@@ -16,10 +16,10 @@\n package org.apache.storm.kafka.spout;\n \n import static org.apache.storm.kafka.spout.config.builder.SingleTopicKafkaSpoutConfiguration.createKafkaSpoutConfigBuilder;\n-import static org.junit.Assert.assertEquals;\n-import static org.junit.Assert.assertTrue;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n import static org.mockito.ArgumentMatchers.anyList;\n-import static org.mockito.ArgumentMatchers.anyLong;\n+import static org.mockito.ArgumentMatchers.any;\n import static org.mockito.ArgumentMatchers.anyString;\n import static org.mockito.Mockito.inOrder;\n import static org.mockito.Mockito.mock;\n@@ -27,6 +27,7 @@ import static org.mockito.Mockito.times;\n import static org.mockito.Mockito.verify;\n import static org.mockito.Mockito.when;\n \n+import java.time.Duration;\n import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n@@ -39,25 +40,23 @@ import org.apache.storm.spout.SpoutOutputCollector;\n import org.apache.storm.task.TopologyContext;\n import org.apache.storm.utils.Time;\n import org.apache.storm.utils.Time.SimulatedTime;\n-import org.junit.Before;\n-import org.junit.Rule;\n-import org.junit.Test;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n import org.mockito.ArgumentCaptor;\n import org.mockito.Captor;\n import org.mockito.InOrder;\n-import org.mockito.junit.MockitoJUnit;\n-import org.mockito.junit.MockitoRule;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n \n+@ExtendWith(MockitoExtension.class)\n public class KafkaSpoutRetryLimitTest {\n-    \n-    @Rule\n-    public MockitoRule mockito = MockitoJUnit.rule();\n-\n     private final long offsetCommitPeriodMs = 2_000;\n     private final TopologyContext contextMock = mock(TopologyContext.class);\n     private final SpoutOutputCollector collectorMock = mock(SpoutOutputCollector.class);\n     private final Map<String, Object> conf = new HashMap<>();\n     private final TopicPartition partition = new TopicPartition(SingleTopicKafkaSpoutConfiguration.TOPIC, 1);\n+    @Mock\n     private KafkaConsumer<String, String> consumerMock;\n     private KafkaSpoutConfig<String, String> spoutConfig;\n     \n@@ -68,26 +67,25 @@ public class KafkaSpoutRetryLimitTest {\n     @Captor\n     private ArgumentCaptor<Map<TopicPartition, OffsetAndMetadata>> commitCapture;\n     \n-    @Before\n+    @BeforeEach\n     public void setUp() {\n         spoutConfig = createKafkaSpoutConfigBuilder(mock(TopicFilter.class), mock(ManualPartitioner.class), -1)\n             .setOffsetCommitPeriodMs(offsetCommitPeriodMs)\n             .setRetry(ZERO_RETRIES_RETRY_SERVICE)\n             .build();\n-        consumerMock = mock(KafkaConsumer.class);\n     }\n     \n     @Test\n     public void testFailingTupleCompletesAckAfterRetryLimitIsMet() {\n         //Spout should ack failed messages after they hit the retry limit\n-        try (SimulatedTime simulatedTime = new SimulatedTime()) {\n+        try (SimulatedTime ignored = new SimulatedTime()) {\n             KafkaSpout<String, String> spout = SpoutWithMockedConsumerSetupHelper.setupSpout(spoutConfig, conf, contextMock, collectorMock, consumerMock, partition);\n             Map<TopicPartition, List<ConsumerRecord<String, String>>> records = new HashMap<>();\n             int lastOffset = 3;\n             int numRecords = lastOffset + 1;\n             records.put(partition, SpoutWithMockedConsumerSetupHelper.createRecords(partition, 0, numRecords));\n             \n-            when(consumerMock.poll(anyLong()))\n+            when(consumerMock.poll(any(Duration.class)))\n                 .thenReturn(new ConsumerRecords<>(records));\n             \n             for (int i = 0; i < numRecords; i++) {\n@@ -107,11 +105,11 @@ public class KafkaSpoutRetryLimitTest {\n             \n             InOrder inOrder = inOrder(consumerMock);\n             inOrder.verify(consumerMock).commitSync(commitCapture.capture());\n-            inOrder.verify(consumerMock).poll(anyLong());\n+            inOrder.verify(consumerMock).poll(any(Duration.class));\n \n             //verify that offset 4 was committed for the given TopicPartition, since processing should resume at 4.\n             assertTrue(commitCapture.getValue().containsKey(partition));\n-            assertEquals(lastOffset + 1, ((OffsetAndMetadata) (commitCapture.getValue().get(partition))).offset());\n+            assertEquals(lastOffset + 1, commitCapture.getValue().get(partition).offset());\n         }\n     }\n     \n",
            "security_relevancy": ""
        },
        {
            "diff": "@@ -1,26 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version\n- * 2.0 (the \"License\"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions\n- * and limitations under the License.\n- */\n-\n-package org.apache.storm.solr.trident;\n-\n-import java.util.List;\n-import org.apache.storm.trident.operation.TridentCollector;\n-import org.apache.storm.trident.state.BaseStateUpdater;\n-import org.apache.storm.trident.tuple.TridentTuple;\n-\n-public class SolrUpdater extends BaseStateUpdater<SolrState> {\n-\n-    @Override\n-    public void updateState(SolrState solrState, List<TridentTuple> tuples, TridentCollector collector) {\n-        solrState.updateState(tuples);\n-    }\n-}\n",
            "security_relevancy": ""
        },
        {
            "diff": "@@ -16,12 +16,11 @@ import static java.lang.String.format;\n \n import java.util.HashMap;\n import java.util.Map;\n-import org.apache.storm.generated.Nimbus;\n+import net.minidev.json.JSONObject;\n+import net.minidev.json.JSONValue;\n import org.apache.storm.generated.RebalanceOptions;\n import org.apache.storm.utils.NimbusClient;\n import org.apache.storm.utils.Utils;\n-import org.json.simple.JSONObject;\n-import org.json.simple.JSONValue;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n@@ -73,12 +72,9 @@ public class Rebalance {\n             rebalanceOptions.set_topology_conf_overrides(JSONValue.toJSONString(confOverrides));\n         }\n \n-        NimbusClient.withConfiguredClient(new NimbusClient.WithNimbus() {\n-            @Override\n-            public void run(Nimbus.Iface nimbus) throws Exception {\n-                nimbus.rebalance(name, rebalanceOptions);\n-                LOG.info(\"Topology {} is rebalancing\", name);\n-            }\n+        NimbusClient.withConfiguredClient(nimbus -> {\n+            nimbus.rebalance(name, rebalanceOptions);\n+            LOG.info(\"Topology {} is rebalancing\", name);\n         });\n     }\n \n",
            "security_relevancy": ""
        },
        {
            "diff": "@@ -1,94 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version\n- * 2.0 (the \"License\"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions\n- * and limitations under the License.\n- */\n-\n-package org.apache.storm.hbase.trident;\n-\n-import org.apache.hadoop.hbase.client.Durability;\n-import org.apache.storm.Config;\n-import org.apache.storm.StormSubmitter;\n-import org.apache.storm.generated.StormTopology;\n-import org.apache.storm.hbase.bolt.mapper.HBaseProjectionCriteria;\n-import org.apache.storm.hbase.bolt.mapper.HBaseValueMapper;\n-import org.apache.storm.hbase.topology.WordCountValueMapper;\n-import org.apache.storm.hbase.trident.mapper.SimpleTridentHBaseMapper;\n-import org.apache.storm.hbase.trident.mapper.TridentHBaseMapper;\n-import org.apache.storm.hbase.trident.state.HBaseQuery;\n-import org.apache.storm.hbase.trident.state.HBaseState;\n-import org.apache.storm.hbase.trident.state.HBaseStateFactory;\n-import org.apache.storm.hbase.trident.state.HBaseUpdater;\n-import org.apache.storm.trident.Stream;\n-import org.apache.storm.trident.TridentState;\n-import org.apache.storm.trident.TridentTopology;\n-import org.apache.storm.trident.state.StateFactory;\n-import org.apache.storm.trident.testing.FixedBatchSpout;\n-import org.apache.storm.tuple.Fields;\n-import org.apache.storm.tuple.Values;\n-\n-public class WordCountTrident {\n-    public static StormTopology buildTopology(String hbaseRoot) {\n-        Fields fields = new Fields(\"word\", \"count\");\n-        FixedBatchSpout spout = new FixedBatchSpout(fields, 4,\n-                                                    new Values(\"storm\", 1),\n-                                                    new Values(\"trident\", 1),\n-                                                    new Values(\"needs\", 1),\n-                                                    new Values(\"javadoc\", 1)\n-        );\n-        spout.setCycle(true);\n-\n-        TridentHBaseMapper tridentHBaseMapper = new SimpleTridentHBaseMapper()\n-            .withColumnFamily(\"cf\")\n-            .withColumnFields(new Fields(\"word\"))\n-            .withCounterFields(new Fields(\"count\"))\n-            .withRowKeyField(\"word\");\n-\n-        HBaseValueMapper rowToStormValueMapper = new WordCountValueMapper();\n-\n-        HBaseProjectionCriteria projectionCriteria = new HBaseProjectionCriteria();\n-        projectionCriteria.addColumn(new HBaseProjectionCriteria.ColumnMetaData(\"cf\", \"count\"));\n-\n-        HBaseState.Options options = new HBaseState.Options()\n-            .withConfigKey(hbaseRoot)\n-            .withDurability(Durability.SYNC_WAL)\n-            .withMapper(tridentHBaseMapper)\n-            .withProjectionCriteria(projectionCriteria)\n-            .withRowToStormValueMapper(rowToStormValueMapper)\n-            .withTableName(\"WordCount\");\n-\n-        StateFactory factory = new HBaseStateFactory(options);\n-\n-        TridentTopology topology = new TridentTopology();\n-        Stream stream = topology.newStream(\"spout1\", spout);\n-\n-        stream.partitionPersist(factory, fields, new HBaseUpdater(), new Fields());\n-\n-        TridentState state = topology.newStaticState(factory);\n-        stream = stream.stateQuery(state, new Fields(\"word\"), new HBaseQuery(), new Fields(\"columnName\", \"columnValue\"));\n-        stream.each(new Fields(\"word\", \"columnValue\"), new PrintFunction(), new Fields());\n-        return topology.build();\n-    }\n-\n-    public static void main(String[] args) throws Exception {\n-        Config conf = new Config();\n-        conf.setMaxSpoutPending(5);\n-        String topoName = \"wordCounter\";\n-\n-        if (args.length == 2) {\n-            topoName = args[1];\n-        } else if (args.length > 2) {\n-            System.out.println(\"Usage: WordCountTrident <hbase.rootdir> [topology name]\");\n-            return;\n-        }\n-        conf.setNumWorkers(3);\n-        StormSubmitter.submitTopology(topoName, conf, buildTopology(args[0]));\n-    }\n-\n-}\n",
            "security_relevancy": ""
        },
        {
            "diff": "@@ -1,40 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.storm.hbase.trident.mapper;\n-\n-import java.io.Serializable;\n-import org.apache.storm.hbase.common.ColumnList;\n-import org.apache.storm.trident.tuple.TridentTuple;\n-\n-/**\n- * Maps a <code>org.apache.storm.trident.tuple.TridentTuple</code> object to a row in an HBase table.\n- */\n-public interface TridentHBaseMapper extends Serializable {\n-\n-\n-    /**\n-     * Given a tuple, return the HBase rowkey.\n-     */\n-    byte[] rowKey(TridentTuple tuple);\n-\n-    /**\n-     * Given a tuple, return a list of HBase columns to insert.\n-     */\n-    ColumnList columns(TridentTuple tuple);\n-}\n",
            "security_relevancy": ""
        },
        {
            "diff": "@@ -16,7 +16,6 @@ import java.io.IOException;\n import java.util.Arrays;\n import java.util.HashSet;\n import java.util.Set;\n-import java.util.concurrent.atomic.AtomicInteger;\n import org.apache.storm.shade.io.netty.channel.Channel;\n import org.apache.storm.shade.io.netty.channel.ChannelHandlerContext;\n import org.apache.storm.shade.io.netty.channel.ChannelInboundHandlerAdapter;\n@@ -28,11 +27,9 @@ public class StormServerHandler extends ChannelInboundHandlerAdapter {\n     private static final Logger LOG = LoggerFactory.getLogger(StormServerHandler.class);\n     private static final Set<Class<?>> ALLOWED_EXCEPTIONS = new HashSet<>(Arrays.asList(new Class<?>[]{ IOException.class }));\n     private final IServer server;\n-    private final AtomicInteger failureCount;\n \n     public StormServerHandler(IServer server) {\n         this.server = server;\n-        failureCount = new AtomicInteger(0);\n     }\n \n     @Override\n@@ -51,14 +48,13 @@ public class StormServerHandler extends ChannelInboundHandlerAdapter {\n             server.received(msg, channel.remoteAddress().toString(), channel);\n         } catch (InterruptedException e) {\n             LOG.info(\"failed to enqueue a request message\", e);\n-            failureCount.incrementAndGet();\n         }\n     }\n \n     @Override\n     public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) {\n         try {\n-            LOG.error(\"server errors in handling the request\", cause);\n+            LOG.error(\"server errors in handling the request from {}\", ctx.channel().remoteAddress().toString(), cause);\n         } catch (Throwable err) {\n             // Doing nothing (probably due to an oom issue) and hoping Utils.handleUncaughtException will handle it\n         }\n",
            "security_relevancy": ""
        },
        {
            "diff": "@@ -18,7 +18,7 @@ import org.apache.storm.thrift.transport.TTransportException;\n \n public class NoOpTTrasport extends TSaslServerTransport {\n \n-    public NoOpTTrasport(TTransport transport) {\n+    public NoOpTTrasport(TTransport transport) throws TTransportException {\n         super(transport);\n     }\n \n",
            "security_relevancy": ""
        },
        {
            "diff": "@@ -25,7 +25,6 @@ import java.util.HashMap;\n import java.util.Map;\n import javax.security.auth.Subject;\n \n-import org.apache.storm.Config;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n",
            "security_relevancy": ""
        },
        {
            "diff": "@@ -41,9 +41,8 @@ import org.apache.storm.tuple.Tuple;\n import org.apache.storm.tuple.TupleImpl;\n import org.apache.storm.tuple.Values;\n import org.apache.storm.utils.MockTupleHelpers;\n-import org.junit.Assert;\n-import org.junit.Before;\n-import org.junit.Test;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n import org.mockito.Mock;\n import org.mockito.Mockito;\n import org.mockito.MockitoAnnotations;\n@@ -52,10 +51,11 @@ import org.mockito.stubbing.Answer;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import static org.junit.jupiter.api.Assertions.*;\n import static org.mockito.Mockito.any;\n import static org.mockito.Mockito.never;\n import static org.mockito.Mockito.verify;\n-import static org.mockito.Mockito.verifyZeroInteractions;\n+import static org.mockito.Mockito.verifyNoInteractions;\n \n public class TestHiveBolt {\n     final static String dbName = \"testdb\";\n@@ -91,7 +91,7 @@ public class TestHiveBolt {\n         }\n     }\n \n-    @Before\n+    @BeforeEach\n     public void setup() throws Exception {\n         MockitoAnnotations.initMocks(this);\n     }\n@@ -127,7 +127,7 @@ public class TestHiveBolt {\n             verify(collector).ack(t);\n         }\n \n-        Assert.assertEquals(4, bolt.getRecordWritten(partVals).size());\n+        assertEquals(4, bolt.getRecordWritten(partVals).size());\n \n         bolt.cleanup();\n     }\n@@ -162,8 +162,8 @@ public class TestHiveBolt {\n         }\n \n         List<byte[]> recordWritten = bolt.getRecordWritten(partVals);\n-        Assert.assertNotNull(recordWritten);\n-        Assert.assertEquals(4, recordWritten.size());\n+        assertNotNull(recordWritten);\n+        assertEquals(4, recordWritten.size());\n \n         bolt.cleanup();\n     }\n@@ -203,13 +203,13 @@ public class TestHiveBolt {\n         List<String> partVals = Lists.newArrayList(today);\n \n         List<byte[]> recordsWritten = bolt.getRecordWritten(partVals);\n-        Assert.assertNotNull(recordsWritten);\n-        Assert.assertEquals(2, recordsWritten.size());\n+        assertNotNull(recordsWritten);\n+        assertEquals(2, recordsWritten.size());\n \n         byte[] mapped = generateDelimiteredRecord(Lists.newArrayList(id, msg), mapper.getFieldDelimiter());\n \n         for (byte[] record : recordsWritten) {\n-            Assert.assertArrayEquals(mapped, record);\n+            assertArrayEquals(mapped, record);\n         }\n \n         bolt.cleanup();\n@@ -241,11 +241,11 @@ public class TestHiveBolt {\n         List<String> partVals = Lists.newArrayList(city, state);\n \n         List<byte[]> recordsWritten = bolt.getRecordWritten(partVals);\n-        Assert.assertNotNull(recordsWritten);\n-        Assert.assertEquals(1, recordsWritten.size());\n+        assertNotNull(recordsWritten);\n+        assertEquals(1, recordsWritten.size());\n \n         byte[] mapped = generateDelimiteredRecord(Lists.newArrayList(id, msg), mapper.getFieldDelimiter());\n-        Assert.assertArrayEquals(mapped, recordsWritten.get(0));\n+        assertArrayEquals(mapped, recordsWritten.get(0));\n \n         bolt.cleanup();\n     }\n@@ -278,8 +278,8 @@ public class TestHiveBolt {\n         List<String> partVals = Lists.newArrayList(city, state);\n \n         List<byte[]> recordsWritten = bolt.getRecordWritten(partVals);\n-        Assert.assertNotNull(recordsWritten);\n-        Assert.assertEquals(1, recordsWritten.size());\n+        assertNotNull(recordsWritten);\n+        assertEquals(1, recordsWritten.size());\n \n         byte[] written = recordsWritten.get(0);\n \n@@ -290,7 +290,7 @@ public class TestHiveBolt {\n         expected.put(COL1, id);\n         expected.put(COL2, msg);\n \n-        Assert.assertEquals(expected, writtenMap);\n+        assertEquals(expected, writtenMap);\n \n         bolt.cleanup();\n     }\n@@ -311,7 +311,7 @@ public class TestHiveBolt {\n         Tuple tuple2 = generateTestTuple(2, \"SFO\", \"San Jose\", \"CA\");\n \n         bolt.execute(tuple1);\n-        verifyZeroInteractions(collector);\n+        verifyNoInteractions(collector);\n \n         bolt.execute(tuple2);\n         verify(collector).ack(tuple1);\n@@ -389,7 +389,7 @@ public class TestHiveBolt {\n         //The tick should NOT cause any acks since the batch was empty except for acking itself\n         Tuple mockTick = MockTupleHelpers.mockTickTuple();\n         bolt.execute(mockTick);\n-        verifyZeroInteractions(collector);\n+        verifyNoInteractions(collector);\n \n         bolt.cleanup();\n     }\n@@ -426,14 +426,14 @@ public class TestHiveBolt {\n         List<String> partVals = Lists.newArrayList(city, state);\n \n         List<byte[]> recordsWritten = bolt.getRecordWritten(partVals);\n-        Assert.assertNotNull(recordsWritten);\n-        Assert.assertEquals(100, recordsWritten.size());\n+        assertNotNull(recordsWritten);\n+        assertEquals(100, recordsWritten.size());\n \n \n         byte[] mapped = generateDelimiteredRecord(Lists.newArrayList(id, msg), mapper.getFieldDelimiter());\n \n         for (byte[] record : recordsWritten) {\n-            Assert.assertArrayEquals(mapped, record);\n+            assertArrayEquals(mapped, record);\n         }\n \n         bolt.cleanup();\n",
            "security_relevancy": ""
        },
        {
            "diff": "@@ -1,48 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.storm.kinesis.spout.test;\n-\n-import org.apache.storm.task.OutputCollector;\n-import org.apache.storm.task.TopologyContext;\n-import org.apache.storm.topology.OutputFieldsDeclarer;\n-import org.apache.storm.topology.base.BaseRichBolt;\n-import org.apache.storm.tuple.Tuple;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import java.util.Map;\n-\n-public class KinesisBoltTest extends BaseRichBolt {\n-    protected static final Logger LOG = LoggerFactory.getLogger(KinesisBoltTest.class);\n-    private transient OutputCollector collector;\n-\n-    @Override\n-    public void prepare(Map<String, Object> topoConf, TopologyContext context, OutputCollector collector) {\n-        this.collector = collector;\n-    }\n-\n-    @Override\n-    public void execute(Tuple input) {\n-        LOG.info(\"input = [\" + input + \"]\");\n-        collector.ack(input);\n-    }\n-\n-    @Override\n-    public void declareOutputFields(OutputFieldsDeclarer declarer) {\n-    }\n-}\n",
            "security_relevancy": ""
        }
    ]
}